<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta
      name="author"
      content="Frank Elavsky,^{1} Cynthia Bennett,^{1} and Dominik Moritz^{1} ¶ ¶ ^1Carnegie Mellon University, Human-Computer Interaction Institute "
    />
    <title>How accessible is my visualization? Evaluating visualization accessibility with Chartability</title>
    <style>
      html {
        line-height: 1.5;
        font-family: Georgia, serif;
        font-size: 20px;
        color: #1a1a1a;
        background-color: #fdfdfd;
      }
      body {
        margin: 0 auto;
        max-width: 36em;
        padding-left: 50px;
        padding-right: 50px;
        padding-top: 50px;
        padding-bottom: 50px;
        hyphens: auto;
        overflow-wrap: break-word;
        text-rendering: optimizeLegibility;
        font-kerning: normal;
      }
      @media (max-width: 600px) {
        body {
          font-size: 0.9em;
          padding: 1em;
        }
        h1 {
          font-size: 1.8em;
        }
      }
      @media print {
        body {
          background-color: transparent;
          color: black;
          font-size: 12pt;
        }
        p,
        h2,
        h3 {
          orphans: 3;
          widows: 3;
        }
        h2,
        h3,
        h4 {
          page-break-after: avoid;
        }
      }
      p {
        margin: 1em 0;
      }
      a {
        color: #1a1a1a;
      }
      a:visited {
        color: #1a1a1a;
      }
      img {
        max-width: 100%;
      }
      h1,
      h2,
      h3,
      h4,
      h5,
      h6 {
        margin-top: 1.4em;
      }
      h5,
      h6 {
        font-size: 1em;
        font-style: italic;
      }
      h6 {
        font-weight: normal;
      }
      ol,
      ul {
        padding-left: 1.7em;
        margin-top: 1em;
      }
      li > ol,
      li > ul {
        margin-top: 0;
      }
      blockquote {
        margin: 1em 0 1em 1.7em;
        padding-left: 1em;
        border-left: 2px solid #e6e6e6;
        color: #606060;
      }
      div.abstract {
        margin: 2em 2em 2em 2em;
        text-align: left;
        font-size: 85%;
      }
      div.abstract-title {
        font-weight: bold;
        text-align: center;
        padding: 0;
        margin-bottom: 0.5em;
      }
      code {
        font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
        font-size: 85%;
        margin: 0;
      }
      pre {
        margin: 1em 0;
        overflow: auto;
      }
      pre code {
        padding: 0;
        overflow: visible;
        overflow-wrap: normal;
      }
      .sourceCode {
        background-color: transparent;
        overflow: visible;
      }
      hr {
        background-color: #1a1a1a;
        border: none;
        height: 1px;
        margin: 1em 0;
      }
      table {
        margin: 1em 0;
        border-collapse: collapse;
        width: 100%;
        overflow-x: auto;
        display: block;
        font-variant-numeric: lining-nums tabular-nums;
      }
      table caption {
        margin-bottom: 0.75em;
      }
      tbody {
        margin-top: 0.5em;
        border-top: 1px solid #1a1a1a;
        border-bottom: 1px solid #1a1a1a;
      }
      th {
        border-top: 1px solid #1a1a1a;
        padding: 0.25em 0.5em 0.25em 0.5em;
      }
      td {
        padding: 0.125em 0.5em 0.25em 0.5em;
      }
      header {
        margin-bottom: 4em;
        text-align: center;
      }
      #TOC li {
        list-style: none;
      }
      #TOC ul {
        padding-left: 1.3em;
      }
      #TOC > ul {
        padding-left: 0;
      }
      #TOC a:not(:hover) {
        text-decoration: none;
      }
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
      div.hanging-indent {
        margin-left: 1.5em;
        text-indent: -1.5em;
      }
      ul.task-list {
        list-style: none;
      }
      .display.math {
        display: block;
        text-align: center;
        margin: 0.5rem auto;
      }
    </style>
    <!--[if lt IE 9]>
      <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
    <![endif]-->
    <style>
      html {
        line-height: 1.5;
        font-family: Georgia, serif;
        font-size: 20px;
        color: #1a1a1a;
        background-color: #fdfdfd;
      }
      body {
        margin: 0 auto;
        max-width: 36em;
        padding-left: 50px;
        padding-right: 50px;
        padding-top: 50px;
        padding-bottom: 50px;
        hyphens: auto;
        overflow-wrap: break-word;
        text-rendering: optimizeLegibility;
        font-kerning: normal;
      }
      @media (max-width: 600px) {
        body {
          font-size: 0.9em;
          padding: 1em;
        }
        h1 {
          font-size: 1.8em;
        }
      }
      @media print {
        body {
          background-color: transparent;
          color: black;
          font-size: 12pt;
        }
        p,
        h2,
        h3 {
          orphans: 3;
          widows: 3;
        }
        h2,
        h3,
        h4 {
          page-break-after: avoid;
        }
      }
      p {
        margin: 1em 0;
      }
      a {
        color: #1a1a1a;
      }
      a:visited {
        color: #1a1a1a;
      }
      img {
        max-width: 100%;
      }
      h1,
      h2,
      h3,
      h4,
      h5,
      h6 {
        margin-top: 1.4em;
      }
      h5,
      h6 {
        font-size: 1em;
        font-style: italic;
      }
      h6 {
        font-weight: normal;
      }
      ol,
      ul {
        padding-left: 1.7em;
        margin-top: 1em;
      }
      li > ol,
      li > ul {
        margin-top: 0;
      }
      blockquote {
        margin: 1em 0 1em 1.7em;
        padding-left: 1em;
        border-left: 2px solid #e6e6e6;
        color: #606060;
      }
      code {
        font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
        font-size: 85%;
        margin: 0;
      }
      pre {
        margin: 1em 0;
        overflow: auto;
      }
      pre code {
        padding: 0;
        overflow: visible;
        overflow-wrap: normal;
      }
      .sourceCode {
        background-color: transparent;
        overflow: visible;
      }
      hr {
        background-color: #1a1a1a;
        border: none;
        height: 1px;
        margin: 1em 0;
      }
      table {
        margin: 1em 0;
        border-collapse: collapse;
        width: 100%;
        overflow-x: auto;
        display: block;
        font-variant-numeric: lining-nums tabular-nums;
      }
      table caption {
        margin-bottom: 0.75em;
      }
      tbody {
        margin-top: 0.5em;
        border-top: 1px solid #1a1a1a;
        border-bottom: 1px solid #1a1a1a;
      }
      th {
        border-top: 1px solid #1a1a1a;
        padding: 0.25em 0.5em 0.25em 0.5em;
      }
      td {
        padding: 0.125em 0.5em 0.25em 0.5em;
      }
      header {
        margin-bottom: 4em;
        text-align: center;
      }
      #TOC li {
        list-style: none;
      }
      #TOC ul {
        padding-left: 1.3em;
      }
      #TOC > ul {
        padding-left: 0;
      }
      #TOC a:not(:hover) {
        text-decoration: none;
      }
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
      div.hanging-indent {
        margin-left: 1.5em;
        text-indent: -1.5em;
      }
      ul.task-list {
        list-style: none;
      }
      .display.math {
        display: block;
        text-align: center;
        margin: 0.5rem auto;
      }
      div.csl-bib-body {
      }
      div.csl-entry {
        clear: both;
      }
      .hanging div.csl-entry {
        margin-left: 2em;
        text-indent: -2em;
      }
      div.csl-left-margin {
        min-width: 2em;
        float: left;
      }
      div.csl-right-inline {
        margin-left: 2em;
        padding-left: 1em;
      }
      div.csl-indent {
        margin-left: 2em;
      }
    </style>
  </head>
  <body>
    <header id="title-block-header">
      <h1 class="title">
        How accessible is my visualization? Evaluating visualization accessibility with Chartability
      </h1>
      <p class="author">
        Frank Elavsky,<span class="math inline"><sup>1</sup></span> Cynthia Bennett,<span class="math inline"
          ><sup>1</sup></span
        >
        and Dominik Moritz<span class="math inline"><sup>1</sup></span> ¶<br />
        ¶ <span class="math inline"><sup>1</sup></span
        >Carnegie Mellon University, Human-Computer Interaction Institute<br />
      </p>
      <div class="abstract">
        <div class="abstract-title">Abstract</div>
        <p>
          Novices and experts have struggled to evaluate the accessibility of data visualizations because there are no
          common shared guidelines across environments, platforms, and contexts in which data visualizations are
          authored. Between non-specific standards bodies like WCAG, emerging research, and guidelines from specific
          communities of practice, it is hard to organize knowledge on how to evaluate accessible data visualizations.
          We present Chartability, a set of heuristics synthesized from these various sources which enables designers,
          developers, researchers, and auditors to evaluate data-driven visualizations and interfaces for visual, motor,
          vestibular, neurological, and cognitive accessibility. In this paper, we outline our process of making a set
          of heuristics and accessibility principles for Chartability and highlight key features in the auditing
          process. Working with participants on real projects, we found that data practitioners with a novice level of
          accessibility skills were more confident and found auditing to be easier after using Chartability. Expert
          accessibility practitioners were eager to integrate Chartability into their own work. Reflecting on
          Chartability’s development and the preliminary user evaluation, we discuss tradeoffs of open projects, working
          with high-risk evaluations like auditing projects in the wild, and challenge future research projects at the
          intersection of visualization and accessibility to consider the broad intersections of disabilities.
        </p>
        <div class="CCSXML">
          <p>
            &lt;ccs2012&gt; &lt;concept&gt; &lt;concept_id&gt;10003120.10003145.10011770&lt;/concept_id&gt;
            &lt;concept_desc&gt;Human-centered computing&nbsp;Visualization design and evaluation
            methods&lt;/concept_desc&gt; &lt;concept_significance&gt;500&lt;/concept_significance&gt; &lt;/concept&gt;
            &lt;concept&gt; &lt;concept_id&gt;10003120.10011738.10011774&lt;/concept_id&gt;
            &lt;concept_desc&gt;Human-centered computing&nbsp;Accessibility design and evaluation
            methods&lt;/concept_desc&gt; &lt;concept_significance&gt;500&lt;/concept_significance&gt; &lt;/concept&gt;
            &lt;concept&gt; &lt;concept_id&gt;10003120.10003121.10003122.10010855&lt;/concept_id&gt;
            &lt;concept_desc&gt;Human-centered computing&nbsp;Heuristic evaluations&lt;/concept_desc&gt;
            &lt;concept_significance&gt;500&lt;/concept_significance&gt; &lt;/concept&gt; &lt;/ccs2012&gt;
          </p>
        </div>
      </div>
    </header>
    <h1 id="introduction">Introduction</h1>
    <p>
      26% of people in the United States self-report living with at least one disability&nbsp;<span
        class="citation"
        data-cites="cdc_disability_2018"
        >[<a href="#ref-cdc_disability_2018" id="cdc_disability_201801" aria-label="1, C. Okoro" title="1, C. Okoro"
          >1</a
        >]</span
      >. Of those, 13.7% live with a mobility disability and 10.8% with a cognitive disability. Globally, the World
      Health Organization reports that 29% of the world lives with uncorrected or uncorrectable blindness, low vision,
      or moderate to severe visual impairment&nbsp;<span class="citation" data-cites="noauthor_world_nodate"
        >[<a
          href="#ref-noauthor_world_nodate"
          id="noauthor_world_nodate01"
          aria-label="13, W. H. Organization"
          title="13, W. H. Organization"
          >13</a
        >]</span
      >. Access is a significant inclusion effort that has broad international impact, especially for data
      visualization.
    </p>
    <p>
      Accessibility is the practice of making information, content, and functionality fully available to and usable by
      people with disabilities. As part of this process, practitioners need to be able to identify accessibility
      barriers. While general accessibility standards help, evaluating the inaccessibility of complex data systems can
      be a daunting and often expensive task. State-of-the art automated compliance checkers only find 57% of
      accessibility errors&nbsp;<span class="citation" data-cites="noauthor_study_2021"
        >[<a href="#ref-noauthor_study_2021" id="noauthor_study_202101" aria-label="53, Deque" title="53, Deque">53</a
        >]</span
      >, meaning accessible experiences must still be manually designed and checked for quality. And following standards
      may only account for up to half of the needs of people with disabilities
      <span class="citation" data-cites="power_2012"
        >[<a href="#ref-power_2012" id="power_201201" aria-label="86, C. Power" title="86, C. Power">86</a>]</span
      >
      anyway. Additionally, the intended wide applicability of these general standards means they fall short for
      information-rich systems, such as data visualizations (which use size, color, angles, shapes, and other dimensions
      to encode information). These specific contexts, communities, and libraries that deal with data visualizations and
      information-rich interfaces often have their own tools and guidelines for use, but they seldom include
      accessibility. Finally, research at the intersection of data visualization and accessibility has yet to
      meaningfully permeate data visualization tools and communities and primarily focuses on blindness and low vision,
      neglecting diverse accessibility needs of people with other disabilities.
    </p>
    <p>
      Synthesizing evolving accessibility standards, research findings, and artifacts from communities of practice into
      usable knowledge for a specific, evolving domain is a wicked problem. To address this, we present Chartability.
      Chartability is an accessibility evaluation system specific to data visualizations and interfaces which aims to
      help practitioners answer the question, “how accessible is my data visualization?” Chartability organizes
      knowledge from disparate bodies of work into testable heuristics based on the functional accessibility principles
      POUR (Perceivable, Operable, Understandable, and Robust)&nbsp;<span
        class="citation"
        data-cites="initiative_wai_accessibility_nodate"
        >[<a
          href="#ref-initiative_wai_accessibility_nodate"
          id="initiative_wai_accessibility_nodate01"
          aria-label="52, WAI"
          title="52, WAI"
          >52</a
        >]</span
      >
      and 3 novel principles CAF (Compromising, Assistive, and Flexible), which we added to attend to the unique
      qualities and demands of data visualizations. We refer to these 7 heuristic principles as POUR+CAF. Chartability
      is a community-contributed project that leverages the governance strategies of open source projects as a way to
      address the complex dual-evolution of both accessibility and data interaction practices.
    </p>
    <p>
      We additionally present an initial, light evaluation of Chartability from the experience of practitioners using
      it. We set out to see if using Chartability reduces the barrier of entry into this work for accessibility novices
      and if accessibility experts had any feedback to share about its use. We gave practitioners introductory material
      for Chartability and instructed them to use it according to their needs. We found that before using Chartability
      only accessibility experts believed auditing data visualizations to be somewhat easy or easy, while the other
      group believed auditing data visualizations to be somewhat hard or hard. All novice accessibility practitioners
      became more confident after using Chartability and believed auditing data visualizations for accessibility to be
      less difficult. Conversely while the expert accessibility practitioners were already confident in their ability to
      evaluate accessibility (and all unanimously had no change in their before and after evaluations), they were
      excited to adopt Chartability into their set of auditing resources.
    </p>
    <p>
      Our work sets out to acknowledge that data practitioners face significant barriers when first making data
      visualizations, systems, and experiences accessible. While Chartability contributes to filling gaps and organizing
      knowledge, it also challenges visualization and data interaction researchers to explore new horizons of
      possibilities in this space. As such, we conclude with recommendations for future research at the crossroads of
      data visualization and accessibility.
    </p>
    <h1 id="existing-work-in-data-visualization-and-accessibility">
      Existing Work in Data Visualization and Accessibility
    </h1>
    <p>
      While recent works at the intersection of data visualization and accessibility are promising, they do not provide
      a consistent and unified methodology for designers to evaluate the accessibility of their work across the broad
      spectrum of disability considerations.
    </p>
    <h2 id="research-advancements-in-data-visualization-and-accessibility">
      Research Advancements in Data Visualization and Accessibility
    </h2>
    <p>
      In parallel to Mack <span>et&nbsp;al</span>’s “What do we mean by Accessibility Research?”&nbsp;<span
        class="citation"
        data-cites="mack_what_2021"
        >[<a href="#ref-mack_what_2021" id="mack_what_202101" aria-label="93, K. Mack" title="93, K. Mack">93</a>]</span
      >
      when we asked “What do we mean by data visualization accessibility research?” we found that nearly all topics of
      study were vision-related. Largely, access issues other than vision that affect data visualization (such as
      cognitive/neurological, vestibular, and motor concerns) are almost entirely unserved in this research space. Kim
      <span>et&nbsp;al</span> found that 56 papers have been published between 1999 and 2020 that focus on
      vision-related accessibility (not including color vision deficiency), with only 3 being published at a
      visualization venue (and only recently since 2018)&nbsp;<span class="citation" data-cites="kim_accessible_2021"
        >[<a href="#ref-kim_accessible_2021" id="kim_accessible_202101" aria-label="87, N. W. Kim" title="87, N. W. Kim"
          >87</a
        >]</span
      >. Marriott <span>et&nbsp;al</span> found that there is no research at all that engages motor
      accessibility&nbsp;<span class="citation" data-cites="marriott_inclusive_2021"
        >[<a
          href="#ref-marriott_inclusive_2021"
          id="marriott_inclusive_202101"
          aria-label="88, K. Marriott et al."
          title="88, K. Marriott et al."
          >88</a
        >]</span
      >. We have found 2 papers that engage cognitive/neurological disability in visualization and 1 student poster from
      IEEE Vis, which are all recent (specifically intellectual developmental disabilities&nbsp;<span
        class="citation"
        data-cites="wu_understanding_2021"
        >[<a href="#ref-wu_understanding_2021" id="wu_understanding_202101" aria-label="34, K. Wu" title="34, K. Wu"
          >34</a
        >]</span
      >
      and seizure risk&nbsp;<span class="citation" data-cites="south_generating_2020 south_detecting_2021"
        >[<a
          href="#ref-south_generating_2020"
          id="south_generating_202001"
          aria-label="33, L. South and M. Borkin"
          title="33, L. South and M. Borkin"
          >33</a
        >,
        <a href="#ref-south_detecting_2021" id="south_detecting_202101" aria-label="3, L. South" title="3, L. South"
          >3</a
        >]</span
      >). We found no papers that engage vestibular accessibility, such as motion and animation-related accessibility.
      We also found that there is no research specific to low vision disabilities (not blindness or color vision
      deficiency) unless conflated with screen reader usage in data visualization. Blind and low vision people are often
      researched together, but in practice may use different assistive technologies (such as magnifiers and contrast
      enhancers) and have different interaction practices (such as a combination of sight, magnification, and screen
      reader use)&nbsp;<span class="citation" data-cites="szpiro_2016"
        >[<a href="#ref-szpiro_2016" id="szpiro_201601" aria-label="17, S. F. A. Szpiro" title="17, S. F. A. Szpiro"
          >17</a
        >]</span
      >.
    </p>
    <p>
      Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision
      deficiency&nbsp;<span
        class="citation"
        data-cites="chaparro_applications_2017 nunez_optimizing_2018 oliveira_towards_2013 9023497 martinez_methodology_2021"
        >[<a
          href="#ref-chaparro_applications_2017"
          id="chaparro_applications_201701"
          aria-label="57, A. Chaparro and M. Chaparro"
          title="57, A. Chaparro and M. Chaparro"
          >57</a
        >,
        <a
          href="#ref-nunez_optimizing_2018"
          id="nunez_optimizing_201801"
          aria-label="58, J. R. Nuñez"
          title="58, J. R. Nuñez"
          >58</a
        >,
        <a
          href="#ref-oliveira_towards_2013"
          id="oliveira_towards_201301"
          aria-label="59, M. M. Oliveira"
          title="59, M. M. Oliveira"
          >59</a
        >, <a href="#ref-9023497" id="902349701" aria-label="2, B. Lee" title="2, B. Lee">2</a>,
        <a
          href="#ref-martinez_methodology_2021"
          id="martinez_methodology_202101"
          aria-label="43, R. A. Martínez"
          title="43, R. A. Martínez"
          >43</a
        >]</span
      >. Research projects that explore tactile sensory substitutions have been a topic in computational sciences dating
      back to the 1983&nbsp;<span class="citation" data-cites="geldard_tactual_1983"
        >[<a
          href="#ref-geldard_tactual_1983"
          id="geldard_tactual_198301"
          aria-label="47, F. A. Geldard"
          title="47, F. A. Geldard"
          >47</a
        >]</span
      >, with tactile sensory substitutions being used for maps and charts as far back as the 1830s&nbsp;<span
        class="citation"
        data-cites="noauthor_extensive_2016"
        >[<a
          href="#ref-noauthor_extensive_2016"
          id="noauthor_extensive_201601"
          aria-label="90, J. Hale"
          title="90, J. Hale"
          >90</a
        >]</span
      >. Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates
      as far back as 1985&nbsp;<span
        class="citation"
        data-cites="mansur_sound_1985 flowers_cross-modal_1997 brewster_visualization_2002 mcgookin_soundbar_2006 zhao_data_2008 cullen_co-designing_2019"
        >[<a
          href="#ref-mansur_sound_1985"
          id="mansur_sound_198501"
          aria-label="22, D. L. Mansur"
          title="22, D. L. Mansur"
          >22</a
        >,
        <a
          href="#ref-flowers_cross-modal_1997"
          id="flowers_cross-modal_199701"
          aria-label="24, J. H. Flowers"
          title="24, J. H. Flowers"
          >24</a
        >,
        <a
          href="#ref-brewster_visualization_2002"
          id="brewster_visualization_200201"
          aria-label="62, S. Brewster"
          title="62, S. Brewster"
          >62</a
        >,
        <a
          href="#ref-mcgookin_soundbar_2006"
          id="mcgookin_soundbar_200601"
          aria-label="23, D. K. McGookin and S. A. Brewster"
          title="23, D. K. McGookin and S. A. Brewster"
          >23</a
        >, <a href="#ref-zhao_data_2008" id="zhao_data_200801" aria-label="61, H. Zhao" title="61, H. Zhao">61</a>,
        <a
          href="#ref-cullen_co-designing_2019"
          id="cullen_co-designing_201901"
          aria-label="50, C. Cullen and O. Metatla"
          title="50, C. Cullen and O. Metatla"
          >50</a
        >]</span
      >. Some more recent work has explored robust screen reader data interaction techniques&nbsp;<span
        class="citation"
        data-cites="miesenberger_accessible_2018 sorge_polyfilling_2016"
        >[<a
          href="#ref-miesenberger_accessible_2018"
          id="miesenberger_accessible_201801"
          aria-label="84, A. J. R. Godfrey"
          title="84, A. J. R. Godfrey"
          >84</a
        >,
        <a
          href="#ref-sorge_polyfilling_2016"
          id="sorge_polyfilling_201601"
          aria-label="85, V. Sorge"
          title="85, V. Sorge"
          >85</a
        >]</span
      >, screen reader user experiences with digital, 2-D spatial representations, including data
      visualizations&nbsp;<span class="citation" data-cites="schaadhardt_understanding_2021 sharif_understanding_2021"
        >[<a
          href="#ref-schaadhardt_understanding_2021"
          id="schaadhardt_understanding_202101"
          aria-label="60, A. Schaadhardt"
          title="60, A. Schaadhardt"
          >60</a
        >,
        <a
          href="#ref-sharif_understanding_2021"
          id="sharif_understanding_202101"
          aria-label="10, A. Sharif"
          title="10, A. Sharif"
          >10</a
        >]</span
      >, dug deeper into the semantic layers of effective chart descriptions&nbsp;<span
        class="citation"
        data-cites="lundgard_accessible_22"
        >[<a
          href="#ref-lundgard_accessible_22"
          id="lundgard_accessible_2201"
          aria-label="89, A. Lundgard and A. Satyanarayan"
          title="89, A. Lundgard and A. Satyanarayan"
          >89</a
        >]</span
      >, and investigated how to better understand the role of sensory substitution&nbsp;<span
        class="citation"
        data-cites="chundury_towards_2022"
        >[<a
          href="#ref-chundury_towards_2022"
          id="chundury_towards_202201"
          aria-label="92, P. Chundury"
          title="92, P. Chundury"
          >92</a
        >]</span
      >. Jung <span>et&nbsp;al</span> offer guidance that expands beyond commonly cited literature that chart
      descriptions are preferably between 2 and 8 sentences long, written in plain language, and with consideration for
      the order of information and navigation&nbsp;<span class="citation" data-cites="jung_communicating_2022"
        >[<a
          href="#ref-jung_communicating_2022"
          id="jung_communicating_202201"
          aria-label="91, C. Jung"
          title="91, C. Jung"
          >91</a
        >]</span
      >. We find all of this emerging work promising and foundational.
    </p>
    <p>
      Despite this promising work emerging, we also want to acknowledge a spectrum of other work that exists at the
      intersection of accessibility and data visualization that does not serve the goals of our project. There is
      significant research that explores automatic or extracted textual descriptions&nbsp;<span
        class="citation"
        data-cites="choi_visualizing_2019 balaji_chart-text_2018 chen_neural_2019 chen_figure_2020 lai_automatic_2020 obeid_chart--text_2020 qian_generating_2021 sharif_evographs_2018"
        >[<a href="#ref-choi_visualizing_2019" id="choi_visualizing_201901" aria-label="28, J. Choi" title="28, J. Choi"
          >28</a
        >,
        <a
          href="#ref-balaji_chart-text_2018"
          id="balaji_chart-text_201801"
          aria-label="36, A. Balaji"
          title="36, A. Balaji"
          >36</a
        >,
        <a
          href="#ref-chen_neural_2019"
          id="chen_neural_201901"
          aria-label="37, C. Chen et al."
          title="37, C. Chen et al."
          >37</a
        >, <a href="#ref-chen_figure_2020" id="chen_figure_202001" aria-label="38, C. Chen" title="38, C. Chen">38</a>,
        <a href="#ref-lai_automatic_2020" id="lai_automatic_202001" aria-label="39, C. Lai" title="39, C. Lai">39</a>,
        <a
          href="#ref-obeid_chart--text_2020"
          id="obeid_chart--text_202001"
          aria-label="40, J. Obeid and E. Hoque"
          title="40, J. Obeid and E. Hoque"
          >40</a
        >,
        <a
          href="#ref-qian_generating_2021"
          id="qian_generating_202101"
          aria-label="41, X. Qian et al."
          title="41, X. Qian et al."
          >41</a
        >,
        <a
          href="#ref-sharif_evographs_2018"
          id="sharif_evographs_201801"
          aria-label="21, A. Sharif and B. Forouraghi"
          title="21, A. Sharif and B. Forouraghi"
          >21</a
        >]</span
      >
      and haptic graphs and tactile interfaces&nbsp;<span
        class="citation"
        data-cites="aldrich_talk_2008 bornschein_collaborative_2015 brown_viztouch_2012 butler_technology_2021 gallace_what_2011 geldard_tactual_1983 jansen_opportunities_2015 jayant_automated_2007 lederman_perception_1986 schneider_constructing_nodate shi_tickers_2016 baker_2016"
        >[<a href="#ref-aldrich_talk_2008" id="aldrich_talk_200801" aria-label="44, F. Aldrich" title="44, F. Aldrich"
          >44</a
        >,
        <a
          href="#ref-bornschein_collaborative_2015"
          id="bornschein_collaborative_201501"
          aria-label="51, J. Bornschein"
          title="51, J. Bornschein"
          >51</a
        >,
        <a
          href="#ref-brown_viztouch_2012"
          id="brown_viztouch_201201"
          aria-label="25, C. Brown and A. Hurst"
          title="25, C. Brown and A. Hurst"
          >25</a
        >,
        <a
          href="#ref-butler_technology_2021"
          id="butler_technology_202101"
          aria-label="46, M. Butler"
          title="46, M. Butler"
          >46</a
        >,
        <a
          href="#ref-gallace_what_2011"
          id="gallace_what_201101"
          aria-label="48, A. Gallace and C. Spence"
          title="48, A. Gallace and C. Spence"
          >48</a
        >,
        <a
          href="#ref-geldard_tactual_1983"
          id="geldard_tactual_198311"
          aria-label="47, F. A. Geldard"
          title="47, F. A. Geldard"
          >47</a
        >,
        <a
          href="#ref-jansen_opportunities_2015"
          id="jansen_opportunities_201501"
          aria-label="29, Y. Jansen et al."
          title="29, Y. Jansen et al."
          >29</a
        >,
        <a
          href="#ref-jayant_automated_2007"
          id="jayant_automated_200701"
          aria-label="31, C. Jayant"
          title="31, C. Jayant"
          >31</a
        >,
        <a
          href="#ref-lederman_perception_1986"
          id="lederman_perception_198601"
          aria-label="49, S. Lederman"
          title="49, S. Lederman"
          >49</a
        >,
        <a
          href="#ref-schneider_constructing_nodate"
          id="schneider_constructing_nodate01"
          aria-label="45, J. Schneider"
          title="45, J. Schneider"
          >45</a
        >, <a href="#ref-shi_tickers_2016" id="shi_tickers_201601" aria-label="27, L. Shi" title="27, L. Shi">27</a>,
        <a href="#ref-baker_2016" id="baker_201601" aria-label="16, C. M. Baker" title="16, C. M. Baker">16</a>]</span
      >. These research projects produce artifacts that are high-cost for individual use, some are not robust enough to
      interpret complex visualizations effectively, and several have not included people with disabilities. Since our
      goal is to synthesize knowledge for practitioner accessibility work, we also acknowledge that some of these
      projects did not follow standards during their research project and in their output, such as using Web Content
      Accessibility Guidelines&nbsp;<span class="citation" data-cites="noauthor_web_nodate"
        >[<a
          href="#ref-noauthor_web_nodate"
          id="noauthor_web_nodate01"
          aria-label="20, W. A. Initiative"
          title="20, W. A. Initiative"
          >20</a
        >]</span
      >
      or The American Printing House for the Blind and Braille Authority of North America&nbsp;<span
        class="citation"
        data-cites="noauthor_guidelines_nodate"
        >[<a
          href="#ref-noauthor_guidelines_nodate"
          id="noauthor_guidelines_nodate01"
          aria-label="32, BANA"
          title="32, BANA"
          >32</a
        >]</span
      >. All of these challenges are factors that limit the generalizability of these artifacts and knowledge for
      practitioner use&nbsp;<span
        class="citation"
        data-cites="lundgard_sociotechnical_2019 moraes_evaluating_2014 sharif_understanding_2021"
        >[<a
          href="#ref-lundgard_sociotechnical_2019"
          id="lundgard_sociotechnical_201901"
          aria-label="18, A. Lundgard"
          title="18, A. Lundgard"
          >18</a
        >,
        <a
          href="#ref-moraes_evaluating_2014"
          id="moraes_evaluating_201401"
          aria-label="56, P. Moraes"
          title="56, P. Moraes"
          >56</a
        >,
        <a
          href="#ref-sharif_understanding_2021"
          id="sharif_understanding_202111"
          aria-label="10, A. Sharif"
          title="10, A. Sharif"
          >10</a
        >]</span
      >. We encourage work to continue at the intersection of accessibility and visualization, but stress the importance
      of practical, disability-led research that either builds on or explicitly challenges standards.
    </p>
    <h2 id="accessibility-practices-in-data-visualization-tools-and-libraries">
      Accessibility Practices in Data Visualization Tools and Libraries
    </h2>
    <p>
      Our research goals are to find what is already being done in data visualization and accessibility and to see if we
      can enhance that activity. To this aim, our background investigation includes a broad and comprehensive
      exploration of the field of practitioner and non-academic artifacts.
    </p>
    <p>
      Some open source and industry contributions have pushed data visualization and related accessibility efforts.
      Libraries like Highcharts&nbsp;<span class="citation" data-cites="noauthor_accessibility_nodate"
        >[<a
          href="#ref-noauthor_accessibility_nodate"
          id="noauthor_accessibility_nodate01"
          aria-label="63, Highsoft"
          title="63, Highsoft"
          >63</a
        >]</span
      >
      or Visa Chart Components (VCC)&nbsp;<span class="citation" data-cites="vcc"
        >[<a href="#ref-vcc" id="vcc01" aria-label="64, Visa" title="64, Visa">64</a>]</span
      >
      and tools like the Graphics Accelerator in SAS&nbsp;<span class="citation" data-cites="noauthor_sas_nodate"
        >[<a href="#ref-noauthor_sas_nodate" id="noauthor_sas_nodate01" aria-label="83, SAS" title="83, SAS">83</a
        >]</span
      >
      have broad accessibility functionality built in, but their documentation is technically specific to their
      implementation. While these relatively accessible libraries and tools can be helpful for inspiration, their
      specific techniques and guidance materials are not easily transferrable to other environments or applications
      where data visualizations are created. Practitioners must reverse engineer and deconstruct many of the methods
      employed by these libraries, and with the exception of VCC (which is open source), this task requires significant
      effort, given their primarily closed-box nature.
    </p>
    <p>
      In common charting tools and libraries (apart from those already mentioned) accessibility engineering is often not
      present, limited in scope, or has only recently become an effort. More established visualization libraries like
      matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying
      levels of documentation and difficulty involved&nbsp;<span
        class="citation"
        data-cites="noauthor_are_2018 noauthor_making_2018 noauthor_revealing_nodate noauthor_solved_2019 simon_making_2020"
        >[<a href="#ref-noauthor_are_2018" id="noauthor_are_201801" aria-label="67, P. C. Forum" title="67, P. C. Forum"
          >67</a
        >,
        <a
          href="#ref-noauthor_making_2018"
          id="noauthor_making_201801"
          aria-label="66, Rs. Community"
          title="66, Rs. Community"
          >66</a
        >,
        <a
          href="#ref-noauthor_revealing_nodate"
          id="noauthor_revealing_nodate01"
          aria-label="65, S. Canelón and L. Hare"
          title="65, S. Canelón and L. Hare"
          >65</a
        >,
        <a
          href="#ref-noauthor_solved_2019"
          id="noauthor_solved_201901"
          aria-label="68, P. C. Forum"
          title="68, P. C. Forum"
          >68</a
        >,
        <a
          href="#ref-simon_making_2020"
          id="simon_making_202001"
          aria-label="69, S. Wheatcroft"
          title="69, S. Wheatcroft"
          >69</a
        >]</span
      >. None of these major tools have a broad spectrum of accessibility options built in and documented.
    </p>
    <p>
      Community contributors often must fight to make their tools and environments accessible (sometimes even against
      the design of the tools themselves) with little to no compensation for their contributions. For example, Tableau’s
      first accessible data table was built by a volunteer community member Toan Hong as an extension&nbsp;<span
        class="citation"
        data-cites="hoang_tableaumagic_2018"
        >[<a
          href="#ref-hoang_tableaumagic_2018"
          id="hoang_tableaumagic_201801"
          aria-label="14, T. Hoang"
          title="14, T. Hoang"
          >14</a
        >]</span
      >. Tableau users more broadly must resort to voting systems to gather attention to accessibility issues&nbsp;<span
        class="citation"
        data-cites="demartini_tableau_nodate-1"
        >[<a
          href="#ref-demartini_tableau_nodate-1"
          id="demartini_tableau_nodate-101"
          aria-label="19, C. DeMartini"
          title="19, C. DeMartini"
          >19</a
        >]</span
      >. Semiotic’s accessibility features were added by community member Melanie Mazanec&nbsp;<span
        class="citation"
        data-cites="noauthor_semiotic_nodate"
        >[<a
          href="#ref-noauthor_semiotic_nodate"
          id="noauthor_semiotic_nodate01"
          aria-label="35, M. Mazanec"
          title="35, M. Mazanec"
          >35</a
        >]</span
      >. For Microsoft’s PowerBI, students have organized resources for how to make visualizations built with it more
      accessible&nbsp;<span class="citation" data-cites="noauthor_power_nodate"
        >[<a
          href="#ref-noauthor_power_nodate"
          id="noauthor_power_nodate01"
          aria-label="70, R. Klein"
          title="70, R. Klein"
          >70</a
        >]</span
      >
      while non-profits like the City of San Francisco’s data team have had to build features like keyboard instructions
      from scratch&nbsp;<span class="citation" data-cites="noauthor_covid-19_nodate"
        >[<a
          href="#ref-noauthor_covid-19_nodate"
          id="noauthor_covid-19_nodate01"
          aria-label="15, C. of San Francisco"
          title="15, C. of San Francisco"
          >15</a
        >]</span
      >. Mapbox GL JS is an example of a popular mapping library (over 400,000 weekly downloads)&nbsp;<span
        class="citation"
        data-cites="noauthor_mapbox-gl_nodate"
        >[<a
          href="#ref-noauthor_mapbox-gl_nodate"
          id="noauthor_mapbox-gl_nodate01"
          aria-label="12, Mapbox"
          title="12, Mapbox"
          >12</a
        >]</span
      >
      that has no built-in accessibility support by default. The accessibility module for Mapbox GL on GitHub was
      created and maintained by volunteers but has had less than 10 weeks of work with any activity invested since its
      first activity in late 2017&nbsp;<span class="citation" data-cites="noauthor_mapboxmapbox-gl-accessibility_2021"
        >[<a
          href="#ref-noauthor_mapboxmapbox-gl-accessibility_2021"
          id="noauthor_mapboxmapbox-gl-accessibility_202101"
          aria-label="71, Mapbox"
          title="71, Mapbox"
          >71</a
        >]</span
      >.
    </p>
    <p>
      Many community-driven efforts are under-utilized, must be discovered outside of the primary environment’s
      ecosystem, have poor or no core, internal support, and are inconsistently and partially implemented. Accessibility
      is still an afterthought in data visualization and ad-hoc, specific solutions proposed have not led to widespread
      improvements.
    </p>
    <h2 id="accessibility-in-practice-broadly">Accessibility in Practice, Broadly</h2>
    <p>
      Accessibility in practice is largely motivated by standards work or assistive technology. We want to acknowledge
      that tactile and braille standards are robust&nbsp;<span class="citation" data-cites="noauthor_guidelines_nodate"
        >[<a
          href="#ref-noauthor_guidelines_nodate"
          id="noauthor_guidelines_nodate11"
          aria-label="32, BANA"
          title="32, BANA"
          >32</a
        >]</span
      >, but have limited transferability to digital contexts currently. For example, whereas tactile graphics
      guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be
      embossed onto paper or similar physical mediums&nbsp;<span
        class="citation"
        data-cites="bigham_vizwiz_2010 lundgard_sociotechnical_2019 sharif_understanding_2021"
        >[<a
          href="#ref-bigham_vizwiz_2010"
          id="bigham_vizwiz_201001"
          aria-label="55, J. P. Bigham et al."
          title="55, J. P. Bigham et al."
          >55</a
        >,
        <a
          href="#ref-lundgard_sociotechnical_2019"
          id="lundgard_sociotechnical_201911"
          aria-label="18, A. Lundgard"
          title="18, A. Lundgard"
          >18</a
        >,
        <a
          href="#ref-sharif_understanding_2021"
          id="sharif_understanding_202121"
          aria-label="10, A. Sharif"
          title="10, A. Sharif"
          >10</a
        >]</span
      >.
    </p>
    <p>
      In digital contexts, the most influential body for accessibility is the World Wide Web Consortium’s (W3C) Web
      Accessibility Initiative (WAI). WAI’s Web Content Accessibility Guidelines (WCAG)&nbsp;<span
        class="citation"
        data-cites="noauthor_web_nodate"
        >[<a
          href="#ref-noauthor_web_nodate"
          id="noauthor_web_nodate11"
          aria-label="20, W. A. Initiative"
          title="20, W. A. Initiative"
          >20</a
        >]</span
      >
      influence accessible technology policy and law for more than 55% of the world’s population&nbsp;<span
        class="citation"
        data-cites="initiative_wai_web_2021"
        >[<a
          href="#ref-initiative_wai_web_2021"
          id="initiative_wai_web_202101"
          aria-label="8, W. A. Initiative"
          title="8, W. A. Initiative"
          >8</a
        >]</span
      >. WAI and WCAG outline 4 types of functional accessibility principles: Perceivable, Operable, Understandable, and
      Robust, abbreviated as POUR&nbsp;<span class="citation" data-cites="initiative_wai_accessibility_nodate"
        >[<a
          href="#ref-initiative_wai_accessibility_nodate"
          id="initiative_wai_accessibility_nodate11"
          aria-label="52, WAI"
          title="52, WAI"
          >52</a
        >]</span
      >. POUR is the foundation that organizes all 78 accessibility testing criteria in WCAG.
    </p>
    <h2 id="using-heuristics-to-break-into-under-addressed-areas">
      Using Heuristics to Break Into Under-addressed Areas
    </h2>
    <p>
      To summarize the complex problem space to which this paper contributes: Research in data visualization primarily
      focuses on visual accessibility, accessibility standards focus on a broad range of disabilities but lack deep
      contextualization for data visualization, and practitioners seem to build a wide array of solutions to fill these
      gaps, most of which are poorly maintained or adopted. Any time a practitioner wants to embark on a journey
      learning how to evaluate the accessibility of a data visualization, they must collect and synthesize this complex
      space of knowledge themselves. We have included (with permission) an exemplary field artifact as an example of
      this type of labor in our supplemental materials, which contributed to the United States Government’s project,
      “Improving Accessibility in Data Visualizations”&nbsp;<span
        class="citation"
        data-cites="noauthor_improving_nodate noauthor_data_nodate"
        >[<a
          href="#ref-noauthor_improving_nodate"
          id="noauthor_improving_nodate01"
          aria-label="96, US Government"
          title="96, US Government"
          >96</a
        >,
        <a
          href="#ref-noauthor_data_nodate"
          id="noauthor_data_nodate01"
          aria-label="95, US Government"
          title="95, US Government"
          >95</a
        >]</span
      >.
    </p>
    <p>
      After gathering information with this breadth and complexity, a heuristic evaluation model was chosen as a way to
      deliver useful but flexible knowledge. Heuristic evaluation models have a long history in HCI and are cheap to use
      and require little expertise. They have been shown to be effective methods for practitioners compared to user
      testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment,
      moderation, and compensation of participants&nbsp;<span
        class="citation"
        data-cites="martinez_methodology_2021 chuan_usability_2015 brangier_beyond_2018 experience_10_nodate joyce_mobile_2016 nielsen_heuristic_1994 otey_methodology_2017 santos_heuristic_2018 slavkovic_novice_1999 noauthor_unlocking_2018"
        >[<a
          href="#ref-martinez_methodology_2021"
          id="martinez_methodology_202111"
          aria-label="43, R. A. Martínez"
          title="43, R. A. Martínez"
          >43</a
        >,
        <a
          href="#ref-chuan_usability_2015"
          id="chuan_usability_201501"
          aria-label="9, N. K. Chuan"
          title="9, N. K. Chuan"
          >9</a
        >,
        <a
          href="#ref-brangier_beyond_2018"
          id="brangier_beyond_201801"
          aria-label="72, E. Brangier"
          title="72, E. Brangier"
          >72</a
        >,
        <a
          href="#ref-experience_10_nodate"
          id="experience_10_nodate01"
          aria-label="74, J. Nielsen"
          title="74, J. Nielsen"
          >74</a
        >,
        <a href="#ref-joyce_mobile_2016" id="joyce_mobile_201601" aria-label="78, G. Joyce" title="78, G. Joyce">78</a>,
        <a
          href="#ref-nielsen_heuristic_1994"
          id="nielsen_heuristic_199401"
          aria-label="75, J. Nielsen"
          title="75, J. Nielsen"
          >75</a
        >,
        <a
          href="#ref-otey_methodology_2017"
          id="otey_methodology_201701"
          aria-label="77, D. Q. Otey"
          title="77, D. Q. Otey"
          >77</a
        >,
        <a
          href="#ref-santos_heuristic_2018"
          id="santos_heuristic_201801"
          aria-label="79, B. S. Santos"
          title="79, B. S. Santos"
          >79</a
        >,
        <a
          href="#ref-slavkovic_novice_1999"
          id="slavkovic_novice_199901"
          aria-label="76, A. Slavkovic and K. Cross"
          title="76, A. Slavkovic and K. Cross"
          >76</a
        >,
        <a
          href="#ref-noauthor_unlocking_2018"
          id="noauthor_unlocking_201801"
          aria-label="73, D. Boudreau"
          title="73, D. Boudreau"
          >73</a
        >]</span
      >. Heuristics are also not new in visualization&nbsp;<span
        class="citation"
        data-cites="forsell_heuristic_2010 craft_beyond_2005 oliveira_adapting_2022 scholtz_developing_2011"
        >[<a
          href="#ref-forsell_heuristic_2010"
          id="forsell_heuristic_201001"
          aria-label="103, C. Forsell and J. Johansson"
          title="103, C. Forsell and J. Johansson"
          >103</a
        >,
        <a
          href="#ref-craft_beyond_2005"
          id="craft_beyond_200501"
          aria-label="102, B. Craft and P. Cairns"
          title="102, B. Craft and P. Cairns"
          >102</a
        >,
        <a
          href="#ref-oliveira_adapting_2022"
          id="oliveira_adapting_202201"
          aria-label="101, M. Oliveira and C. Guimarães da Silva"
          title="101, M. Oliveira and C. Guimarães da Silva"
          >101</a
        >,
        <a
          href="#ref-scholtz_developing_2011"
          id="scholtz_developing_201101"
          aria-label="99, J. Scholtz"
          title="99, J. Scholtz"
          >99</a
        >]</span
      >
      even among topics related to accessibility (color vision deficiency, specifically)&nbsp;<span
        class="citation"
        data-cites="santos_heuristic_2018 oliveira_towards_2013"
        >[<a
          href="#ref-santos_heuristic_2018"
          id="santos_heuristic_201811"
          aria-label="79, B. S. Santos"
          title="79, B. S. Santos"
          >79</a
        >,
        <a
          href="#ref-oliveira_towards_2013"
          id="oliveira_towards_201311"
          aria-label="59, M. M. Oliveira"
          title="59, M. M. Oliveira"
          >59</a
        >]</span
      >.
    </p>
    <h1 id="making-chartability">Making Chartability</h1>
    <p>
      We next present Elavsky’s work to develop Chartability as a real-world design process contribution to the larger
      research community. Our making process does not neatly fit into most design models that divide researchers from
      practitioners. In Gray’s different models of practitioner-researcher relations, our work is some variation of
      bubble-up, practitioner-led research&nbsp;<span class="citation" data-cites="gray_reprioritizing_2014"
        >[<a
          href="#ref-gray_reprioritizing_2014"
          id="gray_reprioritizing_201401"
          aria-label="105, C. M. Gray"
          title="105, C. M. Gray"
          >105</a
        >]</span
      >. This project was initiated by Elavsky while they were an industry practitioner, deeply situated in this work
      already.
    </p>
    <p>
      Thus, the following description of Chartability’s 10-month creation is written from Elavsky’s perspective. The
      supplemental materials include the data from this stage of the process, a preview of which is available in
      <a href="#tab:table" data-reference-type="autoref" data-reference="tab:table">[tab:table]</a>:
    </p>
    <ol>
      <li>
        <p>
          <strong>Situate, Survey, and Select Problem Space</strong>: I was situated within the context of accessibility
          evaluations of data visualizations. From personal experience, I recognized the prohibitively significant labor
          involved in ensuring I was effectively following accessibility standards while also attending to the complex
          design considerations of data visualizations. To improve this work both for myself and others in the future, I
          surveyed existing problems and challenges others faced and selected a solution that I felt equipped to
          address.
        </p>
      </li>
      <li>
        <p>
          <strong>Collect Existing Resources</strong>: I set out to answer, “If evaluating the accessibility of data
          experiences is hard, what do existing standards miss?” I evaluated my seed knowledge (WCAG criteria) for
          shortcomings and gaps and collected other data relevant to my goal (academic and industry research,
          open-source libraries, tools, applications, data products, government guidelines, design guidelines, software
          documentation, university coursework, and practitioner articles).
        </p>
      </li>
      <li>
        <p>
          <strong>Code Resources</strong>: After collating these resources (including relevant WCAG criteria), I loosely
          borrowed from thematic analysis&nbsp;<span class="citation" data-cites="braun_clarke_thematic_2006"
            >[<a
              href="#ref-braun_clarke_thematic_2006"
              id="braun_clarke_thematic_200601"
              aria-label="100, V. Braun and V. Clarke"
              title="100, V. Braun and V. Clarke"
              >100</a
            >]</span
          >
          and qualitatively coded this data. I developed a set of 29 codes starting with WCAG’s POUR principles and
          expanded the codes to account for other concerns that came up in the resources, including what type of
          accessibility was being addressed (e.g., cognitive, visual), whether a solution was technology-specific or
          agnostic, and other categories (like “time-consuming” or “user-controlled”). I then divided the resources into
          codable segments with relatively distinct pieces of information and applied the 29 codes to the information
          segments. I grouped information with codes in common, resulting in a representative 45 groups of related
          information segments.
        </p>
      </li>
      <li>
        <p>
          <strong>Synthesize Heuristics</strong>: Since auditing depends on measurable heuristics, I adjusted each of
          the 45 groupings that resulted from the qualitative analysis into phrasing that could be verified by an
          evaluation. I then augmented each heuristic with known testing procedures, resources, and tools necessary for
          applying them in practice. 10 critical heuristics (these were determined top priorities through user feedback)
          are previewed in
          <a href="#tab:table" data-reference-type="autoref" data-reference="tab:table">[tab:table]</a>, with the full
          version of this table (and more) provided in our supplemental materials.
        </p>
      </li>
      <li>
        <p>
          <strong>Group Heuristics into Higher-level Principles</strong>: I linked each heuristic with relevant web
          accessibility standards and POUR principles to draw a familiar connection for users who might already be
          accessibility practitioners. 26 heuristics fit neatly back into Perceivable, Operable, Understandable, or
          Robust.
        </p>
      </li>
      <li>
        <p>
          <strong>Develop Remaining Themes into New Principles</strong>: 19 remaining heuristics with complex codes and
          overlapping groups demanded new theorizing, as they either did not fit into POUR at all or could arguably
          belong to multiple principles at once. I analyzed these remaining complex heuristics and for similarities and
          organized them under 3 new themes, which we are contributing as new accessibility principles, Compromising,
          Assistive, and Flexible, defined below.
        </p>
      </li>
    </ol>
    <div id="tab:table">
      <table>
        <caption>
          Previewing Chartability’s 10 Critical Heuristics<br />
          <br />
          (Coding Categories are broken into two sections: first which POUR principles contributed to the heuristic
          while “Other” refers to how many additional coding categories were assigned.)
        </caption>
        <tbody>
          <tr class="odd">
            <td style="text-align: left"></td>
            <td style="text-align: left"></td>
            <td style="text-align: left"></td>
            <td colspan="2" style="text-align: left">Coding Categories</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">Heuristic Title</td>
            <td style="text-align: left">Principle</td>
            <td style="text-align: left">Origin</td>
            <td style="text-align: left">POUR</td>
            <td style="text-align: left">Other</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">Low contrast</td>
            <td style="text-align: left">Perceivable</td>
            <td style="text-align: left">Standard</td>
            <td style="text-align: left">P</td>
            <td style="text-align: left">2</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">Small text</td>
            <td style="text-align: left">Perceivable</td>
            <td style="text-align: left">Research</td>
            <td style="text-align: left">P</td>
            <td style="text-align: left">2</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">Content is only visual</td>
            <td style="text-align: left">Perceivable</td>
            <td style="text-align: left">Standard</td>
            <td style="text-align: left">P, R</td>
            <td style="text-align: left">3</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">Interaction has only one input</td>
            <td style="text-align: left">Operable</td>
            <td style="text-align: left">Standard</td>
            <td style="text-align: left">O, R</td>
            <td style="text-align: left">3</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">No interaction cues/instructions</td>
            <td style="text-align: left">Operable</td>
            <td style="text-align: left">Standard</td>
            <td style="text-align: left">O, U</td>
            <td style="text-align: left">2</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">No explanation for how to read</td>
            <td style="text-align: left">Understandable</td>
            <td style="text-align: left">Research</td>
            <td style="text-align: left">U</td>
            <td style="text-align: left">1</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">No title, summary, or caption</td>
            <td style="text-align: left">Understandable</td>
            <td style="text-align: left">Research</td>
            <td style="text-align: left">U</td>
            <td style="text-align: left">1</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">No table</td>
            <td style="text-align: left">Compromising</td>
            <td style="text-align: left">Research</td>
            <td style="text-align: left">O, U, R</td>
            <td style="text-align: left">3</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">Data density inappropriate</td>
            <td style="text-align: left">Assistive</td>
            <td style="text-align: left">Research</td>
            <td style="text-align: left">P, U</td>
            <td style="text-align: left">4</td>
          </tr>
          <tr class="even">
            <td style="text-align: left">User style change not respected</td>
            <td style="text-align: left">Flexible</td>
            <td style="text-align: left">Standard</td>
            <td style="text-align: left">P, O, R</td>
            <td style="text-align: left">6</td>
          </tr>
          <tr class="odd">
            <td style="text-align: left">... +35 non-Critical heuristics</td>
            <td style="text-align: left"></td>
            <td style="text-align: left"></td>
            <td style="text-align: left"></td>
            <td style="text-align: left"></td>
          </tr>
        </tbody>
      </table>
    </div>
    <h2 id="compromising">Compromising</h2>
    <p>
      Compromising is a principle that focuses on Understandable, yet Robust heuristics. These heuristics are based on
      providing alternative, transparent, tolerant, information flows with consideration for different ways that users
      of assistive technologies and users with disabilities need to consume information.
    </p>
    <p>
      Compromising challenges designs that only allow access to information through limited or few interfaces or
      processes. These heuristics focus on providing information at a low and high level (such as tables and summaries),
      transparency about the state of complex interactions, error tolerance, and that data structures can be navigated
      according to their presentation. Compromising designs have both information and system redundancies in place.
    </p>
    <h2 id="assistive">Assistive</h2>
    <p>
      Assistive is a principle that primarily builds off the intersection of Understandable and Perceivable principles
      but focuses on the labor involved in access. These heuristics include categories that encourage data interfaces to
      be intelligent and multi-sensory in a way that reduces the cognitive and functional labor required of the user as
      much as possible.
    </p>
    <p>
      The Assistive principle focuses on what Swan <span>et&nbsp;al</span> refer to as “adding value”&nbsp;<span
        class="citation"
        data-cites="noauthor_inclusive_nodate"
        >[<a
          href="#ref-noauthor_inclusive_nodate"
          id="noauthor_inclusive_nodate01"
          aria-label="81, H. Swan"
          title="81, H. Swan"
          >81</a
        >]</span
      >
      and what Doug Schepers meant by “data visualization is an assistive technology”&nbsp;<span
        class="citation"
        data-cites="noauthor_why_nodate"
        >[<a
          href="#ref-noauthor_why_nodate"
          id="noauthor_why_nodate01"
          aria-label="54, D. Schepers"
          title="54, D. Schepers"
          >54</a
        >]</span
      >. We visualize because it is faster and more efficient than munging cell at a time through data. Assistive
      heuristics ensure that both visual and non-visual data representations add value for people with disabilities.
    </p>
    <h2 id="flexible">Flexible</h2>
    <p>
      Contrasted with Compromising (which focuses on robust understanding), flexible heuristics focus on robust user
      agency and the ability to adjust the Perceivable and Operable traits of a data experience. Flexible heuristics all
      have a tight coupling between a data experience and the larger technological context the user inhabits. The
      preferences that a user sets in lower-level systems must be respected in higher level environments.
    </p>
    <p>
      Self-advocacy and interdependent agency are important sociotechnical considerations that engage the conflicting
      access needs that different users might have in complex technological interactions like data
      experiences&nbsp;<span class="citation" data-cites="bennett_interdependence_2018 mankoff_disability_2010"
        >[<a
          href="#ref-bennett_interdependence_2018"
          id="bennett_interdependence_201801"
          aria-label="30, C. L. Bennett"
          title="30, C. L. Bennett"
          >30</a
        >,
        <a
          href="#ref-mankoff_disability_2010"
          id="mankoff_disability_201001"
          aria-label="42, J. Mankoff"
          title="42, J. Mankoff"
          >42</a
        >]</span
      >. Some users might want specific controls or presentation, while others might want something else entirely.
      Designs must not be rigid in their opinions and ability assumptions and should be designed to be moldable by and
      adaptive to user needs&nbsp;<span class="citation" data-cites="wobbrock_ability-based_2011 ladner_design_2015"
        >[<a
          href="#ref-wobbrock_ability-based_2011"
          id="wobbrock_ability-based_201101"
          aria-label="82, J. O. Wobbrock"
          title="82, J. O. Wobbrock"
          >82</a
        >,
        <a
          href="#ref-ladner_design_2015"
          id="ladner_design_201501"
          aria-label="104, R. E. Ladner"
          title="104, R. E. Ladner"
          >104</a
        >]</span
      >.
    </p>
    <h1 id="using-chartability">Using Chartability</h1>
    <p>
      All of Chartability’s tests are performed using Chartability’s workbook&nbsp;<span
        class="citation"
        data-cites="noauthor_chartability_nodate"
        >[<a
          href="#ref-noauthor_chartability_nodate"
          id="noauthor_chartability_nodate01"
          aria-label="80, F. Elavsky"
          title="80, F. Elavsky"
          >80</a
        >]</span
      >
      alongside various tools and software (linked in the workbook). For the scope of this paper, we are not including
      an explanation for how to perform all of these. Both the workbook and supplementary materials with this paper give
      more details.
    </p>
    <p>
      While a highly trained auditor may be able to casually evaluate an artifact in as little as 30 minutes or even
      hold heuristics in mind as they are doing their own creative work, those new to auditing may take anywhere between
      2 and 8 hours to complete a full pass of Chartability. Professional audits, which can take weeks or months, often
      include multiple auditors and provide rigorous documentation and detailed recommendations for remediation,
      typically in the form of a report. Chartability is meant to serve both quick pass and deep dive styles of audits,
      so users are expected to leverage it as they see fit.
    </p>
    <p>
      Below we give an example of what might be a quick pass audit, using Chartability. Which principles are applied in
      each of these stages are listed in parentheses in each heading.
    </p>
    <h2 id="visual-testing-perceivable">Visual Testing (Perceivable)</h2>
    <figure>
      <img
        src="figures/figure 2.png"
        id="fig:2"
        alt="A low contrast chart (left) compared to a higher contrast version (right). A dropper tool is extracting the fill color of the bar and then a contrast ratio has been calculated. Note that the fill color is the same on both bars, but darker borders have been added to ensure the visualization passes contrast tests."
      />
      <figcaption aria-hidden="true">
        A low contrast chart (left) compared to a higher contrast version (right). A dropper tool is extracting the fill
        color of the bar and then a contrast ratio has been calculated. Note that the fill color is the same on both
        bars, but darker borders have been added to ensure the visualization passes contrast tests.
      </figcaption>
    </figure>
    <p>
      Checking for contrast is the most common critical failure; 87.5% of tests (7 out of 8) from our user study
      involving this heuristic failed, which supports the WebAim Million Report’s findings (83.9% of the top 1 million
      websites also fail contrast testing, more than any other WCAG criteria)&nbsp;<span
        class="citation"
        data-cites="noauthor_webaim_nodate"
        >[<a href="#ref-noauthor_webaim_nodate" id="noauthor_webaim_nodate01" aria-label="11, WebAIM" title="11, WebAIM"
          >11</a
        >]</span
      >. In order to evaluate contrast, often a combination of automatic (code-driven) and manual tooling is performed.
      When manually auditing, practitioners typically use a dropper and a contrast calculator (<a
        href="#fig:2"
        data-reference-type="autoref"
        data-reference="fig:2"
        >[fig:2]</a
      >). Most auditors find this to be one of the easiest tasks to perform and accomplishes 3 different heuristics in
      Chartability: ensuring text/geometries have contrast, interactive states for elements have enough contrast change,
      and the keyboard focus indicator is easy to distinguish.
    </p>
    <p>
      Perceivable heuristics also include tests and tools for color vision deficiency and ensuring that color alone
      isn’t used to communicate meaning (like the redundantly encoded textures in
      <a href="#fig:9" data-reference-type="autoref" data-reference="fig:9">[fig:9]</a>). And another common, critical
      failure from Perceivable is text size. No text should be smaller than 12px/9pt in size.
    </p>
    <figure>
      <img
        src="figures/figure 3.png"
        id="fig:3"
        alt="Keyboard navigation paths on a stacked bar chart. The left shows a serial navigation example, typically just a default of rendering order. The right shows both groups (the stack of bars) and categories (the color/texture shared among bars across stacks) as dimensions to explore laterally or vertically."
      />
      <figcaption aria-hidden="true">
        Keyboard navigation paths on a stacked bar chart. The left shows a serial navigation example, typically just a
        default of rendering order. The right shows both groups (the stack of bars) and categories (the color/texture
        shared among bars across stacks) as dimensions to explore laterally or vertically.
      </figcaption>
    </figure>
    <h2 id="keyboard-probing-operable-assistive">Keyboard Probing (Operable, Assistive)</h2>
    <p>
      The next practice that most auditors should become comfortable with is using a keyboard to navigate and operate
      any functionality that is provided. Most assistive technologies, from screen readers to a variety of input devices
      (like switches, joysticks, sip and puffs, etc) use the keyboard api (or keyboard interface) to navigate content.
      If a data interface contains interactive elements (<a
        href="#fig:3"
        data-reference-type="autoref"
        data-reference="fig:3"
        >[fig:3]</a
      >, <a href="#fig:4" data-reference-type="autoref" data-reference="fig:4">[fig:4]</a>), those elements (or their
      functionality) must be able to be reached and controlled using a keyboard alone. Auditors should be critical of
      how much work is involved in keyboard navigation, especially (<a
        href="#fig:8"
        data-reference-type="autoref"
        data-reference="fig:8"
        >[fig:8]</a
      >). All that is required to start is the auditor begins pressing the tab key to see if anything interactive comes
      into focus. Arrow keys, spacebar, enter, and escape may be used in some contexts. Generally, instructions or cues
      should always be provided.
    </p>
    <figure>
      <img
        src="figures/figure 4.png"
        id="fig:4"
        alt="A mouse cursor is selecting a bar (left, shown with a thick indication border) in a stacked bar chart to filter a dataset (on the right). A system alert (red box) notifies the user of their interaction result. This selection capability must also be provided for the keyboard interface and the alert must be announced to screen readers."
      />
      <figcaption aria-hidden="true">
        A mouse cursor is selecting a bar (left, shown with a thick indication border) in a stacked bar chart to filter
        a dataset (on the right). A system alert (red box) notifies the user of their interaction result. This selection
        capability must also be provided for the keyboard interface and the alert must be announced to screen readers.
      </figcaption>
    </figure>
    <p>
      Using a keyboard provides an opportunity to evaluate many different heuristics: checking for multiple inputs (<a
        href="#fig:4"
        data-reference-type="autoref"
        data-reference="fig:4"
        >[fig:4]</a
      >), whether the data structure that is rendered is navigable according to its structure (<a
        href="#fig:3"
        data-reference-type="autoref"
        data-reference="fig:3"
        >[fig:3]</a
      >), and whether keyboard navigability across all elements in a data interface is even necessary (<a
        href="#fig:8"
        data-reference-type="autoref"
        data-reference="fig:8"
        >[fig:8]</a
      >).
    </p>
    <h2 id="screen-reader-inspecting-perceivable-operable-robust-assistive">
      Screen Reader Inspecting (Perceivable, Operable, Robust, Assistive)
    </h2>
    <p>
      Closely related to keyboard testing is testing with a screen reader. Some things may work with a screen reader
      that do not with a keyboard (and vice versa), so both must be evaluated.
    </p>
    <figure>
      <img
        src="figures/figure 5.png"
        id="fig:5"
        alt="Charts must have a visually available textual explanation provided that summarizes the outcome. “Client Registration Chart” for “Product X” (left) is inaccessible while “New Product Launch a Success” (right) gives a clear takeaway."
      />
      <figcaption aria-hidden="true">
        Charts must have a visually available textual explanation provided that summarizes the outcome. “Client
        Registration Chart” for “Product X” (left) is inaccessible while “New Product Launch a Success” (right) gives a
        clear takeaway.
      </figcaption>
    </figure>
    <p>
      Screen readers, unlike more basic keyboard input devices, read out content that is textual (including non-visual
      textual information like <em>alternative text</em>). Using a screen reader to audit is generally the hardest skill
      to learn. Keeping this in mind, testing whether the meaningful text provided in a visual (such as in
      <a href="#fig:5" data-reference-type="autoref" data-reference="fig:5">[fig:5]</a>) is accessible with a screen
      reader is the easiest and most basic test that auditors should first perform.
    </p>
    <figure>
      <img
        src="figures/figure 6.png"
        id="fig:6"
        alt="An interactive chart displaying only “Image” as semantic information with no feedback provided on selection. The robust semantics given to a screen reader, “toggle button” (middle) as well instant feedback, “selected” (right) are considered proper semantics for an interactive experience."
      />
      <figcaption aria-hidden="true">
        An interactive chart displaying only “Image” as semantic information with no feedback provided on selection. The
        robust semantics given to a screen reader, “toggle button” (middle) as well instant feedback, “selected” (right)
        are considered proper semantics for an interactive experience.
      </figcaption>
    </figure>
    <p>
      Next, all valuable information and functionality in a data experience should be tested whether it is available to
      a screen reader. This includes the individual variables about a mark as well as whether that mark is interactive
      (<a href="#fig:6" data-reference-type="autoref" data-reference="fig:6">[fig:6]</a>), whether status updates that
      reflect context change provide alerts (<a href="#fig:4" data-reference-type="autoref" data-reference="fig:4"
        >[fig:4]</a
      >), and whether summary textual information is provided about the whole chart (<a
        href="#fig:5"
        data-reference-type="autoref"
        data-reference="fig:5"
        >[fig:5]</a
      >) as well as statistically and visually important areas of that chart (<a
        href="#fig:8"
        data-reference-type="autoref"
        data-reference="fig:8"
        >[fig:8]</a
      >).
    </p>
    <figure>
      <img
        src="figures/figure 7.png"
        id="fig:7"
        alt="A line chart (left) with a single line and an accompanying data table (right). This line chart would not provide enough low-level information about each datapoint without the table provided. A table alone however would also be inaccessible. Providing both can satisfy conflicting accessibility needs for different audiences."
      />
      <figcaption aria-hidden="true">
        A line chart (left) with a single line and an accompanying data table (right). This line chart would not provide
        enough low-level information about each datapoint without the table provided. A table alone however would also
        be inaccessible. Providing both can satisfy conflicting accessibility needs for different audiences.
      </figcaption>
    </figure>
    <h2 id="checking-cognitive-barriers-understandable-compromising">
      Checking Cognitive Barriers (Understandable, Compromising)
    </h2>
    <p>
      First, auditing for cognitive barriers generally involves checking the reading level and clarity of all available
      text using analytical tools. But Chartability also requires that all charts have basic text that provides a
      visually-available textual description and takeaway (<a
        href="#fig:5"
        data-reference-type="autoref"
        data-reference="fig:5"
        >[fig:5]</a
      >). This alone is one of the most important things to check for. In complex cases where a chart has a visual
      feature with an assumedly obvious takeaway, checking for annotations or textual callouts is important to help
      avoid interpretive issues&nbsp;<span class="citation" data-cites="xiong_curse_2020"
        >[<a href="#ref-xiong_curse_2020" id="xiong_curse_202001" aria-label="94, C. Xiong" title="94, C. Xiong">94</a
        >]</span
      >
      (<a href="#fig:8" data-reference-type="autoref" data-reference="fig:8">[fig:8]</a>).
    </p>
    <figure>
      <img
        src="figures/figure 8.png"
        id="fig:8"
        alt="A scatterplot with many points, where a single point within the chart can be accessed by a screen reader (left). Navigating this data piece by piece is unnecessarily tedious, so an annotation callout is provided to help the reader focus on an outlier cluster (right). The callout is being accessed by a screen reader, which is displaying the annotation’s summary as well."
      />
      <figcaption aria-hidden="true">
        A scatterplot with many points, where a single point within the chart can be accessed by a screen reader (left).
        Navigating this data piece by piece is unnecessarily tedious, so an annotation callout is provided to help the
        reader focus on an outlier cluster (right). The callout is being accessed by a screen reader, which is
        displaying the annotation’s summary as well.
      </figcaption>
    </figure>
    <h2 id="evaluating-context-robust-assistive-flexible">Evaluating Context (Robust, Assistive, Flexible)</h2>
    <p>
      The final series of checks an auditor should make involve thinking about the overall work in a design (as it
      intersects with other considerations) as well as the larger technical context where the user is situated.
    </p>
    <p>
      Auditors should first try to change system settings (such as toggling high contrast modes) to see whether a data
      experience respects these settings (<a href="#fig:9" data-reference-type="autoref" data-reference="fig:9"
        >[fig:9]</a
      >), run automatic semantic evaluations as well as manually check for appropriate meaning (<a
        href="#fig:6"
        data-reference-type="autoref"
        data-reference="fig:6"
        >[fig:6]</a
      >), and check if dense or highly complex visuals have sonified, tactile, or textual summaries available (<a
        href="#fig:8"
        data-reference-type="autoref"
        data-reference="fig:8"
        >[fig:8]</a
      >). Auditors should also check whether system updates provide clear feedback textually (<a
        href="#fig:4"
        data-reference-type="autoref"
        data-reference="fig:4"
        >[fig:4]</a
      >) as well as checking if there are both high and low level representations of information available (<a
        href="#fig:7"
        data-reference-type="autoref"
        data-reference="fig:7"
        >[fig:7]</a
      >).
    </p>
    <figure>
      <img
        src="figures/figure 9.png"
        id="fig:9"
        alt="A bar chart with categories (left) shown not conforming to Windows High Contrast White Mode. High contrast mode on Windows requires limiting color palettes, using only black or white for most elements (shown on the right)."
      />
      <figcaption aria-hidden="true">
        A bar chart with categories (left) shown not conforming to Windows High Contrast White Mode. High contrast mode
        on Windows requires limiting color palettes, using only black or white for most elements (shown on the right).
      </figcaption>
    </figure>
    <p>
      Auditors should be especially critical of static designs, such as those that either use textures by default or not
      (<a href="#fig:9" data-reference-type="autoref" data-reference="fig:9">[fig:9]</a>), which are a high risk of
      compromising and assistive failure.
    </p>
    <h1 id="validating-chartability">Validating Chartability</h1>
    <p>
      Next, Elavsky explains the preliminary user evaluation: I validated whether data practitioners felt more confident
      and equipped to make their own work accessible with Chartability. Additionally, I also wanted to interview expert
      accessibility practitioners (including those with disabilities) with the same questions, to see if Chartability
      had anything to offer in helping them understand and evaluate data experiences better.
    </p>
    <p>
      My secondary goal was to present a tool that can be helpful even in the wild on real projects (with all the weird
      design and engineering quirks that come with that). I wanted Chartability to be usable on things built with a tool
      like Tableau and fully bespoke, hand-coded visualizations, like those made with JavaScript and D3. To this
      secondary aim, I intentionally solicited participants who were working on a variety of different projects, each of
      their own design.
    </p>
    <h2 id="pre-validations-and-flipped-roles-participants-question-me">
      Pre-Validations and Flipped Roles: Participants Question <em>Me</em>
    </h2>
    <p>
      I performed several early, light validations of my work before soliciting and involving participants formally. My
      early pre-validations #2-4 (below) all focused on practitioners asking me questions and giving feedback.
    </p>
    <p>
      My 4 pre-validations happened during the process of making Chartability, as well as introducing short iterations
      back into the making process:
    </p>
    <ol>
      <li>
        <p>
          <strong>Beta Testing</strong>: I performed several beta tests of Chartability during the process of making. I
          audited using versions that only had POUR principles, tried versions of Chartability that focused only on
          standards, and also tried out different iterations of the heuristics as I was forming them. This testing was
          important to perform early in the process because it helped me test the limits of various possible directions
          for this tool (standards-only, against standards, building off of standards, etc).
        </p>
      </li>
      <li>
        <p>
          <strong>Early Advice</strong>: After the first full pass of making Chartability was complete, I sent
          Chartability via email to 4 accessibility experts and 6 interested people with disabilities familiar with
          auditing in order to solicit open feedback.
        </p>
      </li>
      <li>
        <p>
          <strong>Professional Workshop</strong>: I held a half-day professional workshop via zoom on auditing
          visualizations for accessibility and presented Chartability’s heuristics to this select audience of 50
          participants. I demonstrated how to audit and then had a chance for feedback and questions.
        </p>
      </li>
      <li>
        <p>
          <strong>Deep Feedback Session</strong>: I presented Chartability to 14 experts on data visualization and
          accessibility, 5 of which are people with disabilities. I presented in two separate sessions through 2-hour
          video calls on zoom (roughly one hour was demonstration and one hour was discussion).
        </p>
      </li>
    </ol>
    <h2 id="sec:critical heuristics">Discovering “Critical” Heuristics</h2>
    <p>
      These pre-validations helped me combine and divide some of the heuristics, adjust the language and phrasing, and
      label 10 specific tests as “Critical,” which can be seen in
      <a href="#tab:table" data-reference-type="autoref" data-reference="tab:table">[tab:table]</a>. These critical
      tests were ones that community members stressed as an important priority for one or more of the following reasons:
    </p>
    <ul>
      <li><p>They are prohibitively expensive to fix late.</p></li>
      <li><p>The barriers they produce are too significant to ignore.</p></li>
      <li><p>They are among the most common type of accessibility failure.</p></li>
      <li><p>They affect many parts of a data experience.</p></li>
    </ul>
    <p>All Critical heuristics are based on standards or research.</p>
    <h2 id="selecting-participants-and-projects">Selecting Participants and Projects</h2>
    <p>
      I was a practitioner and representing myself as a volunteer when I reached out to participants. At this stage in
      the project, I was still not affiliated with a research institution and was not interested in producing
      publishable knowledge. I intended to test Chartability in the wild and validate whether it achieved its aims. My
      priority was to collaborate with folks working on difficult problems or those who had a rare intersection of
      expertise between accessibility standards and interactive data experiences. To this end, I was highly permissive
      with potential collaborators in order to maximize the expertise of participants and breadth of environments for
      testing Chartability.
    </p>
    <p>
      However, part of being permissive with participants meant that I was willing to collaborate on projects that I
      cannot share in a research publication and many of my participants must remain anonymous (including interview
      results that contain sensitive information about intellectual property). Given that auditing is a field of work
      about identifying failures, there was both a high demand for participation in the evaluation of Chartability in
      tension with a low motivation to make these failures known in a public venue.
    </p>
    <p>A summary of our selection process:</p>
    <ul>
      <li>
        <p>
          <strong>Solicitation</strong>: I reached out via email to 24 individuals in my network to participate in
          helping to evaluate Chartability. I mentioned that I wanted Chartability to be applied to a current project of
          theirs and was interested in performing some interviews about their experience before and after using
          Chartability. I mentioned up front that working with me would be uncompensated and potentially take multiple
          hours of their time (even multiple sessions) over zoom meetings.
        </p>
      </li>
      <li>
        <p>
          <strong>Response</strong>: 16 individuals were interested and shared their project details (2 would require an
          NDA to be signed).
        </p>
      </li>
      <li>
        <p>
          <strong>Selection</strong>: I selected 8, based either on the expertise of the individuals, on the robustness
          of their project, and/or on the opportunity to get feedback about Chartability in team environments (which I
          didn’t anticipate, but 3 of the 8 represented team efforts).
        </p>
      </li>
      <li>
        <p><strong>Resulting Group</strong>: I worked with 19 total participants across 8 environment spaces.</p>
      </li>
      <li>
        <p>
          <strong>Publishable Group</strong>: Due to intellectual property concerns, I can publish interview results
          from 6 participants and discuss the details of 4 audit environments.
        </p>
      </li>
    </ul>
    <p>
      <strong>Chris DeMartini</strong>: a multi-year Tableau Zen Master and recognized expert visualization
      practitioner. His dashboard of a coin flipping probability game dataset that he produced with his daughter was the
      subject of his audit&nbsp;<span class="citation" data-cites="noauthor_we_nodate"
        >[<a
          href="#ref-noauthor_we_nodate"
          id="noauthor_we_nodate01"
          aria-label="7, C. DeMartini"
          title="7, C. DeMartini"
          >7</a
        >]</span
      >. His audit only included criteria labelled Critical in Chartability (which involves only 10 tests instead of the
      full 45) and his dashboard failed 7 of them. A full audit was later conducted on Chris’s behalf. His full audit
      had a total 26 failures, 11 of which were considered non-applicable.<a
        href="#fn1"
        class="footnote-ref"
        id="fnref1"
        role="doc-noteref"
        ><sup>1</sup></a
      >
    </p>
    <p>
      <strong>Amber Thomas</strong>: a data storyteller and technologist credited on 30 of The Pudding’s visual essays.
      Amber has had a growing interest in accessibility challenges related to her line of work designing and developing
      state of the art, bespoke visual essays. Her article The Naked Truth was still in the early design and development
      stages when it was fully audited&nbsp;<span class="citation" data-cites="noauthor_naked_nodate"
        >[<a
          href="#ref-noauthor_naked_nodate"
          id="noauthor_naked_nodate01"
          aria-label="6, O. Amaka and A. Thomas"
          title="6, O. Amaka and A. Thomas"
          >6</a
        >]</span
      >. It failed 22 out of 45 tests, including 6 out of 10 criteria considered Critical. 6 tests were considered
      non-applicable.
    </p>
    <p>
      <strong>Sam</strong> (self-selected pseudonym): a recognized design practitioner in the visualization community
      who lives with disability. They were collaborating on an interactive data project that would be specifically made
      to be used by international participants with a broad spectrum of disabilities. Their interactive infographic
      failed 21 out of 45 tests, 5 of which were considered Critical. 10 tests were considered non-applicable.
    </p>
    <p>
      <strong>Øystein Moseng</strong>: Core Developer and Head of Accessibility of Highcharts. Øystein was interested in
      taking one of Highchart’s demo charts not specifically developed with accessibility features in mind&nbsp;<span
        class="citation"
        data-cites="noauthor_fixed_nodate"
        >[<a href="#ref-noauthor_fixed_nodate" id="noauthor_fixed_nodate01" aria-label="5, Highsoft" title="5, Highsoft"
          >5</a
        >]</span
      >
      and testing it against a full Chartability audit to see how it held up. The demo failed 13 out of 45 tests, 3 of
      which were Critical. 10 tests were considered non-applicable.
    </p>
    <p>
      <strong>Jennifer Zhang</strong>: a senior accessibility program manager at Microsoft with expertise working on
      enterprise data products.
    </p>
    <p>
      <strong>Ryan Shugart</strong>: a blind, screen reader user and disability subject matter expert at Microsoft who
      has a strong expertise in collaborative accessibility for interactive data systems.
    </p>
    <p>
      Both Shugart and Zhang were interested in applying Chartability internally and testing its effectiveness and
      potential with various projects. Their application and use of Chartability (including audits) are not available
      for publication, but their valuable interviews and evaluations are included with permission.
    </p>
    <h1 id="study-results">Study Results</h1>
    <p>I asked the 6 participants a series of qualitative and Likert-scale evaluation questions:</p>
    <ol>
      <li><p>Have you ever performed an audit of a data experience before?</p></li>
      <li>
        <p>What stage of production is your project in? Analysis, design, prototyping, development, maintenance?</p>
      </li>
      <li>
        <p>
          How confident are you in your ability to perform an audit of a data experience for accessibility issues? (1-5,
          1 being not confident at all, 5 being fully confident.)
        </p>
      </li>
      <li>
        <p>
          How difficult do you perceive auditing a data experience for accessibility issues is? (1-5, 1 being trivial, 5
          being very difficult.)
        </p>
      </li>
      <li>
        <p>
          (After using Chartability) How confident are you in your ability to perform an audit of a data experience for
          accessibility issues? (1-5, 1 being not confident at all, 5 being fully confident.)
        </p>
      </li>
      <li>
        <p>
          (After using Chartability) How difficult do you perceive auditing a data experience for accessibility issues
          is? (1-5, 1 being trivial, 5 being very difficult.)
        </p>
      </li>
      <li><p>(After using Chartability) Do you intend to continue using Chartability?</p></li>
    </ol>
    <p>
      Each of these questions had an open-ended question attached, “Is there anything else you would like to add?” Every
      participant provided additional input on questions 3 through 7.
    </p>
    <p>
      None of the 3 participants who only consider themselves expert data practitioners had performed an audit before.
      All 3 of them reported that they believed auditing to be easier and that they are more confident in their ability
      to evaluate the accessibility of data experiences after using Chartability.
    </p>
    <p>
      Of the 3 accessibility experts (all of whom have performed audits of data experiences before), their opinions on
      these measurements were unchanged after using Chartability. All 6 participants noted that they plan to use
      Chartability in their own work and would recommend it to their peers.
    </p>
    <p>Below we overview some of the key insights Elavsky received from the open ended responses.</p>
    <h2 id="real-access-has-more-considerations-than-colorblindness">
      Real Access has more Considerations than Colorblindness
    </h2>
    <p>
      Among the data practitioners, DeMartini wrote after his audit, “I have read a lot about color blindness and could
      provide meaningful feedback to visualization developers on that topic, but I have come to realize that
      accessibility is so much more than this and I basically didn’t really know where to start when it came to the true
      scope of accessibility.” He ended his qualitative feedback with, “I think this could be a great tool for the
      masses and really look forward to the impact it can possibly have on the (inaccessible) data visualizations which
      are being created in huge numbers these days.”
    </p>
    <h2 id="audits-are-slow-but-help-me-focus">Audits are Slow, but Help me Focus</h2>
    <p>
      Amber Thomas wrote, “It still takes a while to do a complete audit, but it’s not hard! For someone new to the
      space, all the possible options that can be used to make visualizations more accessible can be overwhelming.
      [Chartability] helped me to focus.” She finished her feedback with, “There aren’t really guidelines (at least to
      my knowledge) that exist to help data visualization creators to ensure their work is accessible… [Chartability]
      helps to direct users to the most common accessibility problems with straightforward questions. It really helps to
      narrow the focus and prioritize efforts.”
    </p>
    <h2 id="chartability-helps-me-remember-and-stay-consistent">Chartability Helps me Remember and Stay Consistent</h2>
    <p>
      Among the accessibility experts, Zhang wrote, “While I am skilled, depending on the day I might not remember
      everything I need to look at. I am more confident in consistency between different auditing sessions. For experts
      it’s a good reminder framework.” Moseng of Highcharts noted, “[Chartability] did a very good job of highlighting
      concerns that are often ignored or forgotten when auditing and designing/developing.” Shugart of Microsoft added
      along those lines, “I feel [Chartability] arranges a good set of questions in a user’s mind and makes it easier
      for them to determine if a visualization is accessible.”
    </p>
    <h2 id="access-is-an-experience-not-just-compliance">Access is an Experience, not just Compliance</h2>
    <p>
      Zhang offered insight into the design intention of Chartability, “[it is] clearly going for above compliance and
      focusing on a good experience.” Sam expressed their need to make an excellent accessibility experience, “I am not
      just worried about compliance, but I want to make something really good. Nothing seems to help you go beyond? This
      is better than WCAG, I can already tell.”
    </p>
    <h2 id="everyone-wants-more-evaluation-resources-and-tools">Everyone wants More Evaluation Resources and Tools</h2>
    <p>
      For constructive feedback, all the data experts noted that they wanted more resources and materials related to
      learning the skills needed to conduct an audit. Shugart and Moseng both noted that they hope for more tooling and
      (in some cases) automated tests that can take the burden off the auditor and streamline the design and development
      process (much like Axe-core&nbsp;<span class="citation" data-cites="noauthor_axe-core_2021"
        >[<a href="#ref-noauthor_axe-core_2021" id="noauthor_axe-core_202101" aria-label="4, Deque" title="4, Deque"
          >4</a
        >]</span
      >). They both also agreed that automation and tooling would help novice practitioners perform this work faster and
      with more confidence. 2 of the 3 mentioned wanting more examples of failures as well as accessible data
      experiences. Sam wrote that they felt Chartability was overwhelming at first, but after focusing on just the
      Critical items, the rest of the framework “became easier.”
    </p>
    <h2 id="experts-novices-will-struggle.-novices-this-was-so-helpful">
      Experts: “Novices will Struggle.” Novices: “This was so helpful”
    </h2>
    <p>
      The accessibility experts all unanimously agreed that Chartability is helpful to their own work, but they are
      unsure how accessibility novices would do. They all believe that more training and resources are needed to help
      people who are new, with one noting that Chartability could even be “overwhelming” to someone who has not been
      exposed to accessibility work before. All of the novices remarked that Chartability was “so helpful,” “made this
      work so much clearer than before,” and “made a lot of hard problems not as hard.”
    </p>
    <h2 id="what-about-auditors-with-disabilities">What about Auditors with Disabilities?</h2>
    <p>
      Shugart’s feedback was critical when discussing continuing to use Chartability, “I still feel as a screen reader
      user, the audit itself would have some unique challenges because I’d be missing a lot and would have problems
      determining things such as color.” He continued, “Auditing anything accessibility-wise as a screen reader user
      poses challenges because you don’t always know what you’re missing. In many cases there are workarounds to this
      but datavis is one area where this is really hard to do now.”
    </p>
    <h1 id="extended-results">Extended Results</h1>
    <p>
      Following calls to ensure accessibility work has practical benefits that exceed publications&nbsp;<span
        class="citation"
        data-cites="hurst_making_2013"
        >[<a
          href="#ref-hurst_making_2013"
          id="hurst_making_201301"
          aria-label="26, A. Hurst and S. Kane"
          title="26, A. Hurst and S. Kane"
          >26</a
        >]</span
      >, in April, 2021 Elavsky made Chartability openly available on Github. As new research and practices emerge and
      more community members get involved, Chartability will become an evolving artifact of consensus similar to
      existing standards bodies&nbsp;<span class="citation" data-cites="noauthor_w3c_nodate"
        >[<a href="#ref-noauthor_w3c_nodate" id="noauthor_w3c_nodate01" aria-label="97, WAI" title="97, WAI">97</a
        >]</span
      >.
    </p>
    <p>
      Projects like Turkopticon benefited from the discussion about how a community actually used their tool&nbsp;<span
        class="citation"
        data-cites="irani_turkopticon_13"
        >[<a
          href="#ref-irani_turkopticon_13"
          id="irani_turkopticon_1301"
          aria-label="98, L. C. Irani and M. S. Silberman"
          title="98, L. C. Irani and M. S. Silberman"
          >98</a
        >]</span
      >. In the same vein, we are happy to report some valuable findings from within this last year that we think
      demonstrate (in a pragmatic way) that Chartability has some merit:
    </p>
    <ul>
      <li>
        <p>
          <strong>It is living and growing</strong>: Chartability has received enough community feedback that it is now
          on Version 2, with more tests and background resources provided.
        </p>
      </li>
      <li>
        <p>
          <strong>People are talking about it</strong>: Chartability has been featured in 14 workshops, talks, and
          podcasts and at least 2 university courses.
        </p>
      </li>
      <li>
        <p>
          <strong>People are using it</strong>: Chartability has contributed to projects at Microsoft, Highcharts,
          Project Jupyter, Fizz Studio, FiveThirtyEight, Vega-Lite, UCLA, the City of San Francisco, the Missouri School
          of Journalism, a fortune 50 company, two Fortune 500 companies, and community groups (like MiR).
        </p>
      </li>
      <li>
        <p>
          <strong>It has breadth</strong>: Chartability has evaluated static and interactive data experiences made with
          Microsoft’s Excel and PowerBI, Tableau, JavaScript (D3, Vega-Lite, Highcharts, Visa Chart Components), Python
          (Altair, Bokeh, and matplotlib), R (ggplot2), as well as design sketches and low/medium-fidelity artifacts
          (Illustrator, Figma, Sketch).
        </p>
      </li>
    </ul>
    <p>
      When considering the analysis by Hurst and Kane about high abandonment rates in assistive technology,&nbsp;<span
        class="citation"
        data-cites="hurst_making_2013"
        >[<a
          href="#ref-hurst_making_2013"
          id="hurst_making_201311"
          aria-label="26, A. Hurst and S. Kane"
          title="26, A. Hurst and S. Kane"
          >26</a
        >]</span
      >
      we wanted to make sure that we created an artifact (assistive technology or otherwise) that would at least survive
      its first year of use in the real world.
    </p>
    <p>
      The greater community feedback as well as new research before and after open-sourcing Chartability has also led to
      5 new heuristics being added since our test users performed audits and gave evaluations. The current version of
      Chartability (v2) has a total of 50 heuristics.
    </p>
    <p>
      It is important to note that the work of Chartability did not begin and does not conclude with the publication of
      this manuscript. We want Chartability to become a living, community-driven effort that will adapt and grow as more
      resources, tools, and research become available.
    </p>
    <h1 id="discussion">Discussion</h1>
    <p>
      From our presentation of Chartability and a preliminary user evaluation with data visualization and accessibility
      practitioners, we learned that Chartability reduced the perception that working on accessibility is difficult and
      increased the confidence of those new to this work. Chartability shows promise as a useful framework for expert
      accessibility practitioners because it serves to produce consistency in contexts like the evaluation of
      dashboards, data science workflows, and other complex, data-driven interfaces.
    </p>
    <p>
      While our practitioners with novice accessibility experience were initially concerned about doing the audit
      correctly, most of their audit results were reasonably comparable with that of the authors (although their time to
      complete was much longer).
    </p>
    <p>
      We agree with experts that beyond Chartability, more resources are needed which provide examples of both
      inaccessible and accessible data visualizations as well as how to perform some of the more difficult parts of the
      auditing process (such as evaluating with a screen reader). We hope that keeping Chartability on GitHub will
      inspire future improvements to address this gap in examples, and will address future limitations, as we discover
      them.
    </p>
    <p>Chartability is a valuable tool for auditing. But we also hope that it can inspire researchers to:</p>
    <ol>
      <li>
        <p>
          Examine which heuristics (in our supplemental materials) could use more research attention, particularly those
          labelled “community practice.”
        </p>
      </li>
      <li>
        <p>
          Define constraints or requirements on novel projects, ensuring that new explorations still respects
          established standards, mitigating ethical risks.
        </p>
      </li>
      <li>
        <p>
          Explore the intersections of disability in ways yet unaddressed in standards, such as the strong overlaps
          between understandability and operability (like keyboard navigation patterns across a data structure) or
          conflicts in understandability and flexibility (how some users need redundant encodings on charts while others
          find this overwhelming).
        </p>
      </li>
      <li><p>Consider access barriers in data experiences beyond those related to visual perception.</p></li>
      <li>
        <p>
          Engage the relationship between labor and access in computing, such as developing more measurements that
          demonstrate the imbalance of time and effort expected of users with disabilities (even in systems considered
          to provide “equal” access) and ways to evaluate who is contributing to accessibility efforts in a project
          (core team members, contractors, or volunteers).
        </p>
      </li>
    </ol>
    <p>
      We also want to caution researchers who are considering developing heuristics or auditing tools for use in
      practitioner environments to consider the tradeoffs between evaluation in rich, authentic professional settings
      and concerns such as intellectual property and corporate branding. We were able to apply our work in rich and
      collaborative practitioner settings because we were permissive with our potential participants. However, much of
      this work exists behind closed doors, similar to the downsides of industry research settings. More work may need
      to be done in order to encourage rich, cross-industry research projects, such as helping to anonymize the content
      of intellectual property and not just participants, while retaining data and findings.
    </p>
    <h1 id="conclusion">Conclusion</h1>
    <p>
      The demand for accessible data experiences is long overdue. The Web Accessibility Initiative’s (WAI) Web Content
      Accessibility Guidelines (WCAG) are over 22 years old and yet little work has been done to synthesize this large
      body of existing accessibility standards with research and inclusive design principles relevant to the fields of
      data communication, data science, data analysis, and visualization. Chartability begins to address unique
      accessibility best practice gaps in these domains with specific heuristics. This synthesis is meant to empower
      researchers, analysts, designers, developers, editors, and accessibility specialists with a framework to audit the
      accessibility of data experiences, interfaces, and systems to produce more inclusive environments for users with
      disabilities. The goal of Chartability is to make this work easier in order to encourage practitioners to regard
      current practices and resources, some of which have existed for decades.
    </p>
    <p>
      In addition, Chartability opens the door to more work that remains to be explored in this space. Additional
      research is needed into many of the topic areas within Chartability’s heuristic principles (POUR+CAF) as well as
      resources, examples, and tools provided for practitioners to perform this work more confidently and efficiently.
    </p>
    <p>
      The changing landscape of visualization techniques and alternative interfaces (such as sonification and dynamic
      tactile graphics) may increase the demands for accessibility considerations in this space. The growing
      technological divide will become an even greater human rights issue as time moves on and we believe that tools
      like Chartability are necessary for the community of data practitioners to ensure they are including people with
      disabilities.
    </p>
    <h1 class="unnumbered" id="acknowledgements">Acknowledgements</h1>
    <p>
      First we want to thank our reviewers. This paper would not have found its core contribution without your help.
    </p>
    <p>
      We especially want to thank all the community members who helped contribute to improving Chartability during the
      making process as well as after we released (in no particular order): Liz Hare, Silvia Canelón, Léonie Watson,
      Emily Kund, Sarah Fossheim, Ted Gies, Larene Le Gassick, Melanie Mazanec, Amanda Makulec, Amy Cesal, and anonymous
      friends. We also want to thank all of our industry partners who are currently using Chartability.
    </p>
    <p>
      And lastly, special thanks to Doug Schepers of Fizz Studio for sponsoring Chartability and for your gracious
      encouragement, support, and feedback.
    </p>
    <section class="footnotes footnotes-end-of-document" role="doc-endnotes">
      <hr />
      <ol>
        <li id="fn1" role="doc-endnote">
          <p>
            “Non-applicable:” any test in the auditing process that that does not contain content relevant to the test,
            such as “Scrolling experiences cannot be adjusted or opted out of” for a visualization that does not a
            scrolling input control<span id="fnlabel" label="fnlabel"></span
            ><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a>
          </p>
        </li>
      </ol>
    </section>

    <div>
      <div id="refs" class="references csl-bib-body" role="doc-bibliography">
        <div id="ref-cdc_disability_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[1]</div>
          <div class="csl-right-inline">
            C. Okoro, N. Hollis, A. Cyrus, and S. Griffin-Blake,
            <span
              >“Prevalence of disabilities and health care access by disability status and type among adults — united
              states, 2016,”</span
            >
            <em>Centers for Disease Control and Prevention MMWR</em>, vol. 67, pp. 882–887, 2018, doi:
            <a href="https://doi.org/10.15585/mmwr.mm6732a3">10.15585/mmwr.mm6732a3</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#cdc_disability_201801"
                aria-label="Return to: 26% of people in the United States self-report living with at least one disability&nbsp;"
                title="Return to: 26% of people in the United States self-report living with at least one disability&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-9023497" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[2]</div>
          <div class="csl-right-inline">
            B. Lee, E. K. Choe, P. Isenberg, K. Marriott, and J. Stasko,
            <span>“Reaching broader audiences with data visualization,”</span>
            <em>IEEE Computer Graphics and Applications</em>, vol. 40, no. 2, pp. 82–90, 2020, doi:
            <a href="https://doi.org/10.1109/MCG.2020.2968244">10.1109/MCG.2020.2968244</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#902349701"
                aria-label="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                title="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-south_detecting_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[3]</div>
          <div class="csl-right-inline">
            L. South, D. Saffo, and M. Borkin,
            <span
              >“Detecting and <span>Defending</span> <span>Against</span> <span>Seizure</span>-<span>Inducing</span>
              <span>GIFs</span> in <span>Social</span> <span>Media</span>,”</span
            >
            OSF Preprints, Jan. 2021. doi:
            <a href="https://doi.org/10.31219/osf.io/4kgu6">10.31219/osf.io/4kgu6</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#south_detecting_202101"
                aria-label="Return to:  and seizure risk&nbsp;"
                title="Return to:  and seizure risk&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_axe-core_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[4]</div>
          <div class="csl-right-inline">
            Deque, <span>“Axe-core.”</span> Deque Systems Inc., Aug. 2021. Available:
            <a href="https://github.com/dequelabs/axe-core">https://github.com/dequelabs/axe-core</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_axe-core_202101"
                aria-label="Return to: Shugart and Moseng both noted that they hope for more tooling and (in some cases) automated tests that can take the burden off the auditor and streamline the design and development process (much like Axe-core&nbsp;"
                title="Return to: Shugart and Moseng both noted that they hope for more tooling and (in some cases) automated tests that can take the burden off the auditor and streamline the design and development process (much like Axe-core&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_fixed_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[5]</div>
          <div class="csl-right-inline">
            Highsoft, <span>“Fixed placement columns <span></span> <span>Highcharts</span>.com.”</span> Available:
            <a href="https://www.highcharts.com/demo/column-placement"
              >https://www.highcharts.com/demo/column-placement</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_fixed_nodate01"
                aria-label="Return to: : Core Developer and Head of Accessibility of Highcharts. Øystein was interested in taking one of Highchart’s demo charts not specifically developed with accessibility features in mind&nbsp;"
                title="Return to: : Core Developer and Head of Accessibility of Highcharts. Øystein was interested in taking one of Highchart’s demo charts not specifically developed with accessibility features in mind&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_naked_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[6]</div>
          <div class="csl-right-inline">
            O. Amaka and A. Thomas, <span>“The <span>Naked</span> <span>Truth</span>,”</span> <em>The Pudding</em>.
            Available:
            <a href="https://pudding.cool/2021/03/foundation-names">https://pudding.cool/2021/03/foundation-names</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_naked_nodate01"
                aria-label="Return to: Her article The Naked Truth was still in the early design and development stages when it was fully audited&nbsp;"
                title="Return to: Her article The Naked Truth was still in the early design and development stages when it was fully audited&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_we_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[7]</div>
          <div class="csl-right-inline">
            C. DeMartini, <span>“Coin flip game.”</span> <em>Tableau Software</em>. Available:
            <a href="https://public.tableau.com/views/CoinFlipGame/CoinFlipGame"
              >https://public.tableau.com/views/CoinFlipGame/CoinFlipGame</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_we_nodate01"
                aria-label="Return to: His dashboard of a coin flipping probability game dataset that he produced with his daughter was the subject of his audit&nbsp;"
                title="Return to: His dashboard of a coin flipping probability game dataset that he produced with his daughter was the subject of his audit&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-initiative_wai_web_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[8]</div>
          <div class="csl-right-inline">
            W. A. Initiative,
            <span>“Web <span>Accessibility</span> <span>Laws</span> &amp; <span>Policies</span>,”</span>
            <em>Web Accessibility Initiative (WAI)</em>. Aug. 2021. Available:
            <a href="https://www.w3.org/WAI/policies/">https://www.w3.org/WAI/policies/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#initiative_wai_web_202101"
                aria-label="Return to:  influence accessible technology policy and law for more than 55% of the world’s population&nbsp;"
                title="Return to:  influence accessible technology policy and law for more than 55% of the world’s population&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-chuan_usability_2015" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[9]</div>
          <div class="csl-right-inline">
            N. K. Chuan, A. Sivaji, and W. F. W. Ahmad,
            <span
              >“Usability <span>Heuristics</span> for <span>Heuristic</span> <span>Evaluation</span> of
              <span>Gestural</span> <span>Interaction</span> in <span>HCI</span>,”</span
            >
            in
            <em
              >Design, <span>User</span> <span>Experience</span>, and <span>Usability</span>: <span>Design</span>
              <span>Discourse</span></em
            >, 2015, pp. 138–148. doi:
            <a href="https://doi.org/10.1007/978-3-319-20886-2_14">10.1007/978-3-319-20886-2_14</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#chuan_usability_201501"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-sharif_understanding_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[10]</div>
          <div class="csl-right-inline">
            A. Sharif, S. S. Chintalapati, J. O. Wobbrock, and K. Reinecke,
            <span>“Understanding screen-reader users’ experiences with online data visualizations,”</span> 2021. doi:
            <a href="https://doi.org/10.1145/3441852.3471202">10.1145/3441852.3471202</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#sharif_understanding_202101"
                aria-label="Return to: , screen reader user experiences with digital, 2-D spatial representations, including data visualizations&nbsp;"
                title="Return to: , screen reader user experiences with digital, 2-D spatial representations, including data visualizations&nbsp;"
                >1</a
              >,
              <a
                href="#sharif_understanding_202111"
                aria-label="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                title="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                >2</a
              >,
              <a
                href="#sharif_understanding_202121"
                aria-label="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                title="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                >3</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_webaim_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[11]</div>
          <div class="csl-right-inline">
            WebAIM,
            <span
              >“<span>WebAIM</span>: <span>The</span> <span>WebAIM</span> <span>Million</span> - <span>An</span> annual
              accessibility analysis of the top 1,000,000 home pages.”</span
            >
            Available:
            <a href="https://webaim.org/projects/million/\#wcag">https://webaim.org/projects/million/\#wcag</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_webaim_nodate01"
                aria-label="Return to: Checking for contrast is the most common critical failure; 87.5% of tests (7 out of 8) from our user study involving this heuristic failed, which supports the WebAim Million Report’s findings (83.9% of the top 1 million websites also fail contrast testing, more than any other WCAG criteria)&nbsp;"
                title="Return to: Checking for contrast is the most common critical failure; 87.5% of tests (7 out of 8) from our user study involving this heuristic failed, which supports the WebAim Million Report’s findings (83.9% of the top 1 million websites also fail contrast testing, more than any other WCAG criteria)&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_mapbox-gl_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[12]</div>
          <div class="csl-right-inline">
            Mapbox, <span>“Mapbox-gl js,”</span> <em>npm</em>. Available:
            <a href="https://www.npmjs.com/package/mapbox-gl">https://www.npmjs.com/package/mapbox-gl</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_mapbox-gl_nodate01"
                aria-label="Return to: Mapbox GL JS is an example of a popular mapping library (over 400,000 weekly downloads)&nbsp;"
                title="Return to: Mapbox GL JS is an example of a popular mapping library (over 400,000 weekly downloads)&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_world_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[13]</div>
          <div class="csl-right-inline">
            W. H. Organization, <span>“World report on vision.”</span> Available:
            <a href="https://www.who.int/publications-detail-redirect/9789241516570"
              >https://www.who.int/publications-detail-redirect/9789241516570</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_world_nodate01"
                aria-label="Return to: Globally, the World Health Organization reports that 29% of the world lives with uncorrected or uncorrectable blindness, low vision, or moderate to severe visual impairment&nbsp;"
                title="Return to: Globally, the World Health Organization reports that 29% of the world lives with uncorrected or uncorrectable blindness, low vision, or moderate to severe visual impairment&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-hoang_tableaumagic_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[14]</div>
          <div class="csl-right-inline">
            T. Hoang, <span>“The <span>TableauMagic</span> <span>DataTables</span> <span>Extension</span>,”</span>
            <em>Toan Hoang</em>. Sep. 2018. Available:
            <a href="https://tableau.toanhoang.com/the-tableau-magic-datatables-extension-now-available/"
              >https://tableau.toanhoang.com/the-tableau-magic-datatables-extension-now-available/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#hoang_tableaumagic_201801"
                aria-label="Return to: For example, Tableau’s first accessible data table was built by a volunteer community member Toan Hong as an extension&nbsp;"
                title="Return to: For example, Tableau’s first accessible data table was built by a volunteer community member Toan Hong as an extension&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_covid-19_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[15]</div>
          <div class="csl-right-inline">
            C. of San Francisco,
            <span>“<span>COVID</span>-19 data and reports <span></span> <span>San</span> <span>Francisco</span>.”</span>
            Available:
            <a href="https://sf.gov/resource/2021/covid-19-data-and-reports"
              >https://sf.gov/resource/2021/covid-19-data-and-reports</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_covid-19_nodate01"
                aria-label="Return to:  while non-profits like the City of San Francisco’s data team have had to build features like keyboard instructions from scratch&nbsp;"
                title="Return to:  while non-profits like the City of San Francisco’s data team have had to build features like keyboard instructions from scratch&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-baker_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[16]</div>
          <div class="csl-right-inline">
            C. M. Baker, L. R. Milne, R. Drapeau, J. Scofield, C. L. Bennett, and R. E. Ladner,
            <span>“Tactile graphics with a voice,”</span> <em>ACM Trans. Access. Comput.</em>, vol. 8, no. 1, Jan. 2016,
            doi: <a href="https://doi.org/10.1145/2854005">10.1145/2854005</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#baker_201601"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-szpiro_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[17]</div>
          <div class="csl-right-inline">
            S. F. A. Szpiro, S. Hashash, Y. Zhao, and S. Azenkot,
            <span
              >“How people with low vision access computing devices: Understanding challenges and opportunities,”</span
            >
            in <em>Proceedings of the 18th international ACM SIGACCESS conference on computers and accessibility</em>,
            2016, pp. 171–180. doi: <a href="https://doi.org/10.1145/2982142.2982168">10.1145/2982142.2982168</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#szpiro_201601"
                aria-label="Return to: Blind and low vision people are often researched together, but in practice may use different assistive technologies (such as magnifiers and contrast enhancers) and have different interaction practices (such as a combination of sight, magnification, and screen reader use)&nbsp;"
                title="Return to: Blind and low vision people are often researched together, but in practice may use different assistive technologies (such as magnifiers and contrast enhancers) and have different interaction practices (such as a combination of sight, magnification, and screen reader use)&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-lundgard_sociotechnical_2019" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[18]</div>
          <div class="csl-right-inline">
            A. Lundgard, C. Lee, and A. Satyanarayan,
            <span
              >“Sociotechnical <span>Considerations</span> for <span>Accessible</span> <span>Visualization</span>
              <span>Design</span>,”</span
            >
            <em>2019 IEEE Visualization Conference (VIS)</em>, Sep. 2019, doi:
            <a href="https://doi.org/10.1109/VISUAL.2019.8933762">10.1109/VISUAL.2019.8933762</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#lundgard_sociotechnical_201901"
                aria-label="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                title="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                >1</a
              >,
              <a
                href="#lundgard_sociotechnical_201911"
                aria-label="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                title="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-demartini_tableau_nodate-1" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[19]</div>
          <div class="csl-right-inline">
            C. DeMartini,
            <span
              >“A <span>Tableau</span> <span>Accessibility</span> <span>Journey</span> - <span>Part</span>
              <span>IV</span> - <span>Keyboard</span> <span>Accessibility</span>,”</span
            >
            <em>DataBlick</em>. Available:
            <a
              href="https://www.datablick.com/blog/2021/8/10/a-tableau-accessibility-journey-part-iv-keyboard-accessibility"
              >https://www.datablick.com/blog/2021/8/10/a-tableau-accessibility-journey-part-iv-keyboard-accessibility</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#demartini_tableau_nodate-101"
                aria-label="Return to: Tableau users more broadly must resort to voting systems to gather attention to accessibility issues&nbsp;"
                title="Return to: Tableau users more broadly must resort to voting systems to gather attention to accessibility issues&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_web_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[20]</div>
          <div class="csl-right-inline">
            W. A. Initiative,
            <span
              >“Web <span>Content</span> <span>Accessibility</span> <span>Guidelines</span> (<span>WCAG</span>)
              2.1.”</span
            >
            Available: <a href="https://www.w3.org/TR/WCAG21/">https://www.w3.org/TR/WCAG21/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_web_nodate01"
                aria-label="Return to: Since our goal is to synthesize knowledge for practitioner accessibility work, we also acknowledge that some of these projects did not follow standards during their research project and in their output, such as using Web Content Accessibility Guidelines&nbsp;"
                title="Return to: Since our goal is to synthesize knowledge for practitioner accessibility work, we also acknowledge that some of these projects did not follow standards during their research project and in their output, such as using Web Content Accessibility Guidelines&nbsp;"
                >1</a
              >,
              <a
                href="#noauthor_web_nodate11"
                aria-label="Return to: WAI’s Web Content Accessibility Guidelines (WCAG)&nbsp;"
                title="Return to: WAI’s Web Content Accessibility Guidelines (WCAG)&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-sharif_evographs_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[21]</div>
          <div class="csl-right-inline">
            A. Sharif and B. Forouraghi,
            <span
              >“<span class="nocase">evoGraphs</span> — <span>A</span> <span class="nocase">jQuery</span> plugin to
              create web accessible graphs,”</span
            >
            in
            <em
              >2018 15th <span>IEEE</span> <span>Annual</span> <span>Consumer</span> <span>Communications</span>
              <span>Networking</span> <span>Conference</span> (<span>CCNC</span>)</em
            >, Jan. 2018, pp. 1–4. doi:
            <a href="https://doi.org/10.1109/CCNC.2018.8319239">10.1109/CCNC.2018.8319239</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#sharif_evographs_201801"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-mansur_sound_1985" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[22]</div>
          <div class="csl-right-inline">
            D. L. Mansur, M. M. Blattner, and K. I. Joy,
            <span>“Sound graphs: <span>A</span> numerical data analysis method for the blind,”</span>
            <em>Journal of Medical Systems</em>, vol. 9, no. 3, pp. 163–174, Jun. 1985, doi:
            <a href="https://doi.org/10.1007/BF00996201">10.1007/BF00996201</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#mansur_sound_198501"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-mcgookin_soundbar_2006" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[23]</div>
          <div class="csl-right-inline">
            D. K. McGookin and S. A. Brewster,
            <span>“<span>SoundBar</span>: Exploiting multiple views in multimodal graph browsing,”</span> in
            <em
              >Proceedings of the 4th <span>Nordic</span> conference on <span>Human</span>-computer interaction:
              Changing roles</em
            >, Oct. 2006, pp. 145–154. doi:
            <a href="https://doi.org/10.1145/1182475.1182491">10.1145/1182475.1182491</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#mcgookin_soundbar_200601"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-flowers_cross-modal_1997" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[24]</div>
          <div class="csl-right-inline">
            J. H. Flowers, D. C. Buhman, and K. D. Turnage,
            <span
              >“Cross-<span>Modal</span> <span>Equivalence</span> of <span>Visual</span> and <span>Auditory</span>
              <span>Scatterplots</span> for <span>Exploring</span> <span>Bivariate</span> <span>Data</span>
              <span>Samples</span>,”</span
            >
            <em>Human Factors</em>, vol. 39, no. 3, pp. 341–351, Sep. 1997, doi:
            <a href="https://doi.org/10.1518/001872097778827151">10.1518/001872097778827151</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#flowers_cross-modal_199701"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-brown_viztouch_2012" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[25]</div>
          <div class="csl-right-inline">
            C. Brown and A. Hurst,
            <span>“<span>VizTouch</span>: Automatically generated tactile visualizations of coordinate spaces,”</span>
            in
            <em
              >Proceedings of the <span>Sixth</span> <span>International</span> <span>Conference</span> on
              <span>Tangible</span>, <span>Embedded</span> and <span>Embodied</span> <span>Interaction</span></em
            >, Feb. 2012, pp. 131–138. doi:
            <a href="https://doi.org/10.1145/2148131.2148160">10.1145/2148131.2148160</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#brown_viztouch_201201"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-hurst_making_2013" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[26]</div>
          <div class="csl-right-inline">
            A. Hurst and S. Kane, <span>“Making "making" accessible,”</span> in
            <em
              >Proceedings of the 12th <span>International</span> <span>Conference</span> on <span>Interaction</span>
              <span>Design</span> and <span>Children</span></em
            >, Jun. 2013, pp. 635–638. doi:
            <a href="https://doi.org/10.1145/2485760.2485883">10.1145/2485760.2485883</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#hurst_making_201301"
                aria-label="Return to: Following calls to ensure accessibility work has practical benefits that exceed publications&nbsp;"
                title="Return to: Following calls to ensure accessibility work has practical benefits that exceed publications&nbsp;"
                >1</a
              >,
              <a
                href="#hurst_making_201311"
                aria-label="Return to: When considering the analysis by Hurst and Kane about high abandonment rates in assistive technology,&nbsp;"
                title="Return to: When considering the analysis by Hurst and Kane about high abandonment rates in assistive technology,&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-shi_tickers_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[27]</div>
          <div class="csl-right-inline">
            L. Shi, I. Zelzer, C. Feng, and S. Azenkot,
            <span
              >“Tickers and <span>Talker</span>: <span>An</span> <span>Accessible</span> <span>Labeling</span>
              <span>Toolkit</span> for <span>3D</span> <span>Printed</span> <span>Models</span>,”</span
            >
            in
            <em
              >Proceedings of the 2016 <span>CHI</span> <span>Conference</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, New York, NY, USA: Association for Computing Machinery, 2016, pp. 4896–4907. doi:
            <a href="https://doi.org/10.1145/2858036.2858507">10.1145/2858036.2858507</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#shi_tickers_201601"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-choi_visualizing_2019" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[28]</div>
          <div class="csl-right-inline">
            J. Choi, S. Jung, D. G. Park, J. Choo, and N. Elmqvist,
            <span
              >“Visualizing for the <span>Non</span>-<span>Visual</span>: <span>Enabling</span> the
              <span>Visually</span> <span>Impaired</span> to <span>Use</span> <span>Visualization</span>,”</span
            >
            <em>Computer Graphics Forum</em>, vol. 38, no. 3, pp. 249–260, 2019, doi:
            <a href="https://doi.org/10.1111/cgf.13686">10.1111/cgf.13686</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#choi_visualizing_201901"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-jansen_opportunities_2015" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[29]</div>
          <div class="csl-right-inline">
            Y. Jansen <em>et al.</em>,
            <span>“Opportunities and <span>Challenges</span> for <span>Data</span> <span>Physicalization</span>,”</span>
            in
            <em
              >Proceedings of the 33rd <span>Annual</span> <span>ACM</span> <span>Conference</span> on
              <span>Human</span> <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, New York, NY, USA: Association for Computing Machinery, 2015, pp. 3227–3236. doi:
            <a href="https://doi.org/10.1145/2702123.2702180">10.1145/2702123.2702180</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#jansen_opportunities_201501"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-bennett_interdependence_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[30]</div>
          <div class="csl-right-inline">
            C. L. Bennett, E. Brady, and S. M. Branham,
            <span
              >“Interdependence as a <span>Frame</span> for <span>Assistive</span> <span>Technology</span>
              <span>Research</span> and <span>Design</span>,”</span
            >
            in
            <em
              >Proceedings of the 20th <span>International</span> <span>ACM</span> <span>SIGACCESS</span>
              <span>Conference</span> on <span>Computers</span> and <span>Accessibility</span></em
            >, Oct. 2018, pp. 161–173. doi:
            <a href="https://doi.org/10.1145/3234695.3236348">10.1145/3234695.3236348</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#bennett_interdependence_201801"
                aria-label="Return to: Self-advocacy and interdependent agency are important sociotechnical considerations that engage the conflicting access needs that different users might have in complex technological interactions like data experiences&nbsp;"
                title="Return to: Self-advocacy and interdependent agency are important sociotechnical considerations that engage the conflicting access needs that different users might have in complex technological interactions like data experiences&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-jayant_automated_2007" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[31]</div>
          <div class="csl-right-inline">
            C. Jayant, M. Renzelmann, D. Wen, S. Krisnandi, R. Ladner, and D. Comden,
            <span>“Automated tactile graphics translation: In the field,”</span> in
            <em
              >Proceedings of the 9th international <span>ACM</span> <span>SIGACCESS</span> conference on
              <span>Computers</span> and accessibility</em
            >, Oct. 2007, pp. 75–82. doi:
            <a href="https://doi.org/10.1145/1296843.1296858">10.1145/1296843.1296858</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#jayant_automated_200701"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_guidelines_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[32]</div>
          <div class="csl-right-inline">
            BANA,
            <span>“Guidelines and <span>Standards</span> for <span>Tactile</span> <span>Graphics</span>,”</span> Braille
            Authority of North America, Braille {Standard}, 2010. Available:
            <a href="http://www.brailleauthority.org/tg/">http://www.brailleauthority.org/tg/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_guidelines_nodate01"
                aria-label="Return to:  or The American Printing House for the Blind and Braille Authority of North America&nbsp;"
                title="Return to:  or The American Printing House for the Blind and Braille Authority of North America&nbsp;"
                >1</a
              >,
              <a
                href="#noauthor_guidelines_nodate11"
                aria-label="Return to: We want to acknowledge that tactile and braille standards are robust&nbsp;"
                title="Return to: We want to acknowledge that tactile and braille standards are robust&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-south_generating_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[33]</div>
          <div class="csl-right-inline">
            L. South and M. Borkin,
            <span
              >“Generating <span>Seizure</span>-<span>Inducing</span> <span>Sequences</span> with
              <span>Interactive</span> <span>Visualizations</span>,”</span
            >
            Oct. 2020. doi: <a href="https://doi.org/10.31219/osf.io/85gwy">10.31219/osf.io/85gwy</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#south_generating_202001"
                aria-label="Return to:  and seizure risk&nbsp;"
                title="Return to:  and seizure risk&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-wu_understanding_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[34]</div>
          <div class="csl-right-inline">
            K. Wu, E. Petersen, T. Ahmad, D. Burlinson, S. Tanis, and D. A. Szafir,
            <span
              >“Understanding <span>Data</span> <span>Accessibility</span> for <span>People</span> with
              <span>Intellectual</span> and <span>Developmental</span> <span>Disabilities</span>,”</span
            >
            in
            <em
              >Proceedings of the 2021 <span>CHI</span> <span>Conference</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, May 2021, pp. 1–16. doi:
            <a href="https://doi.org/10.1145/3411764.3445743">10.1145/3411764.3445743</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#wu_understanding_202101"
                aria-label="Return to: We have found 2 papers that engage cognitive/neurological disability in visualization and 1 student poster from IEEE Vis, which are all recent (specifically intellectual developmental disabilities&nbsp;"
                title="Return to: We have found 2 papers that engage cognitive/neurological disability in visualization and 1 student poster from IEEE Vis, which are all recent (specifically intellectual developmental disabilities&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_semiotic_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[35]</div>
          <div class="csl-right-inline">
            M. Mazanec, <span>“Semiotic.”</span> Available:
            <a href="https://semiotic.nteract.io/guides/accessibility"
              >https://semiotic.nteract.io/guides/accessibility</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_semiotic_nodate01"
                aria-label="Return to: Semiotic’s accessibility features were added by community member Melanie Mazanec&nbsp;"
                title="Return to: Semiotic’s accessibility features were added by community member Melanie Mazanec&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-balaji_chart-text_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[36]</div>
          <div class="csl-right-inline">
            A. Balaji, T. Ramanathan, and V. Sonathi,
            <span
              >“Chart-<span>Text</span>: <span>A</span> <span>Fully</span> <span>Automated</span> <span>Chart</span>
              <span>Image</span> <span>Descriptor</span>,”</span
            >
            <em>arXiv Preprint</em>, Dec. 2018, Available:
            <a href="http://arxiv.org/abs/1812.10636">http://arxiv.org/abs/1812.10636</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#balaji_chart-text_201801"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-chen_neural_2019" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[37]</div>
          <div class="csl-right-inline">
            C. Chen <em>et al.</em>, <span>“Neural caption generation over figures,”</span> in
            <em
              >Adjunct <span>Proceedings</span> of the 2019 <span>ACM</span> <span>International</span>
              <span>Joint</span> <span>Conference</span> on <span>Pervasive</span> and <span>Ubiquitous</span>
              <span>Computing</span> and <span>Proceedings</span> of the 2019 <span>ACM</span>
              <span>International</span> <span>Symposium</span> on <span>Wearable</span> <span>Computers</span></em
            >, Sep. 2019, pp. 482–485. doi:
            <a href="https://doi.org/10.1145/3341162.3345601">10.1145/3341162.3345601</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#chen_neural_201901"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-chen_figure_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[38]</div>
          <div class="csl-right-inline">
            C. Chen, R. Zhang, E. Koh, S. Kim, S. Cohen, and R. Rossi,
            <span
              >“Figure <span>Captioning</span> with <span>Relation</span> <span>Maps</span> for
              <span>Reasoning</span>,”</span
            >
            in
            <em
              >2020 <span>IEEE</span> <span>Winter</span> <span>Conference</span> on <span>Applications</span> of
              <span>Computer</span> <span>Vision</span> (<span>WACV</span>)</em
            >, Mar. 2020, pp. 1526–1534. doi:
            <a href="https://doi.org/10.1109/WACV45572.2020.9093592">10.1109/WACV45572.2020.9093592</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#chen_figure_202001"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-lai_automatic_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[39]</div>
          <div class="csl-right-inline">
            C. Lai, Z. Lin, R. Jiang, Y. Han, C. Liu, and X. Yuan,
            <span
              >“Automatic <span>Annotation</span> <span>Synchronizing</span> with <span>Textual</span>
              <span>Description</span> for <span>Visualization</span>,”</span
            >
            in
            <em
              >Proceedings of the 2020 <span>CHI</span> <span>Conference</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, New York, NY, USA: Association for Computing Machinery, 2020, pp. 1–13. doi:
            <a href="https://doi.org/doi.org/10.1145/3313831.3376443">doi.org/10.1145/3313831.3376443</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#lai_automatic_202001"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-obeid_chart--text_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[40]</div>
          <div class="csl-right-inline">
            J. Obeid and E. Hoque,
            <span
              >“Chart-to-<span>Text</span>: <span>Generating</span> <span>Natural</span> <span>Language</span>
              <span>Descriptions</span> for <span>Charts</span> by <span>Adapting</span> the <span>Transformer</span>
              <span>Model</span>,”</span
            >
            <em>arXiv Preprint</em>, Nov. 2020, Available:
            <a href="http://arxiv.org/abs/2010.09142">http://arxiv.org/abs/2010.09142</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#obeid_chart--text_202001"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-qian_generating_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[41]</div>
          <div class="csl-right-inline">
            X. Qian <em>et al.</em>,
            <span
              >“Generating <span>Accurate</span> <span>Caption</span> <span>Units</span> for <span>Figure</span>
              <span>Captioning</span>,”</span
            >
            in <em>Proceedings of the <span>Web</span> <span>Conference</span> 2021</em>, New York, NY, USA: Association
            for Computing Machinery, 2021, pp. 2792–2804. doi:
            <a href="https://doi.org/10.1145/3442381.3449923">10.1145/3442381.3449923</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#qian_generating_202101"
                aria-label="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                title="Return to: There is significant research that explores automatic or extracted textual descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-mankoff_disability_2010" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[42]</div>
          <div class="csl-right-inline">
            J. Mankoff, G. R. Hayes, and D. Kasnitz,
            <span>“Disability studies as a source of critical inquiry for the field of assistive technology,”</span> in
            <em
              >Proceedings of the 12th international <span>ACM</span> <span>SIGACCESS</span> conference on
              <span>Computers</span> and accessibility</em
            >, Oct. 2010, pp. 3–10. doi:
            <a href="https://doi.org/10.1145/1878803.1878807">10.1145/1878803.1878807</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#mankoff_disability_201001"
                aria-label="Return to: Self-advocacy and interdependent agency are important sociotechnical considerations that engage the conflicting access needs that different users might have in complex technological interactions like data experiences&nbsp;"
                title="Return to: Self-advocacy and interdependent agency are important sociotechnical considerations that engage the conflicting access needs that different users might have in complex technological interactions like data experiences&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-martinez_methodology_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[43]</div>
          <div class="csl-right-inline">
            R. A. Martínez, M. R. Turró, and T. G. Saltiveri,
            <span
              >“Methodology for heuristic evaluation of the accessibility of statistical charts for people with low
              vision and color vision deficiency,”</span
            >
            <em>Universal Access in the Information Society</em>, Dec. 2021, doi:
            <a href="https://doi.org/10.21203/rs.3.rs-156959/v1">10.21203/rs.3.rs-156959/v1</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#martinez_methodology_202101"
                aria-label="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                title="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                >1</a
              >,
              <a
                href="#martinez_methodology_202111"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-aldrich_talk_2008" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[44]</div>
          <div class="csl-right-inline">
            F. Aldrich,
            <span
              >“Talk to the <span>Hand</span>: <span>An</span> <span>Agenda</span> for <span>Further</span>
              <span>Research</span> on <span>Tactile</span> <span>Graphics</span>,”</span
            >
            in <em>Diagrammatic <span>Representation</span> and <span>Inference</span></em
            >, 2008, pp. 344–346. doi:
            <a href="https://doi.org/10.1007/978-3-540-87730-1_31">10.1007/978-3-540-87730-1_31</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#aldrich_talk_200801"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-schneider_constructing_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[45]</div>
          <div class="csl-right-inline">
            J. Schneider,
            <span
              >“Constructing the <span>Yellow</span> <span>Brick</span> <span>Road</span>: <span>Route</span>
              <span>Bricks</span> on <span>Virtual</span> <span>Tactile</span> <span>Maps</span>.”</span
            >
            <span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#schneider_constructing_nodate01"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-butler_technology_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[46]</div>
          <div class="csl-right-inline">
            M. Butler, L. M. Holloway, S. Reinders, C. Goncu, and K. Marriott,
            <span
              >“Technology <span>Developments</span> in <span>Touch</span>-<span>Based</span> <span>Accessible</span>
              <span>Graphics</span>: <span>A</span> <span>Systematic</span> <span>Review</span> of
              <span>Research</span> 2010-2020,”</span
            >
            in
            <em
              >Proceedings of the 2021 <span>CHI</span> <span>Conference</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, May 2021, pp. 1–15. doi:
            <a href="https://doi.org/10.1145/3411764.3445207">10.1145/3411764.3445207</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#butler_technology_202101"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-geldard_tactual_1983" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[47]</div>
          <div class="csl-right-inline">
            F. A. Geldard, W. Schiff, and E. Foulke,
            <em>Tactual <span>Perception</span>: <span>A</span> <span>Source</span> <span>Book</span></em
            >. Cambridge University Press, 1983. doi:
            <a href="https://doi.org/10.2307/1422824">10.2307/1422824</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#geldard_tactual_198301"
                aria-label="Return to: Research projects that explore tactile sensory substitutions have been a topic in computational sciences dating back to the 1983&nbsp;"
                title="Return to: Research projects that explore tactile sensory substitutions have been a topic in computational sciences dating back to the 1983&nbsp;"
                >1</a
              >,
              <a
                href="#geldard_tactual_198311"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-gallace_what_2011" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[48]</div>
          <div class="csl-right-inline">
            A. Gallace and C. Spence,
            <span>“To what extent do <span>Gestalt</span> grouping principles influence tactile perception?”</span>
            <em>Psychological bulletin</em>, 2011, doi:
            <a href="https://doi.org/10.1037/a0022335">10.1037/a0022335</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#gallace_what_201101"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-lederman_perception_1986" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[49]</div>
          <div class="csl-right-inline">
            S. Lederman, G. Thorne, and B. Jones,
            <span>“Perception of texture by vision and touch: Multidimensionality and intersensory integration.”</span>
            <em>Journal of experimental psychology. Human perception and performance</em>, 1986, doi:
            <a href="https://doi.org/10.1037//0096-1523.12.2.169">10.1037//0096-1523.12.2.169</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#lederman_perception_198601"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-cullen_co-designing_2019" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[50]</div>
          <div class="csl-right-inline">
            C. Cullen and O. Metatla,
            <span
              >“Co-designing <span>Inclusive</span> <span>Multisensory</span> <span>Story</span>
              <span>Mapping</span> with <span>Children</span> with <span>Mixed</span> <span>Visual</span>
              <span>Abilities</span>,”</span
            >
            in
            <em
              >Proceedings of the 18th <span>ACM</span> <span>International</span> <span>Conference</span> on
              <span>Interaction</span> <span>Design</span> and <span>Children</span></em
            >, Jun. 2019, pp. 361–373. doi:
            <a href="https://doi.org/10.1145/3311927.3323146">10.1145/3311927.3323146</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#cullen_co-designing_201901"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-bornschein_collaborative_2015" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[51]</div>
          <div class="csl-right-inline">
            J. Bornschein, D. Prescher, and G. Weber,
            <span
              >“Collaborative <span>Creation</span> of <span>Digital</span> <span>Tactile</span>
              <span>Graphics</span>,”</span
            >
            in
            <em
              >Proceedings of the 17th <span>International</span> <span>ACM</span> <span>SIGACCESS</span>
              <span>Conference</span> on <span>Computers</span> &amp; <span>Accessibility</span></em
            >, Oct. 2015, pp. 117–126. doi:
            <a href="https://doi.org/10.1145/2700648.2809869">10.1145/2700648.2809869</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#bornschein_collaborative_201501"
                aria-label="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                title="Return to:  and haptic graphs and tactile interfaces&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-initiative_wai_accessibility_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[52]</div>
          <div class="csl-right-inline">
            WAI, <span>“Accessibility principles,”</span> <span>W3C</span>, {WCAG} {Standard}, 2019. Available:
            <a href="https://www.w3.org/WAI/fundamentals/accessibility-principles/"
              >https://www.w3.org/WAI/fundamentals/accessibility-principles/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#initiative_wai_accessibility_nodate01"
                aria-label="Return to: Chartability is an accessibility evaluation system specific to data visualizations and interfaces which aims to help practitioners answer the question, “how accessible is my data visualization?” Chartability organizes knowledge from disparate bodies of work into testable heuristics based on the functional accessibility principles POUR (Perceivable, Operable, Understandable, and Robust)&nbsp;"
                title="Return to: Chartability is an accessibility evaluation system specific to data visualizations and interfaces which aims to help practitioners answer the question, “how accessible is my data visualization?” Chartability organizes knowledge from disparate bodies of work into testable heuristics based on the functional accessibility principles POUR (Perceivable, Operable, Understandable, and Robust)&nbsp;"
                >1</a
              >,
              <a
                href="#initiative_wai_accessibility_nodate11"
                aria-label="Return to: WAI and WCAG outline 4 types of functional accessibility principles: Perceivable, Operable, Understandable, and Robust, abbreviated as POUR&nbsp;"
                title="Return to: WAI and WCAG outline 4 types of functional accessibility principles: Perceivable, Operable, Understandable, and Robust, abbreviated as POUR&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_study_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[53]</div>
          <div class="csl-right-inline">
            Deque,
            <span
              >“<span>Automated</span> <span>Testing</span> <span>Identifies</span> 57 <span>Percent</span> of
              <span>Digital</span> <span>Accessibility</span> <span>Issues</span>,”</span
            >
            Deque, Mar. 2021. Available:
            <a
              href="https://www.deque.com/blog/automated-testing-study-identifies-57-percent-of-digital-accessibility-issues/"
              >https://www.deque.com/blog/automated-testing-study-identifies-57-percent-of-digital-accessibility-issues/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_study_202101"
                aria-label="Return to: State-of-the art automated compliance checkers only find 57% of accessibility errors&nbsp;"
                title="Return to: State-of-the art automated compliance checkers only find 57% of accessibility errors&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_why_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[54]</div>
          <div class="csl-right-inline">
            D. Schepers,
            <span
              >“Why <span>Accessibility</span> <span>Is</span> at the <span>Heart</span> of <span>Data</span>
              <span>Visualization</span> <span></span> by <span>Doug</span> <span>Schepers</span> <span></span>
              <span>Nightingale</span> <span></span> <span>Medium</span>.”</span
            >
            Available:
            <a href="https://medium.com/nightingale/accessibility-is-at-the-heart-of-data-visualization-64a38d6c505b"
              >https://medium.com/nightingale/accessibility-is-at-the-heart-of-data-visualization-64a38d6c505b</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_why_nodate01"
                aria-label="Return to:  and what Doug Schepers meant by “data visualization is an assistive technology”&nbsp;"
                title="Return to:  and what Doug Schepers meant by “data visualization is an assistive technology”&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-bigham_vizwiz_2010" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[55]</div>
          <div class="csl-right-inline">
            J. P. Bigham <em>et al.</em>,
            <span>“<span>VizWiz</span>: Nearly real-time answers to visual questions,”</span> in
            <em
              >Proceedings of the 23nd annual <span>ACM</span> symposium on <span>User</span> interface software and
              technology</em
            >, New York, NY, USA: Association for Computing Machinery, 2010, pp. 333–342. doi:
            <a href="https://doi.org/10.1145/1866029.1866080">10.1145/1866029.1866080</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#bigham_vizwiz_201001"
                aria-label="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                title="Return to: For example, whereas tactile graphics guidelines lend insight into information prioritization, layout, and fidelity, the assumption is they will be embossed onto paper or similar physical mediums&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-moraes_evaluating_2014" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[56]</div>
          <div class="csl-right-inline">
            P. Moraes, G. Sina, K. McCoy, and S. Carberry,
            <span
              >“Evaluating the accessibility of line graphs through textual summaries for visually impaired
              users,”</span
            >
            in
            <em
              >Proceedings of the 16th international <span>ACM</span> <span>SIGACCESS</span> conference on
              <span>Computers</span> &amp; accessibility</em
            >, Oct. 2014, pp. 83–90. doi:
            <a href="https://doi.org/10.1145/2661334.2661368">10.1145/2661334.2661368</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#moraes_evaluating_201401"
                aria-label="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                title="Return to: All of these challenges are factors that limit the generalizability of these artifacts and knowledge for practitioner use&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-chaparro_applications_2017" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[57]</div>
          <div class="csl-right-inline">
            A. Chaparro and M. Chaparro,
            <span
              >“Applications of <span>Color</span> in <span>Design</span> for <span>Color</span>-<span>Deficient</span>
              <span>Users</span>,”</span
            >
            <em>Ergonomics in Design</em>, vol. 25, no. 1, pp. 23–30, Jan. 2017, doi:
            <a href="https://doi.org/10.1177/1064804616635382">10.1177/1064804616635382</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#chaparro_applications_201701"
                aria-label="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                title="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-nunez_optimizing_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[58]</div>
          <div class="csl-right-inline">
            J. R. Nuñez, C. R. Anderton, and R. S. Renslow,
            <span
              >“Optimizing colormaps with consideration for color vision deficiency to enable accurate interpretation of
              scientific data,”</span
            >
            <em>PLOS ONE</em>, vol. 13, no. 7, Aug. 2018, doi:
            <a href="https://doi.org/10.1371/journal.pone.0199239">10.1371/journal.pone.0199239</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#nunez_optimizing_201801"
                aria-label="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                title="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-oliveira_towards_2013" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[59]</div>
          <div class="csl-right-inline">
            M. M. Oliveira,
            <span
              >“Towards <span>More</span> <span>Accessible</span> <span>Visualizations</span> for
              <span>Color</span>-<span>Vision</span>-<span>Deficient</span> <span>Individuals</span>,”</span
            >
            <em>Computing in Science Engineering</em>, vol. 15, no. 5, pp. 80–87, Sep. 2013, doi:
            <a href="https://doi.org/10.1109/MCSE.2013.113">10.1109/MCSE.2013.113</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#oliveira_towards_201301"
                aria-label="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                title="Return to: Since the 1990s, the most prominent and active accessibility topic in visualization has been color vision deficiency&nbsp;"
                >1</a
              >,
              <a
                href="#oliveira_towards_201311"
                aria-label="Return to:  even among topics related to accessibility (color vision deficiency, specifically)&nbsp;"
                title="Return to:  even among topics related to accessibility (color vision deficiency, specifically)&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-schaadhardt_understanding_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[60]</div>
          <div class="csl-right-inline">
            A. Schaadhardt, A. Hiniker, and J. O. Wobbrock,
            <span
              >“Understanding <span>Blind</span> <span>Screen</span>-<span>Reader</span> <span>Users</span>&amp;#x2019;
              <span>Experiences</span> of <span>Digital</span> <span>Artboards</span>,”</span
            >
            May 2021. doi: <a href="https://doi.org/10.1145/3411764.3445242">10.1145/3411764.3445242</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#schaadhardt_understanding_202101"
                aria-label="Return to: , screen reader user experiences with digital, 2-D spatial representations, including data visualizations&nbsp;"
                title="Return to: , screen reader user experiences with digital, 2-D spatial representations, including data visualizations&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-zhao_data_2008" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[61]</div>
          <div class="csl-right-inline">
            H. Zhao, C. Plaisant, B. Shneiderman, and J. Lazar,
            <span
              >“Data <span>Sonification</span> for <span>Users</span> with <span>Visual</span> <span>Impairment</span>:
              <span>A</span> <span>Case</span> <span>Study</span> with <span>Georeferenced</span>
              <span>Data</span>,”</span
            >
            <em>ACM Transactions on Computer-Human Interaction</em>, vol. 15, no. 1, May 2008, doi:
            <a href="https://doi.org/10.1145/1352782.1352786">10.1145/1352782.1352786</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#zhao_data_200801"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-brewster_visualization_2002" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[62]</div>
          <div class="csl-right-inline">
            S. Brewster, <span>“Visualization tools for blind people using multiple modalities,”</span>
            <em>Disability and Rehabilitation</em>, vol. 24, no. 11–12, pp. 613–621, Aug. 2002, doi:
            <a href="https://doi.org/10.1080/09638280110111388">10.1080/09638280110111388</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#brewster_visualization_200201"
                aria-label="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                title="Return to: Sonification used both in comparison to and alongside visualization and tactile methods for accessibility dates as far back as 1985&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_accessibility_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[63]</div>
          <div class="csl-right-inline">
            Highsoft, <span>“Highcharts accessibility module.”</span> Available:
            <a href="https://highcharts.com/docs/accessibility/accessibility-module"
              >https://highcharts.com/docs/accessibility/accessibility-module</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_accessibility_nodate01"
                aria-label="Return to: Libraries like Highcharts&nbsp;"
                title="Return to: Libraries like Highcharts&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-vcc" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[64]</div>
          <div class="csl-right-inline">
            Visa, <span>“Visa <span>Chart</span> <span>Components</span>,”</span> <em>GitHub</em>. Available:
            <a href="https://github.com/visa/visa-chart-components">https://github.com/visa/visa-chart-components</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#vcc01"
                aria-label="Return to:  or Visa Chart Components (VCC)&nbsp;"
                title="Return to:  or Visa Chart Components (VCC)&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_revealing_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[65]</div>
          <div class="csl-right-inline">
            S. Canelón and L. Hare,
            <span
              >“Revealing <span>Room</span> for <span>Improvement</span> in <span>Accessibility</span> within a
              <span>Social</span> <span>Media</span> <span>Data</span> <span>Visualization</span> <span>Learning</span>
              <span>Community</span>.”</span
            >
            Available:
            <a href="https://silvia.rbind.io/talk/2021-05-04-data-viz-accessibility/"
              >https://silvia.rbind.io/talk/2021-05-04-data-viz-accessibility/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_revealing_nodate01"
                aria-label="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                title="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_making_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[66]</div>
          <div class="csl-right-inline">
            Rs. Community, <span>“Making <span>Shiny</span> apps accessible for all humans.”</span> May 2018. Available:
            <a href="https://community.rstudio.com/t/making-shiny-apps-accessible-for-all-humans/8458"
              >https://community.rstudio.com/t/making-shiny-apps-accessible-for-all-humans/8458</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_making_201801"
                aria-label="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                title="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_are_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[67]</div>
          <div class="csl-right-inline">
            P. C. Forum, <span>“Are plotly tables accessible?”</span> Feb. 2018. Available:
            <a href="https://community.plotly.com/t/are-plotly-tables-accessible/8263"
              >https://community.plotly.com/t/are-plotly-tables-accessible/8263</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_are_201801"
                aria-label="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                title="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_solved_2019" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[68]</div>
          <div class="csl-right-inline">
            P. C. Forum, <span>“<span>Datatables</span> and <span>Accessibility</span>.”</span> Nov. 2019. Available:
            <a href="https://community.plotly.com/t/solved-datatables-and-accessibility/31085"
              >https://community.plotly.com/t/solved-datatables-and-accessibility/31085</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_solved_201901"
                aria-label="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                title="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-simon_making_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[69]</div>
          <div class="csl-right-inline">
            S. Wheatcroft,
            <span
              >“Making <span>Graphs</span> <span>And</span> <span>Plots</span> <span>Accessible</span> <span>For</span>
              <span>The</span> <span>Blind</span>.”</span
            >
            Jun. 2020. Available:
            <a href="https://andadapt.com/making-graphs-and-plots-accessible-for-the-blind/"
              >https://andadapt.com/making-graphs-and-plots-accessible-for-the-blind/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#simon_making_202001"
                aria-label="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                title="Return to: More established visualization libraries like matplotlib, ggplot2, d3js, R-Shiny, and Plotly have left most accessibility efforts to developers, with varying levels of documentation and difficulty involved&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_power_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[70]</div>
          <div class="csl-right-inline">
            R. Klein,
            <span>“Power <span>BI</span> <span>Accessibility</span> <span>Best</span> <span>Practices</span>,”</span>
            <em>PowerBIAccessibility</em>. Available:
            <a href="https://rklein324.github.io/PowerBIAccessibility/"
              >https://rklein324.github.io/PowerBIAccessibility/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_power_nodate01"
                aria-label="Return to: For Microsoft’s PowerBI, students have organized resources for how to make visualizations built with it more accessible&nbsp;"
                title="Return to: For Microsoft’s PowerBI, students have organized resources for how to make visualizations built with it more accessible&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_mapboxmapbox-gl-accessibility_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[71]</div>
          <div class="csl-right-inline">
            Mapbox, <span>“Mapbox gl accessibility.”</span> Aug. 2021. Available:
            <a href="https://github.com/mapbox/mapbox-gl-accessibility"
              >https://github.com/mapbox/mapbox-gl-accessibility</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_mapboxmapbox-gl-accessibility_202101"
                aria-label="Return to: The accessibility module for Mapbox GL on GitHub was created and maintained by volunteers but has had less than 10 weeks of work with any activity invested since its first activity in late 2017&nbsp;"
                title="Return to: The accessibility module for Mapbox GL on GitHub was created and maintained by volunteers but has had less than 10 weeks of work with any activity invested since its first activity in late 2017&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-brangier_beyond_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[72]</div>
          <div class="csl-right-inline">
            E. Brangier, J. G. Urrutia, V. Senderowicz, and L. Cessat,
            <span
              >“Beyond "<span>Usability</span> and <span>User</span> <span>Experience</span>" , <span>Towards</span> an
              <span>Integrative</span> <span>Heuristic</span> <span>Inspection</span>: From
              <span>Accessibility</span> to <span>Persuasiveness</span> in the <span>UX</span> <span>Evaluation</span>
              <span>A</span> <span>Case</span> <span>Study</span> on an <span>Insurance</span> <span>Prospecting</span>
              <span>Tablet</span> <span>Application</span>,”</span
            >
            <em>Advances in Usability and User Experience</em>, Jun. 2018, doi:
            <a href="https://doi.org/10.1007/978-3-319-60492-3_44">10.1007/978-3-319-60492-3_44</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#brangier_beyond_201801"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_unlocking_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[73]</div>
          <div class="csl-right-inline">
            D. Boudreau,
            <span
              >“Unlocking <span>Accessibility</span> for <span>UX</span>/<span>UI</span> <span>Designers</span>,”</span
            >
            <em>24 Accessibility</em>. Dec. 2018. Available:
            <a href="https://www.24a11y.com/2018/unlocking-accessibility-for-ux-ui-designers/"
              >https://www.24a11y.com/2018/unlocking-accessibility-for-ux-ui-designers/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_unlocking_201801"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-experience_10_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[74]</div>
          <div class="csl-right-inline">
            J. Nielsen,
            <span
              >“10 <span>Usability</span> <span>Heuristics</span> for <span>User</span> <span>Interface</span>
              <span>Design</span>,”</span
            >
            <em>Nielsen Norman Group</em>. Available:
            <a href="https://www.nngroup.com/articles/ten-usability-heuristics/"
              >https://www.nngroup.com/articles/ten-usability-heuristics/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#experience_10_nodate01"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-nielsen_heuristic_1994" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[75]</div>
          <div class="csl-right-inline">
            J. Nielsen, <span>“Heuristic evaluation,”</span> in <em>Usability inspection methods</em>, USA: John Wiley
            &amp; Sons, Inc., 1994, pp. 25–62.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#nielsen_heuristic_199401"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-slavkovic_novice_1999" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[76]</div>
          <div class="csl-right-inline">
            A. Slavkovic and K. Cross, <span>“Novice heuristic evaluations of a complex interface,”</span> in
            <em
              ><span>CHI</span> ’99 <span>Extended</span> <span>Abstracts</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, May 1999, pp. 304–305. doi:
            <a href="https://doi.org/10.1145/632716.632902">10.1145/632716.632902</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#slavkovic_novice_199901"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-otey_methodology_2017" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[77]</div>
          <div class="csl-right-inline">
            D. Q. Otey, <span>“A methodology to develop usability / user experience heuristics,”</span> in
            <em
              >Proceedings of the <span>XVIII</span> <span>International</span> <span>Conference</span> on
              <span>Human</span> <span>Computer</span> <span>Interaction</span></em
            >, Sep. 2017, pp. 1–2. doi:
            <a href="https://doi.org/10.1145/3123818.3133832">10.1145/3123818.3133832</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#otey_methodology_201701"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-joyce_mobile_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[78]</div>
          <div class="csl-right-inline">
            G. Joyce, M. Lilley, T. Barker, and A. Jefferies,
            <span
              >“Mobile <span>Application</span> <span>Usability</span>: <span>Heuristic</span>
              <span>Evaluation</span> and <span>Evaluation</span> of <span>Heuristics</span>,”</span
            >
            in
            <em
              >Advances in <span>Human</span> <span>Factors</span>, <span>Software</span>, and <span>Systems</span>
              <span>Engineering</span></em
            >, 2016, pp. 77–86. doi:
            <a href="https://doi.org/10.1007/978-3-319-41935-0_8">10.1007/978-3-319-41935-0_8</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#joyce_mobile_201601"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-santos_heuristic_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[79]</div>
          <div class="csl-right-inline">
            B. S. Santos, S. Silva, and P. Dias,
            <span
              >“Heuristic <span>Evaluation</span> in <span>Visualization</span>: <span>An</span> <span>Empirical</span>
              <span>Study</span> : <span>Position</span> paper,”</span
            >
            in
            <em
              >2018 <span>IEEE</span> <span>Evaluation</span> and <span>Beyond</span> - <span>Methodological</span>
              <span>Approaches</span> for <span>Visualization</span> (<span>BELIV</span>)</em
            >, Oct. 2018, pp. 78–85. doi:
            <a href="https://doi.org/10.1109/BELIV.2018.8634108">10.1109/BELIV.2018.8634108</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#santos_heuristic_201801"
                aria-label="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                title="Return to: They have been shown to be effective methods for practitioners compared to user testing, focus groups, or other evaluative methods that require existing expert knowledge or recruitment, moderation, and compensation of participants&nbsp;"
                >1</a
              >,
              <a
                href="#santos_heuristic_201811"
                aria-label="Return to:  even among topics related to accessibility (color vision deficiency, specifically)&nbsp;"
                title="Return to:  even among topics related to accessibility (color vision deficiency, specifically)&nbsp;"
                >2</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_chartability_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[80]</div>
          <div class="csl-right-inline">
            F. Elavsky, <span>“Chartability.”</span> Available:
            <a href="https://chartability.github.io/POUR-CAF/">https://chartability.github.io/POUR-CAF/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_chartability_nodate01"
                aria-label="Return to: All of Chartability’s tests are performed using Chartability’s workbook&nbsp;"
                title="Return to: All of Chartability’s tests are performed using Chartability’s workbook&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_inclusive_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[81]</div>
          <div class="csl-right-inline">
            H. Swan, I. Pouncey, H. Pickering, and L. Watson,
            <span>“Inclusive <span>Design</span> <span>Principles</span>.”</span> Available:
            <a href="https://inclusivedesignprinciples.org/">https://inclusivedesignprinciples.org/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_inclusive_nodate01"
                aria-label="Return to:  refer to as “adding value”&nbsp;"
                title="Return to:  refer to as “adding value”&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-wobbrock_ability-based_2011" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[82]</div>
          <div class="csl-right-inline">
            J. O. Wobbrock, S. K. Kane, K. Z. Gajos, S. Harada, and J. Froehlich,
            <span
              >“Ability-<span>Based</span> <span>Design</span>: <span>Concept</span>, <span>Principles</span> and
              <span>Examples</span>,”</span
            >
            <em>ACM Transactions on Accessible Computing</em>, vol. 3, no. 3, pp. 9:1–9:27, Apr. 2011, doi:
            <a href="https://doi.org/10.1145/1952383.1952384">10.1145/1952383.1952384</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#wobbrock_ability-based_201101"
                aria-label="Return to: Designs must not be rigid in their opinions and ability assumptions and should be designed to be moldable by and adaptive to user needs&nbsp;"
                title="Return to: Designs must not be rigid in their opinions and ability assumptions and should be designed to be moldable by and adaptive to user needs&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_sas_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[83]</div>
          <div class="csl-right-inline">
            SAS, <span>“<span>SAS</span> <span>Graphics</span> <span>Accelerator</span>.”</span> Available:
            <a href="https://support.sas.com/software/products/graphics-accelerator/"
              >https://support.sas.com/software/products/graphics-accelerator/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_sas_nodate01"
                aria-label="Return to:  and tools like the Graphics Accelerator in SAS&nbsp;"
                title="Return to:  and tools like the Graphics Accelerator in SAS&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-miesenberger_accessible_2018" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[84]</div>
          <div class="csl-right-inline">
            A. J. R. Godfrey, P. Murrell, and V. Sorge,
            <span
              >“An <span>Accessible</span> <span>Interaction</span> <span>Model</span> for <span>Data</span>
              <span>Visualisation</span> in <span>Statistics</span>,”</span
            >
            in <em>Computers <span>Helping</span> <span>People</span> with <span>Special</span> <span>Needs</span></em
            >, vol. 10896, K. Miesenberger and G. Kouroupetroglou, Eds. Cham: Springer International Publishing, 2018,
            pp. 590–597. doi:
            <a href="https://doi.org/10.1007/978-3-319-94277-3_92">10.1007/978-3-319-94277-3_92</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#miesenberger_accessible_201801"
                aria-label="Return to: Some more recent work has explored robust screen reader data interaction techniques&nbsp;"
                title="Return to: Some more recent work has explored robust screen reader data interaction techniques&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-sorge_polyfilling_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[85]</div>
          <div class="csl-right-inline">
            V. Sorge,
            <span>“Polyfilling <span>Accessible</span> <span>Chemistry</span> <span>Diagrams</span>,”</span> in
            <em>Computers <span>Helping</span> <span>People</span> with <span>Special</span> <span>Needs</span></em
            >, 2016, pp. 43–50. doi:
            <a href="https://doi.org/10.1007/978-3-319-41264-1_6">10.1007/978-3-319-41264-1_6</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#sorge_polyfilling_201601"
                aria-label="Return to: Some more recent work has explored robust screen reader data interaction techniques&nbsp;"
                title="Return to: Some more recent work has explored robust screen reader data interaction techniques&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-power_2012" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[86]</div>
          <div class="csl-right-inline">
            C. Power, A. Freire, H. Petrie, and D. Swallow,
            <span
              >“Guidelines are only half of the story: Accessibility problems encountered by blind users on the
              web,”</span
            >
            in <em>Proceedings of the SIGCHI conference on human factors in computing systems</em>, 2012, pp. 433–442.
            doi: <a href="https://doi.org/10.1145/2207676.2207736">10.1145/2207676.2207736</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#power_201201"
                aria-label="Return to: And following standards may only account for up to half of the needs of people with disabilities "
                title="Return to: And following standards may only account for up to half of the needs of people with disabilities "
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-kim_accessible_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[87]</div>
          <div class="csl-right-inline">
            N. W. Kim, S. C. Joyner, A. Riegelhuth, and Y. Kim,
            <span
              >“Accessible <span>Visualization</span>: <span>Design</span> <span>Space</span>,
              <span>Opportunities</span>, and <span>Challenges</span>,”</span
            >
            <em>Computer Graphics Forum</em>, vol. 40, no. 3, pp. 173–188, 2021, doi:
            <a href="https://doi.org/10.1111/cgf.14298">10.1111/cgf.14298</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#kim_accessible_202101"
                aria-label="Return to:  found that 56 papers have been published between 1999 and 2020 that focus on vision-related accessibility (not including color vision deficiency), with only 3 being published at a visualization venue (and only recently since 2018)&nbsp;"
                title="Return to:  found that 56 papers have been published between 1999 and 2020 that focus on vision-related accessibility (not including color vision deficiency), with only 3 being published at a visualization venue (and only recently since 2018)&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-marriott_inclusive_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[88]</div>
          <div class="csl-right-inline">
            K. Marriott <em>et al.</em>,
            <span>“Inclusive data visualization for people with disabilities: A call to action,”</span>
            <em>Interactions</em>, vol. 28, no. 3, pp. 47–51, Apr. 2021, doi:
            <a href="https://doi.org/10.1145/3457875">10.1145/3457875</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#marriott_inclusive_202101"
                aria-label="Return to:  found that there is no research at all that engages motor accessibility&nbsp;"
                title="Return to:  found that there is no research at all that engages motor accessibility&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-lundgard_accessible_22" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[89]</div>
          <div class="csl-right-inline">
            A. Lundgard and A. Satyanarayan,
            <span
              >“Accessible visualization via natural language descriptions: A four-level model of semantic
              content,”</span
            >
            <em>IEEE Transactions on Visualization and Computer Graphics</em>, vol. 28, no. 1, pp. 1073–1083, 2022, doi:
            <a href="https://doi.org/10.1109/TVCG.2021.3114770">10.1109/TVCG.2021.3114770</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#lundgard_accessible_2201"
                aria-label="Return to: , dug deeper into the semantic layers of effective chart descriptions&nbsp;"
                title="Return to: , dug deeper into the semantic layers of effective chart descriptions&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_extensive_2016" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[90]</div>
          <div class="csl-right-inline">
            J. Hale, <span>“Extensive digitization of tactile map collection,”</span>
            <em>Perkins School for the Blind</em>. Available:
            <a href="https://www.perkins.org/extensive-digitization-of-tactile-map-collection/"
              >https://www.perkins.org/extensive-digitization-of-tactile-map-collection/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_extensive_201601"
                aria-label="Return to: , with tactile sensory substitutions being used for maps and charts as far back as the 1830s&nbsp;"
                title="Return to: , with tactile sensory substitutions being used for maps and charts as far back as the 1830s&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-jung_communicating_2022" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[91]</div>
          <div class="csl-right-inline">
            C. Jung, S. Mehta, A. Kulkarni, Y. Zhao, and Y.-S. Kim,
            <span
              >“Communicating <span>Visualizations</span> without <span>Visuals</span>: <span>Investigation</span> of
              <span>Visualization</span> <span>Alternative</span> <span>Text</span> for <span>People</span> with
              <span>Visual</span> <span>Impairments</span>,”</span
            >
            <em>IEEE Transactions on Visualization and Computer Graphics</em>, vol. 28, no. 1, pp. 1095–1105, Jan. 2022,
            doi: <a href="https://doi.org/10.1109/TVCG.2021.3114846">10.1109/TVCG.2021.3114846</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#jung_communicating_202201"
                aria-label="Return to:  offer guidance that expands beyond commonly cited literature that chart descriptions are preferably between 2 and 8 sentences long, written in plain language, and with consideration for the order of information and navigation&nbsp;"
                title="Return to:  offer guidance that expands beyond commonly cited literature that chart descriptions are preferably between 2 and 8 sentences long, written in plain language, and with consideration for the order of information and navigation&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-chundury_towards_2022" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[92]</div>
          <div class="csl-right-inline">
            P. Chundury, B. Patnaik, Y. Reyazuddin, C. Tang, J. Lazar, and N. Elmqvist,
            <span
              >“Towards <span>Understanding</span> <span>Sensory</span> <span>Substitution</span> for
              <span>Accessible</span> <span>Visualization</span>: <span>An</span> <span>Interview</span>
              <span>Study</span>,”</span
            >
            <em>IEEE transactions on visualization and computer graphics</em>, vol. 28, no. 1, pp. 1084–1094, Jan. 2022,
            doi: <a href="https://doi.org/10.1109/TVCG.2021.3114829">10.1109/TVCG.2021.3114829</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#chundury_towards_202201"
                aria-label="Return to: , and investigated how to better understand the role of sensory substitution&nbsp;"
                title="Return to: , and investigated how to better understand the role of sensory substitution&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-mack_what_2021" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[93]</div>
          <div class="csl-right-inline">
            K. Mack, E. McDonnell, D. Jain, L. Lu Wang, J. E. Froehlich, and L. Findlater,
            <span
              >“What <span>Do</span> <span>We</span> <span>Mean</span> by &amp;#x201c;<span>Accessibility</span>
              <span>Research</span>&amp;#x201d;? <span>A</span> <span>Literature</span> <span>Survey</span> of
              <span>Accessibility</span> <span>Papers</span> in <span>CHI</span> and <span>ASSETS</span> from 1994 to
              2019,”</span
            >
            in
            <em
              >Proceedings of the 2021 <span>CHI</span> <span>Conference</span> on <span>Human</span>
              <span>Factors</span> in <span>Computing</span> <span>Systems</span></em
            >, May 2021, pp. 1–18. doi:
            <a href="https://doi.org/10.1145/3411764.3445412">10.1145/3411764.3445412</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#mack_what_202101"
                aria-label="Return to: ’s “What do we mean by Accessibility Research?”&nbsp;"
                title="Return to: ’s “What do we mean by Accessibility Research?”&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-xiong_curse_2020" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[94]</div>
          <div class="csl-right-inline">
            C. Xiong, L. Van Weelden, and S. Franconeri,
            <span
              >“The <span>Curse</span> of <span>Knowledge</span> in <span>Visual</span> <span>Data</span>
              <span>Communication</span>,”</span
            >
            <em>IEEE Transactions on Visualization and Computer Graphics</em>, vol. 26, no. 10, pp. 3051–3062, Oct.
            2020, doi: <a href="https://doi.org/10.1109/TVCG.2019.2917689">10.1109/TVCG.2019.2917689</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#xiong_curse_202001"
                aria-label="Return to: In complex cases where a chart has a visual feature with an assumedly obvious takeaway, checking for annotations or textual callouts is important to help avoid interpretive issues&nbsp;"
                title="Return to: In complex cases where a chart has a visual feature with an assumedly obvious takeaway, checking for annotations or textual callouts is important to help avoid interpretive issues&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_data_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[95]</div>
          <div class="csl-right-inline">
            US Government, General Services Administration,
            <span
              >“Data visualizations <span></span> <span>U</span>.<span>S</span>. <span>Web</span> <span>Design</span>
              <span>System</span> (<span>USWDS</span>).”</span
            >
            Available:
            <a href="https://designsystem.digital.gov/components/data-visualizations/"
              >https://designsystem.digital.gov/components/data-visualizations/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_data_nodate01"
                aria-label="Return to: We have included (with permission) an exemplary field artifact as an example of this type of labor in our supplemental materials, which contributed to the United States Government’s project, “Improving Accessibility in Data Visualizations”&nbsp;"
                title="Return to: We have included (with permission) an exemplary field artifact as an example of this type of labor in our supplemental materials, which contributed to the United States Government’s project, “Improving Accessibility in Data Visualizations”&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_improving_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[96]</div>
          <div class="csl-right-inline">
            US Government, 10x,
            <span
              >“Improving <span>Accessibility</span> in <span>Data</span> <span>Visualizations</span> (formerly
              <span>USWDS</span> <span>Visualization</span> <span>Tool</span>) on 10x.”</span
            >
            Available:
            <a
              href="https://trello.com/c/OOOres7a/63-improving-accessibility-in-data-visualizations-formerly-uswds-visualization-tool"
              >https://trello.com/c/OOOres7a/63-improving-accessibility-in-data-visualizations-formerly-uswds-visualization-tool</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_improving_nodate01"
                aria-label="Return to: We have included (with permission) an exemplary field artifact as an example of this type of labor in our supplemental materials, which contributed to the United States Government’s project, “Improving Accessibility in Data Visualizations”&nbsp;"
                title="Return to: We have included (with permission) an exemplary field artifact as an example of this type of labor in our supplemental materials, which contributed to the United States Government’s project, “Improving Accessibility in Data Visualizations”&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-noauthor_w3c_nodate" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[97]</div>
          <div class="csl-right-inline">
            WAI,
            <span>“<span>W3C</span> <span>Accessibility</span> <span>Guidelines</span> (<span>WCAG</span>) 3.0,”</span>
            <span>W3C</span>, {WCAG} {Standard}, 2021. Available:
            <a href="https://www.w3.org/TR/wcag-3.0/">https://www.w3.org/TR/wcag-3.0/</a
            ><span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#noauthor_w3c_nodate01"
                aria-label="Return to: As new research and practices emerge and more community members get involved, Chartability will become an evolving artifact of consensus similar to existing standards bodies&nbsp;"
                title="Return to: As new research and practices emerge and more community members get involved, Chartability will become an evolving artifact of consensus similar to existing standards bodies&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-irani_turkopticon_13" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[98]</div>
          <div class="csl-right-inline">
            L. C. Irani and M. S. Silberman,
            <span>“Turkopticon: Interrupting worker invisibility in amazon mechanical turk,”</span> in
            <em>Proceedings of the SIGCHI conference on human factors in computing systems</em>, 2013, pp. 611–620. doi:
            <a href="https://doi.org/10.1145/2470654.2470742">10.1145/2470654.2470742</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#irani_turkopticon_1301"
                aria-label="Return to: Projects like Turkopticon benefited from the discussion about how a community actually used their tool&nbsp;"
                title="Return to: Projects like Turkopticon benefited from the discussion about how a community actually used their tool&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-scholtz_developing_2011" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[99]</div>
          <div class="csl-right-inline">
            J. Scholtz, <span>“Developing guidelines for assessing visual analytics environments,”</span>
            <em>Information Visualization</em>, vol. 10, no. 3, pp. 212–231, Jul. 2011, doi:
            <a href="https://doi.org/10.1177/1473871611407399">10.1177/1473871611407399</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#scholtz_developing_201101"
                aria-label="Return to: Heuristics are also not new in visualization&nbsp;"
                title="Return to: Heuristics are also not new in visualization&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-braun_clarke_thematic_2006" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[100]</div>
          <div class="csl-right-inline">
            V. Braun and V. Clarke, <span>“Using thematic analysis in psychology,”</span>
            <em>Qualitative Research in Psychology</em>, vol. 3, no. 2, pp. 77–101, 2006, doi:
            <a href="https://doi.org/10.1191/1478088706qp063oa">10.1191/1478088706qp063oa</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#braun_clarke_thematic_200601"
                aria-label="Return to: : After collating these resources (including relevant WCAG criteria), I loosely borrowed from thematic analysis&nbsp;"
                title="Return to: : After collating these resources (including relevant WCAG criteria), I loosely borrowed from thematic analysis&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-oliveira_adapting_2022" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[101]</div>
          <div class="csl-right-inline">
            M. Oliveira and C. Guimarães da Silva,
            <span
              >“Adapting <span>Heuristic</span> <span>Evaluation</span> to <span>Information</span>
              <span>Visualization</span> - <span>A</span> <span>Method</span> for <span>Defining</span> a
              <span>Heuristic</span> <span>Set</span> by <span>Heuristic</span> <span>Grouping</span>.”</span
            >
            INSTICC; SciTePress, pp. 225–232, 2017. doi:
            <a href="https://doi.org/10.5220/0006133202250232">10.5220/0006133202250232</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#oliveira_adapting_202201"
                aria-label="Return to: Heuristics are also not new in visualization&nbsp;"
                title="Return to: Heuristics are also not new in visualization&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-craft_beyond_2005" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[102]</div>
          <div class="csl-right-inline">
            B. Craft and P. Cairns,
            <span>“Beyond guidelines: What can we learn from the visual information seeking mantra?”</span> in
            <em
              >Ninth <span>International</span> <span>Conference</span> on <span>Information</span>
              <span>Visualisation</span> (<span>IV</span>’05)</em
            >, Jul. 2005, pp. 110–118. doi: <a href="https://doi.org/10.1109/IV.2005.28">10.1109/IV.2005.28</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#craft_beyond_200501"
                aria-label="Return to: Heuristics are also not new in visualization&nbsp;"
                title="Return to: Heuristics are also not new in visualization&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-forsell_heuristic_2010" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[103]</div>
          <div class="csl-right-inline">
            C. Forsell and J. Johansson, <span>“An heuristic set for evaluation in information visualization,”</span> in
            <em
              >Proceedings of the <span>International</span> <span>Conference</span> on <span>Advanced</span>
              <span>Visual</span> <span>Interfaces</span></em
            >, May 2010, pp. 199–206. doi:
            <a href="https://doi.org/10.1145/1842993.1843029">10.1145/1842993.1843029</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#forsell_heuristic_201001"
                aria-label="Return to: Heuristics are also not new in visualization&nbsp;"
                title="Return to: Heuristics are also not new in visualization&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-ladner_design_2015" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[104]</div>
          <div class="csl-right-inline">
            R. E. Ladner, <span>“Design for user empowerment,”</span> <em>Interactions</em>, vol. 22, no. 2, pp. 24–29,
            Feb. 2015, doi: <a href="https://doi.org/10.1145/2723869">10.1145/2723869</a>.<span class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#ladner_design_201501"
                aria-label="Return to: Designs must not be rigid in their opinions and ability assumptions and should be designed to be moldable by and adaptive to user needs&nbsp;"
                title="Return to: Designs must not be rigid in their opinions and ability assumptions and should be designed to be moldable by and adaptive to user needs&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
        <div id="ref-gray_reprioritizing_2014" class="csl-entry" role="doc-biblioentry">
          <div class="csl-left-margin">[105]</div>
          <div class="csl-right-inline">
            C. M. Gray, E. Stolterman, and M. A. Siegel,
            <span
              >“Reprioritizing the relationship between <span>HCI</span> research and practice: Bubble-up and
              trickle-down effects,”</span
            >
            in <em>Proceedings of the 2014 conference on <span>Designing</span> interactive systems</em>, Jun. 2014, pp.
            725–734. doi: <a href="https://doi.org/10.1145/2598510.2598595">10.1145/2598510.2598595</a>.<span
              class="reverse-citation"
              ><br />^ Jump up:
              <a
                href="#gray_reprioritizing_201401"
                aria-label="Return to: In Gray’s different models of practitioner-researcher relations, our work is some variation of bubble-up, practitioner-led research&nbsp;"
                title="Return to: In Gray’s different models of practitioner-researcher relations, our work is some variation of bubble-up, practitioner-led research&nbsp;"
                >1</a
              ></span
            >
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
