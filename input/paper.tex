\documentclass[journal]{vgtc}                % final (journal style)
% \documentclass[review,journal]{vgtc}         % review (journal style)
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint,journal]{vgtc}       % preprint (journal style)

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Please use the ``preprint''  option when producing a preprint version
%% for sharing your article on an open access repository

%% Please note that the use of figures other than the optional teaser is not permitted on the first page
%% of the journal version.  Figures should begin on the second page and be
%% in CMYK or Grey scale format, otherwise, colour shifting may occur
%% during the printing process.  Papers submitted with figures other than the optional teaser on the
%% first page will be refused. Also, the teaser figure should only have the
%% width of the abstract as the template enforces it.

%% These few lines make a distinction between latex and pdflatex calls and they
%% bring in essential packages for graphics and font handling.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the path and extension of a graphics file:
%% \includegraphics{diamondrule} is completely sufficient.
%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

%% it is recomended to use ``\autoref{sec:bla}'' instead of ``Fig.~\ref{sec:bla}''
\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{cite}                      % needed to automatically sort the references
\usepackage{tabu}                      % only used for the table example
\usepackage{booktabs}                  % only used for the table example
\usepackage{listings}
\usepackage[skip=3pt]{caption}
%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

\usepackage{xspace,xpunctuate}
\newcommand{\ie}{{i.e.,}\xspace}
\newcommand{\eg}{{e.g.,}\xspace}
\newcommand{\ea}{{et~al\xperiod}\xspace}
\newcommand{\aka}{{a.k.a.}\xspace}
\newcommand{\etc}{{etc\xperiod}\xspace}

%% In preprint mode you may define your own headline. If not, the default IEEE copyright message will appear in preprint mode.
%\preprinttext{To appear in IEEE Transactions on Visualization and Computer Graphics.}

%% In preprint mode, this adds a link to the version of the paper on IEEEXplore
%% Uncomment this line when you produce a preprint version of the article 
%% after the article receives a DOI for the paper from IEEE
%\ieeedoi{xx.xxxx/TVCG.201x.xxxxxxx}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{1580}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}
%% please declare the paper type of your paper to help reviewers, only shown in review mode
%% choices:
%% * algorithm/technique
%% * application/design study
%% * evaluation
%% * system
%% * theory/model
\vgtcpapertype{Systems \& Rendering}

%% Paper title.
\title{Data Navigator: An Accessibility-Centered Data Navigation Toolkit}

%% This is how authors are specified in the journal style

%% indicate IEEE Member or Student Member in form indicated below
% \author{Anonymous}
\author{Frank Elavsky, Lucas Nadolskis, Dominik Moritz}
\authorfooter{
%% insert punctuation at end of each item
\item
 All authors are with Carnegie Mellon University.
 \item
 Frank Elavsky: fje@cmu.edu.
 \item
 Lucas Nadolskis: nadolskis@cmu.edu.
\item
 Dominik Moritz: domoritz@cmu.edu.
}

%other entries to be set up for journal
\shortauthortitle{Elavsky: Data Navigator}
% \shortauthortitle{Elavsky \MakeLowercase{\textit{et al.}}: Data Navigator}
%\shortauthortitle{Firstauthor \MakeLowercase{\textit{et al.}}: Paper Title}

%% Abstract section.
% The lack of accessible data visualizations for people with disabilities remains a significant challenge in current toolkit and practitioner efforts. Existing visualizations often lack underlying structure, fail to engage necessary input modalities, and rely heavily on visual rendering practices. This limitation stems from a scarcity of building materials, such as non-pointer data navigation structures and accessible rendering formats beyond scalable vector graphics (SVG).

% To address this gap, we present Data Navigator, a toolkit based on a graph data structure that supports various data structures and input modalities. It provides an interface for screen reader, keyboard, touch gestures, motion gestures, voice, and custom input methods. By decoupling navigation and visual encodings, Data Navigator empowers visualization practitioners with expressive control over their designs. We offer a high-level system design and a web-based implementation using JavaScript, HTML, and CSS. Through case examples, we demonstrate the replication of best practices, integration with existing toolkits, and development of novel prototypes for accessible navigation.

% Data Navigator represents a step towards making more accessible data experiences easier to design and implement, involving both toolkit makers and visualization practitioners.
\abstract{Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts. Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices. These limitations exclude people with disabilities, especially users of assistive technologies. To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations. Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices. We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes. Data Navigator is a step towards making accessible data visualizations easier to design and implement.%
% There is a gap between techniques we know are effective for accessible data navigation and what tools are currently capable of. Although scalable vector graphics (SVG) and raster images are common formats for data visualizations, they fail to express relationships in a meaningful way. This has resulted in a reliance on tree or list structures inherent in many UI paradigms, which are not generic enough to express relational, spatial, diagrammatic, and geographic information common to visualization. To address these limitations, we propose Data Navigator, a toolkit built on a graph data structure.
} % end of abstract 

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{accessibility, visualization, tools, technical materials, platforms, data interaction}

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

% \begin{CCSXML}
% <ccs2012>
%    <concept>
%        <concept_id>10003120.10003145.10003151</concept_id>
%        <concept_desc>Human-centered computing~Visualization systems and tools</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10003120.10011738.10011776</concept_id>
%        <concept_desc>Human-centered computing~Accessibility systems and tools</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10003120.10003123.10011760</concept_id>
%        <concept_desc>Human-centered computing~Systems and tools for interaction design</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%  </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Human-centered computing~Visualization systems and tools}
% \ccsdesc[500]{Human-centered computing~Accessibility systems and tools}
% \ccsdesc[300]{Human-centered computing~Systems and tools for interaction design}

%% A teaser figure can be included as follows

\teaser{
  \includegraphics[width=\textwidth]{data_navigator.png}
  \caption{Data Navigator provides data visualization libraries and toolkits with accessible data navigation structures, robust input handling, and flexible semantic rendering capabilities.}
  \label{fig:teaser}
}

%% Uncomment below to disable the manuscript note
%\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the

%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command

\firstsection{Introduction}

\maketitle

While there is a growing interest in making data visualizations more accessible for people with disabilities, current toolkit and practitioner efforts have not risen to the challenge at scale. Major data visualization tools and ecosystems predominantly produce inaccessible artifacts for many users with disabilities. We believe this is largely a gap caused by a lack of underlying structure in most visualizations, failure to engage the input modalities used by people with disabilities, and over-reliance on visual-only rendering practices.

Users who are blind or low vision commonly use screen readers and users with motor and dexterity disabilities often do not use "pointer" (precise mouse and touch) based input technology when interacting with digital interfaces. Many users with motor and dexterity disabilities use discrete navigation controls, either sequentially using keyboard-like input, or directly using voice or text commands.

Most interactive visualizations simply focus on pointer-based input: they can be clicked or tapped, hovered, and selected in order to perform analytical tasks. This excludes non-pointer input technologies. These devices require consideration for the navigation structure and underlying semantics of a visual interface.

However, building navigable spatial and relational interfaces is a difficult task with current resources.

Raster images, arguably the most common format for creating and disseminating data visualizations, currently cannot be made into navigable structures. These are only described using alt text, which limits their usefulness to screen reader users.

Unfortunately, more accessible rendering formats like SVG with ARIA (accessible rich internet applications) properties are more resource intensive than raster approaches, like WebGL-powered HTML canvas or pre-rendered PNG files. SVG puts a burden on low-bandwidth users and a ceiling on how many data points can be rendered in memory.

In addition, ARIA itself has 2 major limitations. First, when added to interface elements, ARIA only provides \textit{screen reader} access, which means that developers must build a solution from scratch for other navigation input modalities. Second, ARIA's linear navigation structure can be time-consuming for screen reader users if a visualization has many elements. This may impede how essential insights and relationships are understood~\cite{Sorge2016Polyfilling,Godfrey2018Accessible,Zong2022Rich,Thompson2023Chart,Jung2022Communicating,Sharif2021Understanding}.

Some emerging approaches have sought to address this serial limitation of data navigation and provide richer experiences for screen reader users~\cite{Sorge2016Polyfilling,Godfrey2018Accessible,Zong2022Rich,Thompson2023Chart}. However, these approaches rely on a tree-based navigation structure which is often not an appropriate choice for visualizations of relational, spatial, diagrammatic, or geographic data. Many visualization structures are currently unaddressed.

Zong \ea stress that in order to realize richer, more accessible data visualizations, the responsibility must be shared by ``toolkit makers,'' the practitioners who design, build, and maintain visualization authoring technologies~\cite{Zong2022Rich}. Our contribution is towards that aim, to make more accessible data experiences easier to design and implement within existing visualization work.

We present Data Navigator. Data Navigator is a toolkit built on a graph data structure, within which a broad array of common data structures can be expressed (including list, tree, graph, relational, spatial, diagrammatic, and geographic structures). Data Navigator also exposes an interface that supports interactions via screen reader, keyboard, gesture-based touch, motion gesture, voice, as well as fabricated and DIY input modalities. Data Navigator provides expressive structure and semantic rendering capabilities as well as the ability for developers to use their own, preferred method of rendering.

Data Navigator builds upon human-studies motivated work on accessible navigation~\cite{Zong2022Rich,Thompson2023Chart} towards a more generalizable resource for visualization practitioners. We contribute a high-level system design for our node-edge graph-based solution as well as an implementation of this system on the web, using JavaScript, HTML, and CSS. Through our case examples we also demonstrate that our generalized approach is suitable for replication of existing best practices from other systems, integration into existing visualization toolkit ecosystems, and development of novel prototypes for accessible navigation. We illustrate how Data Navigator's use of generic edges, dynamic navigation rules, and loose coupling between navigation and visual encodings provides practitioners robust, expressive, control over their system designs.

\section{Related Work}
Our contribution is an attempt to bridge the gap between research and practice more effectively across broad ecosystems in order to enable deeper and more expressive accessible data navigation interfaces. Below we outline the prior research and standards that inform our project, a breakdown of existing visualization toolkit approaches to data navigation, and then accessible input device considerations.

\subsection{Accessibility research and standards in visualization}
Research and standards are both somewhat limited by a strong bias towards visual disabilities. In \textit{Chartability}, 36 of the 50 criteria related to accessible visualization considerations involve visual disabilities~\cite{Elavsky2022Chartability, Fan2023Accessibility}. Marriott \ea also found that visual disability considerations are the primary focus of data visualization literature~\cite{Marriott2021Inclusive}, leaving the barriers that many other demographics face unstudied.

However, despite the heavy focus on visual disabilities, the work that does exist in the visualization community is deeply valuable and serves as an important starting point for our technical contribution.

\subsubsection{Accessible navigation design considerations}

Zong \ea's research, which was conducted as in-depth co-design work and validated in usability studies involving blind participants, presented a design space for accessible, rich screen reader navigation of data visualizations. They organized their design space into \textit{structure, navigation,} and \textit{description} considerations and demonstrated example \textit{structural}, \textit{spatial}, and \textit{direct} tree-based approaches~\cite{Zong2022Rich}.

\textit{Chart Reader} also engaged these design space considerations in their co-design work on accessible data navigation structures~\cite{Thompson2023Chart}. We consider these design dimensions as the best starting point for our work, bridging the gap between research and toolkits.

There are additional research projects that have focused on accessible data navigation and interaction ~\cite{Sharif2022VoxLens,Sorge2016Polyfilling,Godfrey2018Accessible,Sharif2018evoGraphs}. These contributions explore a range of different interaction structures, including lists, trees, and tables of information as well as direct access methods such as voice interface commands and simple, pre-determined questions.

\subsubsection{Accessible visualization: understanding users}

A wide array of emerging research projects investigate screen reader users needs, barriers, and preferences, and offer guidelines, models, and considerations for creating accessible data visualizations~\cite{Sharif2021Understanding,Lundgard2022Accessible,Chundury2022Towards,Fan2023Accessibility}. Jung \ea offer guidance to consider the order of information in textual descriptions and during navigation~\cite{Jung2022Communicating}. Kim \ea collected screen reader users' questions when interacting with data visualizations, which could open the door for more natural language data interaction~\cite{Kim2023Exploring}.

\subsubsection{Accessibility standards and guidelines}
In the space of research, there has been a growing interest in developing guidelines for practitioners~\cite{Elavsky2022Chartability, Durant2022Ten} and even applying guidelines as a method of validation alongside human studies evaluations and co-design~\cite{Lundgard2019Sociotechnical,Zong2022Rich,Lundgard2022Accessible,Fan2023Accessibility}. Unfortunately, most accessibility standards and guidelines do not explicitly engage how to structure data navigation. 

Despite this, existing accessibility standards bodies like the Web Content Accessibility Guidelines do stress the importance of accurate, functional semantics in order for screen reader users to know how to interact with elements~\cite{WAI2021Semantics}. For interactive visualizations this means that button-like or link-like behavior should expressly be made using elements that are semantically buttons and links. Our system should be capable of expressing meaningful semantics to users of assistive technologies.

\subsection{Visualization toolkits and technical work}
Unfortunately while many data visualization toolkits offer some degree of accessible navigation and interaction capabilities to developers, very few toolkits currently out there offer control over the important aspects of accessible data navigation design. Replicating existing research and strategies, remediating toolkit ecosystems, and building novel prototypes are all difficult or impossible to do due to the current lack of toolkit capabilities.

Existing data visualization toolkits have 3 major limitations that we wanted to address in the design of Data Navigator:
\begin{enumerate}
  \itemsep-0.4em
  \item \textbf{Built on visual materials}: toolkits produce either raster or SVG-based visualizations, neither of which are focused towards designing navigable, semantic structures. As a consequence, many visualizations are simply entirely inaccessible.
  \item \textbf{Lacking relational expressiveness}: When data navigation \textit{is} provided, the navigation is based on either a tree or list structure (see~\autoref{existing}). The consequence of this limitation is that many other non-list and non-tree data relationships become difficult or impossible to represent without overly tedious navigation or inefficient architecture.
  \item \textbf{Designed only for screen reader interaction}: When \textit{accessible} data navigation is provided, it is generally only made possible through SVG with ARIA (Accessible Rich Internet Application) attributes. ARIA is primarily only leveraged by screen readers~\cite{WAI2017ARIA}. If a data element can be clicked and performs some form of function, only direct pointer (mouse and touch) and screen reader users are included. The consequence of this is that a wide array of other input devices, many used as assistive technologies by people with motor and dexterity disabilities, are excluded.
\end{enumerate}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/state-of-the-art.png}
  \caption{Existing accessibility trees and lists, shown using node-edge graph conventions. (*) Denotes only \textit{screen reader} access. (**) Denotes \textit{screen reader}, \textit{keyboard-only}, and \textit{pointer} access as well.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{existing}
\end{figure}

\subsubsection{Rich, tree-based approaches}
De-coupling rendered, visual structures from meaningful and effective navigation experiences can provide richer experiences for screen reader users~\cite{Zong2022Rich}. Prior research and industry work, with the exception of the \textit{Visa Chart Components} library~\cite{VisaVisa}, has relied heavily on a 1 to 1 relationship between structure (the encoded marks) and navigation. This emerging work is significant, because it paves the way for considering the design dimensions of accessible data interaction and navigation without dependence on a visually encoded space.

\textit{Olli's} approach has been to build ready-to-go adaptors that automatically build multiple tree structures for a few ecosystems (\textit{Vega}, \textit{Vega-Lite}, and \textit{Observable Plot}) and is entirely uncoupled from a data visualization's graphics. Their approach renders navigable tree structures \textit{underneath} a visualization.

Other than \textit{Olli}, \textit{Highcharts}~\cite{HighsoftHighcharts}, \textit{Visa Chart Components}, and \textit{Progressive Accessibility Solutions'} visualization toolkits~\cite{Sorge2016Polyfilling,Godfrey2018Accessible} also primarily provide tree and list navigation structures across all of their chart types. These toolkits render their structures \textit{upon} the visualization's graphic space. These tools also provide some degree of support for other assistive technologies and input modalities, although are limited exclusively to SVG rendering. 

Unfortunately, these toolkits lack capabilities for dealing with graph, relational, spatial, diagrammatic, and geographic data structures.

\subsubsection{Serial, list-based approaches}
Toolkits like \textit{Vega-Lite}~\cite{Satyanarayan2017VegaLite} and \textit{Observable Plot} only provide basic screen reader support through ARIA attributes when visualizations are rendered using SVG. These libraries do not currently provide additional access to other assistive technologies and input modalities.

Microsoft's \textit{PowerBI} largely uses a serial structure, although it has tree-like elements as well. \textit{PowerBI} generally provides the same access to keyboard users as it does to screen readers, although not completely.

\subsubsection{No navigation provided}
Other visualization tools, like \textit{ggplot2} or \textit{Datawrapper}, \textit{Tableau}, as well as both \textit{Vega-Lite} and \textit{Highcharts} (when rendering to canvas), produce raster images and have no navigable structure available. Raster, or pixel-based graphics have been an accessibility burden since the early days of graphical user interface development~\cite{Boyd1990Graphical}. Practitioners who use these toolkits can only provide alternative text.

% \subsubsection{Automatic description generation}
% A considerable amount of data visualization and accessibility literature focuses on technical contributions that look to automate alt text descriptions or captions for data visualizations ~\cite{Choi2019Visualizing,Balaji2018Chart,Chen2019Neural,Chen2020Figure,Lai2020Automatic,Obeid2020Chart,Qian2021Generating,Sharif2018evoGraphs}. 

% Most recent work by Kim \ea built a prototype that automatically converts a chart specification of a treemap into a description and tested it with blind users~\cite{Kim2023Explain}. While technical contributions that attempt to automate description generation through deterministic or model-driven approaches are closely related to our project and on-going, our interest is primarily in a different direction than hands-off automation: providing developers with a robust ability to express the design dimensions of a data navigation scheme.

\subsection{Considering assistive technologies and input devices}
Modern data visualizations may contain functional capabilities such as the ability to hover, click, select, drag, or perform some analytical tasks over the elements of the visualization space~\cite{Satyanarayan2017VegaLite}. Virtually all of these analytical capabilities are designed for use with a mouse.

Input device consideration can roughly be organized as either \textit{pointer-based} (such as a mouse or direct touch) or \textit{non-pointer based} (which may employ speech recognition or sequential, discrete navigation such as with a keyboard). Assistive pointer-based devices, such as a head-mounted touch stylus, can typically perform any actions that a mouse can and are therefore served by current interactive visualizations. However, assistive non-pointer devices, such as a tongue, foot, or breath-operated switch, are not.

By only providing pointer-based interactivity, modern interactive visualizations exclude users who leverage non-pointer based input, who are most commonly people with motor and dexterity disabilities. And unfortunately, there is a complete lack of engagement with these populations in the data visualization research community~\cite{Marriott2021Inclusive}.

By comparison, the broader accessibility and HCI research communities have rich engagement with interaction and assistive technologies for users with motor and dexterity disabilities. Most research either focuses broadly on physical peripheral devices or sensors~\cite{Siean2021}, wearables~\cite{Sarsenbayeva2022}, or DIY making and fabrication~\cite{Hurst2013Making}.

The DIY making space involves a broad spectrum of complex input devices and materials, such as fabricating with wood and sensors for children with disabilities~\cite{Lin2014}, 3D printed materials for rehabilitation professionals~\cite{Giraud2016}, and even using produce-based input (such as bananas and cucumbers) for aging populations~\cite{Rogers2014}.

Broadly, both research and practical developments related to accessible, non-pointer input are much further ahead than data visualization research and practice. Our goal for Data Navigator is to provide a technical resource towards engaging this under-addressed space.

\section{System Design}
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{figures/system-design.png}
%   \caption{Data Navigator provides data visualization libraries and toolkits with accessible data navigation structures and robust input handling.}
%   \label{pointer}
% \end{figure}

We categorized our system design goals into design considerations for \textit{Structure}, \textit{Input}, and \textit{Rendering}:
\begin{enumerate}
  \itemsep-0.4em
  \item \textbf{Generic structure and navigation specification}: Human studies work has validated that lists, tables, trees, and even pseudo-treelike and direct structure types are all valuable to users in different contexts and with different considerations. Our system must be able to work with all of these as well as less frequently-used structures (spatial, relational, geographic, graph, and diagrammatic).
  \item \textbf{Robust input handling}: Blind and low vision users may use combinations of different assistive technologies, such as magnifiers, voice interfaces, and screen readers. Users with motor impairments may rely on voice, gesture, eye-tracking, keyboard-interface peripherals (like sip-and-puffs or switches), or fabricated devices. Both the developer and user should therefore be able to leverage and customize a broad range of input types, including the above as well as fabricated, adaptive, and future input modalities.
  \item \textbf{Flexible rendering and semantics}: Visuals may or may not be necessary to render to demonstrate Data Navigator's structure. In addition, much of the latest research has shown that different screen reader users may prefer different orders of information and at different levels of verbosity. In addition, the context of tasks the user is performing as well as the nature of the data itself may influence the design of semantic descriptions and visual indications for elements. Data Navigator must provide a high degree of flexibility and control.
\end{enumerate}

To help bridge the gaps between research and standards knowledge about best practices and building an effective toolkit for practitioners, we intend for Data Navigator to provide both \textit{exploratory support} and \textit{vocabulary correspondence}~\cite{Maayan2020Domain}.

In particular, our ideal users are developers who specify data visualizations using code. To that aim, we intend to provide \textit{exploratory support} through generic, dynamic, and flexible system design decisions. Our system is expressive and customizable, which encourages exploration of different options.

And we also want the API to include properties that have conceptual and \textit{vocabulary correspondence} to our design considerations. Each design consideration (\textit{Structure}, \textit{Input}, and \textit{Rendering}) are separately composable, modular subsystems of Data Navigator that can be used independently or in tandem with one another.

% The first major contribution in the design of Data Navigator is to use node-edge data as the substrate for our navigation system. In a generic Backus-Naur Form~\cite{Backus1963Revised}, the high level details of our system grammar are as follows:

% \begin{lstlisting}[
%     basicstyle=\small
% ]
%  <dn> ::= <structure> <navigation> <rendering>
%  <structure> ::= <nodes> <edges>
%  <navigation> ::= <nav-rule>+
%  <nodes> ::= <node>+
%  <edges> ::= <edge>+
%  <rendering> ::= <location> <id> <dimensions> [<on-demand>]
%  <nav-rule> ::= <name> <edge-types> <direction> [<inputs>]
%  <node> ::= <id> <datum> [<spatial>] <edge-ids> <semantics>
%  <edge> ::= <id> <source> <target> <edge-type>
%  <spatial> ::= <coords> <shape>
%  <coords> ::= <x> <y>
%  <shape> ::= <dimensions> | <path>
%  <dimensions> ::= <width> <height>
%  <source> ::= source() | <id>
%  <target> ::= target() | <id>
%  <semantics> ::= <element-type> <role> <description>
% \end{lstlisting}

In this paper we present an implementation of our system using JavaScript, HTML, and CSS on the web. The demonstration of our system is best suited to the web due to the nature of existing, accessible building blocks (HTML), which resolve many of the semantic complexities and logic involved in enabling screen readers to programmatically navigate and announce meaningful information to users. In addition, many existing visualization toolkits target the web as an output platform and we believe that this is the best starting point for adoption and use of Data Navigator. However, this system design could be implemented as a toolkit in other environments with proper consideration for input device handling and screen reader semantics.

\subsection{Structure}
% \begin{lstlisting}[
%     basicstyle=\small
% ]
%  <dn> ::= <structure> <input> <rendering>
% \end{lstlisting}
\subsubsection{Beyond trees: towards an accessibility \textit{graph}}

The first major contribution in the design of Data Navigator is to use node-edge data as the substrate for our navigation system.

The most important argument in favor of using a graph-based approach is that a graph can construct virtually any other data structure type (see \autoref{existing}), including list, table, tree, spatial, geographic, and diagrammatic structures. Graphs are generic, which enables them to represent structures both in current and future interface practices~\cite{Gansner2000Open}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/geoviz.png}
  \caption{\textbf{A.} Map of engineers per capita of US states. \textbf{B.} Tree representation of the map data where states are listed alphabetically and also include links to neighboring states. The structure repeats itself if users navigate in a loop. \textbf{C.} Graph representation with the same navigation potential without redundant rendering.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{map}
\end{figure}

To demonstrate our point, the most recent emerging work with advancements in accessible data navigation used node-edge diagrams to demonstrate their tree-like structures~\cite{Zong2022Rich, Thompson2023Chart} similar to \autoref{existing}, \autoref{static}, and \autoref{vega-lite}. This is because trees are a form of node-edge graph, but with a root, siblings, parents, and children as sub-types of nodes that generally have rules for how they relate to one another. 

Node-edge graph structures prioritize direct relationships. Examples of common direct relationships in visualization are boundaries on maps (see \autoref{map}), flows and cycles, data with multiple high level tree structures pointing to the same child datasets (such as \textit{Olli} in \autoref{existing}), or even just in diagrammatic, graph-based visualizations.

A graph structure allows for direct access between information elements that are not just part of the input data or 1:1 rendered elements, but may also have perceptual or human-attributed meaning. Examples of this might include semantic or task-based relationships, such as navigating to annotations or callouts, between visual-analytic features like trends, comparisons, or outliers. Spatial layouts such as intersections of sets or parallel vectors (see \autoref{section:codesign}), or even relationships to information outside of a visualization and back into it (like in \autoref{semantics}) are enabled by a graph structure.

\subsubsection{Graph structures are more computationally efficient}

Data visualizations often portray information that becomes difficult to handle when using trees and lists. The distance users must travel between relational elements is significant in lists while redundancy when navigating relational elements in trees can be problematic.

As an example of this, often a data table or list of locations are used in conjunction to a map, such as listing all 50 states alphabetically along with relevant information. The list itself is expensive to navigate and may not provide any relationship information about which states border others, let alone ways to easily and directly access those states.

Part of the visual design justification of using a map instead of a table is for sighted individuals to understand how geospatial information may interact with a given variable. The spatial relationships matter. But when supplementing the list of states with sub-lists for each state's bordering states (see \autoref{map}), it produces redundancy in the rendered result. The rendered data contains circular connections between nodes but must render every reference, producing a computational resource creep and cluttered user experience that can be difficult to exit.

\subsubsection{Specific edge instances and generic edges}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/simple_movement.png}
  \caption{An example of how a single edge instance references a navigation rule and can even have multiple navigation rules. A navigation rule can be referenced by multiple edges.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{simple_movement}
\end{figure}

In Data Navigator, nodes are \textit{objects} that always contain a set of edges, where each edge contains a minimum of 4 pieces of information: a unique identifier, a source, a target, and navigation rules. These properties are only accessed when a navigation event occurs on a node with an edge that contains a reference to a rule for that navigation event. Navigation rules may be unique to an edge instance or shared among other edge instances.

The source and target properties of edges are either ids that reference node instances (see \autoref{simple_movement}) or \textit{functions} (see \autoref{dynamic_movement}). Because some edges in a graph may be directed or not, non-directed graphs can use source and target properties to arbitrarily refer to either node attached to an edge.

Generic functions for source or target properties can link nodes to other nodes based on changing content, structure, or behavior that may be difficult or impossible to determine before a user navigates the structure.

Function calling also allows some edges to be \textit{purely} generic. An example of a reasonable use case of a purely generic edge is in \autoref{dynamic_movement}, where the source is a function which returns the present node and the target is whichever node the user was on previously. This single edge may then be part of every node's set of edges, enabling users to have a simple \textit{undo} navigation control without creating an \textit{undo} edge unique to every source node.

Using this pattern, it is possible to have fully navigable structures using only generic edges.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/dynamic_movement.png}
  \caption{A generic edge, such as ``any-return'' can be applied to any node. Function calls handle dynamically assigning the edge's source and target nodes on-demand.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{dynamic_movement}
\end{figure}

\subsection{Input}
\subsubsection{Abstracted navigation facilitates agnostic input}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/inputs.png}
  \caption{An example navigation rule to move ``left'' can be called as a method by an event from any input modality. Some examples include common modalities such as touch swiping (\textbf{A}) or speaking ``left'' (\textbf{B}). This also includes advanced or future modalities such as gesture recognition (\textbf{C}) or touch-activated, fabricated interfaces (\textbf{D}).}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{inputs}
\end{figure}
Navigation rules in Data Navigator (see \autoref{simple_movement} and \autoref{dynamic_movement}) are created alongside the node-edge structure. Edges reference rules for navigation. However, these rules are generic and agnostic to the specifics of input modalities and can be invoked as methods by virtually any detected user input event (see \autoref{inputs}).

Navigation rules are objects with a unique name, ideally as a noun or verb in natural language that refers to a direction or location, a movement direction (a binary used to determine moving towards the source or target of an edge), and optionally any known user inputs that activate that navigation, such as a keyboard keypress event name.

It is important for a system to abstract navigation events so that inputs can be uncoupled from the logic of Data Navigator. This allows higher level software or hardware logic to handle input validation while Data Navigator is just responsible for acting on validated input.

Later in our first case example (\autoref{section:raster}), we demonstrate an application that handles screen reader, keyboard, mouse and touch (pointer) swiping, hand gestures, typed text, and speech recognition input. Abstract navigation namespaces can be called by any of these input methods.

Additionally, since navigation rules are flexible, end users can also supply their own key-bind remapping preferences or input validation rules if developers provide them with an interface.

Because calling a navigation method is abstract, users can even supply events from their own input modalities as long they have access to either a text input interface or access to Data Navigator's navigation methods. Our demonstration material (in \autoref{section:raster}) also includes handling for DIY fabricated interfaces, which are important in accessibility maker spaces. We chose a produce-based interface~\cite{Rogers2014}, since it was an easy and low cost proof of concept.

We believe that enabling agnostic input provides a rich space for future research projects. In addition, browser addons and assistive technologies could both leverage this flexible interface for end users.

\subsubsection{Discrete, sequential input opens new avenues}
The \textit{keyboard interface} is considered foundational for many assistive devices, which leverage this technology for discrete, sequential, non-pointer navigation and interaction~\cite{WAI2017Keyboard}. Desktop screen readers are the most common example of an assistive technology device that leverages the keyboard interface, however single or limited button switches, sip-and-puff devices, on-screen keyboards, and many refreshable braille displays do as well. Support for the keyboard interface by default in turn provides all discrete, sequential input devices with access as well.

However by basing Data Navigator's foundational infrastructure on a keyboard-like modality, this also provides designers and developers new avenues to imagine how existing direct, pointer-based, or continuous inputs can map to discrete, sequential navigation experiences.

For example, with mobile screen readers this already happens: screen reader users swipe and tap on their screen to sequentially navigate, but the exact pixel locations of their swiping and tapping generally does not matter. Their current focus position is discrete and determined by the screen reader software.

Data Navigator therefore allows for many new possibilities. One possibility is that sighted mouse and touch users may now also swipe their way through dense plots or use small interfaces (such as on mobile devices) that may otherwise be too hard to precisely tap. Data Navigator optionally removes the accessibility barriers sometimes posed by precision-based input in visualizations.

Data Navigator does not have to be in conflict with precision-based input, either. A discrete, sequential navigation infrastructure can be used in tandem with precision-based pointer events as well as instant access when coupled with voice commands and search features.

\subsection{Rendering}

\subsubsection{Flexible node semantics provide freedom}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/semantics.png}
  \caption{An example of how navigation within Data Navigator could use semantic nodes as hyperlinks to provide access to other areas in an application. Alabama has a child node ``Counties'' which is a semantic HTML link element pointing to a table of counties, outside of Data Navigator's graph structure. A link is provided to return.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{semantics}
\end{figure}

Nodes in Data Navigator are semantically flexible. This is because the marks in a data visualization may represent many things, that are either dependent on the data or the user interface materials.

Since our toolkit implementation is in JavaScript and HTML, our map example from \autoref{map} might use image semantics for states, alongside a description of the data relevant to that node. However since semantics are flexible in this way, Data Navigator could also be used to integrate into a larger ecosystem, with nodes rendered as hyperlinks to tables or other elements such as in \autoref{semantics}.

The concept of using node-edge graphs can even extend to have ``nodes'' that are entirely different parts of a document or tool, as well as integrated into the explicit structure provided by Data Navigator. In some accessibility toolkits, nodes are geometries without functional semantics~\cite{Satyanarayan2017VegaLite} or list items nested within lists~\cite{Blanco2022olli}. But in Data Navigator, nodes can semantically be buttons, links, or any HTML element. Interactive data visualizations sometimes demand more flexible node semantics than geometries or lists.

\subsubsection{Loose-coupling to visuals enables expressiveness}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/path.png}
  \caption{\textbf{A.} The data specified for a node with a reference to separate data that is used to render that node. \textbf{B.} The node will render as a path at the specified Cartesian coordinates. \textbf{C.} This rendered node may then be placed over a visual.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{path}
\end{figure}

One of the most significant technical limitations of existing data visualization toolkits with regards to accessibility is that they rely on visual substrate, or visual materials, in order to produce data visualizations. In the case of static, raster images such as png files or WebGL and canvas elements on the web, there are no interface properties at all exposed to screen readers for programmatic exploration and interaction.

If raster images are used, they generally cannot be changed after rendering. However, according to web accessibility standards, elements must have a visual indicator provided when focused~\cite{WAI2016Focus}.

Since Data Navigator navigates using focus, an indicator must be rendered alongside the node semantics. But \textit{what} is focused visually and \textit{where} it is depends on different design needs.

In \textit{Visa Chart Components}, chart elements can be \textit{selected}, so the focus indication is visible over the existing elements in the chart space. The design choice to have interactive visual elements located within a chart or graph is also common in other toolkits that provide accessible focus indication, such as \textit{Highcharts}, \textit{PowerBI}, and \textit{SAS Graphics Accelerator}.

However, some visualization toolkits create accessible structures entirely uncoupled from visual space~\cite{Blanco2022olli}, so focus indication is provided beneath or beside the chart, not over it.

Due to the different ways that accessibility might be provided, Data Navigator enables developers to have complete control over the rendering of which focus elements they want, in what styling, and where. This can accommodate both un-coupled and visually-coupled approaches to focusing and more.

Data Navigator's focus is \textit{uncoupled} by default and may even be used independent of any existing graphics at all. Rendering information may be passed to Data Navigator for it to render (like in \autoref{path}) or developers can provide their own rendered elements and simply use Data Navigator to move between them.

Because of Data Navigator's approach to rendering focusable elements, designers and developers can provide fully customized annotations, graphics, text, or marks that may not be not part of the original visual space or elements. One example of this might be adding an outlined path to a collective cross-stack group of bars in a stacked bar chart (see \autoref{path}).

Loose-coupling in this way provides robust flexibility to designers and developers to handle navigation paths and stories through a data visualization, even in bespoke or hand-crafted ways.

\subsubsection{On-demand node rendering is efficient}
Practitioners care about performance and so do users. Practitioner toolkits often focus on lazy-loading techniques where accessibility elements are rendered on-demand rather than all in-memory up front~\cite{Elavsky2021Method,Zong2022Rich,Blanco2022olli}.

Data Navigator's nodes are rendered \textit{on-demand} by default. Data Navigator only renders the node that is about to be focused by the user and after it is focused, the previously focused node is deleted from memory. This technique has advantages in cases where datasets are large or users have lower computational bandwidth available. However, there are cases where practitioners may want to render all of Data Navigator's structure in memory, such as server-side rendering or equivalent. Pre-rendering may be optionally enabled.

\section{Case Examples}
We built example prototypes using our JavaScript implementation of Data Navigator, available open source at our \href{https://github.com/cmudig/data-navigator}{GitHub repository}.

Our first two prototype case examples represent some of the most powerful parts of Data Navigator as a system while reproducing known and effective data navigation patterns from existing industry and research projects. We provide a final case example as a co-design session that demonstrates how Data Navigator may be used to rapidly build new designs.

\subsection{Augmenting a Static, Raster Visualization}
\label{section:raster}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{figures/static.png}
  \caption{\textbf{A.} A raster (png) visualization of a stacked bar chart showing how 4 English teams performed across 3 major trophy contests. \textbf{B.} An example navigation schema that allows children nodes to have 2 parents (two tree structures intersecting), one for contests and one for teams. \textbf{C.} An example of Data Navigator's navigation logic abstraction, which allows edge types to have programmatic sources, targets, and rules, such as a single rule that gives all nodes a edge to exit the visualization. \textbf{D.} An instantiation of the schema, showing all corresponding rendered nodes and their edge types according to the schema design and navigation rules.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{static}
\end{figure}

The first case example (shown in \autoref{static}) builds on an online JavaScript visualization library, \textit{Highcharts}. \textit{Highcharts} already provides relatively robust data navigation handling out of the box for screen reader, keyboard, and even voice recognition interface technologies, such as \textit{Dragon Naturally Speaking}. However, these capabilities are only provided when the chart is rendered using SVG. Developers have several other rendering options available, including WebGL, which is significantly more efficient~\cite{HighsoftBoost}. We wanted to demonstrate that Data Navigator can provide a navigable data structure even if the underlying visualization is a raster image.

For our case example, we exported a png file using the built in menu of a sample stacked bar chart retrieved from their online demos~\cite{HighchartsStacked}. We selected a stacked bar chart because it allows us to demonstrate how two tree structures may interact and share the same children nodes.

We recorded the data and hand-created all of the geometries and their spatial coordinates using \textit{Figma}, by tracing lines over the raster image's geometries (see samples of the data and traced geometries in \autoref{path}). While this method was efficient for building an initial prototype, \autoref{section:ecosystem} engages deterministic methods for extracting and producing the nodes, edges, and descriptions required by Data Navigator automatically and at scale.

The visualization we selected represents 4 English football teams, \textit{Arsenal, Chelsea, Liverpool,} and \textit{Manchester United} and how many trophies they won across 3 contests, \textit{BPL, FA Cup,} and \textit{CL}.

We chose a schema design that arranged the \textit{contests} to be navigable across one dimension of movement (\textit{up} and \textit{down}) while the \textit{teams} are navigable across a perpendicular dimension of movement (\textit{left} and \textit{right}). This 2-axis style of navigation is used by \textit{Highcharts} (when rendering as SVG) and \textit{Visa Chart Components}. We also chose these directions because it is coincidental that their visual affordance is closely coupled with the navigation design (the x axis is ordered \textit{left} to \textit{right} and since the bars are stacked, \textit{up} and \textit{down} can move within the stack). These directions can also be applied to the axis categories and legend categories as well, moving \textit{left} and \textit{right} across the entire \textit{team's} stacks or up and down across the entire \textit{contest's} groupings.

Using a keyboard, a user might enter this schema and navigate to the legend, where they could press \textit{Enter} to then focus the legend's first child, pictured in \autoref{path}. Pressing up or down navigates in a circular fashion among the \textit{contest} groupings. Pressing \textit{Enter} again then focuses the first child element of that \textit{contest}, all of which are in the \textit{Arsenal} group, since it is the first group along the x axis. A user can then navigate \textit{up, down, left,} and \textit{right} among children. Pressing \textit{L Key} moves the user back up towards the contest while pressing \textit{Backspace} moves the user up towards the x axis. The x axis and \textit{team} groupings represent the second tree which intersects the first (the \textit{contests}).

Our first case example includes handling for additional input modalities beyond screen readers and keyboards, including a hand gesture recognition model, swipe-based touch navigation, and text input (which can be controlled using voice recognition software).

\subsubsection{Discussion}
Our first case example demonstrates several of the most important capabilities of Data Navigator, namely that practitioners can add accessible navigation to previously inaccessible, static, raster image formats and that a wide variety of input modalities are supported easily.

Widely-used toolkits like \textit{Vega-Lite}, \textit{Highcharts}, and \textit{D3}~\cite{Bostock2011D3} allow practitioners to choose SVG and canvas-based rendering methods. Data Navigator's affordances help overcome the lack of semantic structure in canvas-based rendering, allowing developers to take advantage of its processing and memory efficiency.

Notably in addition to these capabilities, the visual focus highlighting added was entirely bespoke (as in~\autoref{path}) and the navigation paths through the visual were based on our design intentions, not an extracted view or underlying architecture such as render order. This demonstrates that our system provides a significant degree of freedom and control for designers and developers.

As a final discussion point, the resulting visualization contains no automatically detectable accessibility conformance failures according to the W3C's Web Accessibility Initiative's accessibility evaluation tool, \textit{WAVE}~\cite{WebAIMWAVE}. It is important for any technology developed to also meet minimum requirements for accessibility~\cite{Lundgard2019Sociotechnical,Lundgard2022Accessible,Zong2022Rich,Elavsky2022Chartability}, even when following best-practices and research.

\subsection{Building Data Navigation for a Toolkit Ecosystem}
\label{section:ecosystem}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/vega-lite.png}
  \caption{\textbf{A.} Various charts from \textit{Vega-Lite} share the same general structures with each other when rendered using canvas (\textbf{B}) or SVG (\textbf{C}). \textbf{D.} With Data Navigator, we replicated the existing SVG navigation pattern (\textbf{C}) but used a canvas-based rendering for the visualization. \textbf{E.} We also improved the navigation scheme to nest marks within a mark group to allow users to skip them, if needed.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{vega-lite}
\end{figure}

Our second case example, shown in \autoref{vega-lite}, builds on \textit{Vega-Lite}. As shown in \autoref{existing}, \textit{Vega-Lite} offers basic screen reader navigation but provides no navigation at all when rendered using canvas.

While it might be a tedious design choice to allow every mark in a visualization to be serially accessible to screen reader users, we nevertheless set out to build a generic ingestion function that would take a \textit{Vega-Lite View} object and deterministically recreate their existing SVG navigation structure in Data Navigator. This way users would have the same experience between SVG rendered charts and all current and future rendering options that \textit{Vega-Lite} offers to developers. 

Notably, \textit{Vega-Lite} does not explicitly manipulate the navigation order at all when rendering with SVG. ARIA is simply provided to allow screen reader users to access each mark in the visualization in the order the mark appears in the DOM (which is the order it was rendered). The legend appears after the marks in our schema for this reason because \textit{Vega-Lite} renders the legend after marks. This choice of ordering is for visual reasons: z-axis placement is currently based on render order in SVG and \textit{Vega-Lite} wants their legend visually on top of the rendered marks.

In addition to mimicking their existing SVG navigation strategy, we also created a way to nest all of the marks within a group so that users can skip past them and drill in on-demand, which is a valuable pattern when dealing with situations where providing a mark-level fidelity of information may not be relevant to a user's needs by default~\cite{Shneiderman2003Eyes,Zong2022Rich}.

In order to deterministically supply Data Navigator with accurate information about any given \textit{Vega-Lite} visualization, we built 3 functions: one that takes a \textit{Vega-Lite View} as input and extracts meaningful nodes, one that produces edges based on those nodes, and one to describe our nodes in a meaningful way for screen reader users. These generic functions technically work on all existing \textit{Vega-Lite} charts, however some are more useful out of the box than others due to the type of marks involved.

\subsubsection{Discussion}
This case example demonstrates that ecosystem-level remediation and customization is not only possible for toolkit builders but Data Navigator offers robust potential. Data Navigator's structure, input, and rendering capabilities are all flexible and can be adjusted to suit the needs of a specific toolkit's design  and intended use.

Many visualization libraries may not even provide screen reader accessible SVG using ARIA-based approaches but do have a consistent underlying architectural pattern. Some libraries have a consistent method for converting data into visual formats, readable text labels, and interaction logic. Strong contenders would be visualization libraries popular in online, web-based data science notebooks like \textit{ggplot2} in R or \textit{matplotlib} for Python, which typically only render rasterized pngs or semanticless SVG.

Toolkits with consistent underlying architecture would allow toolkit developers, not just developers who \textit{use} toolkits, to remediate and customize their navigation accessibility using a generic approach.

Enabling accessibility at the toolkit level allows all downstream use of that tool to have better defaults, options, and resources available for building more accessible outcomes for end users.

Many libraries and toolkits provide users with a level of functional defaults and abstract conciseness so that users don't have to worry about low-level geometric considerations~\cite{Satyanarayan2017VegaLite}.

Data Navigator allows toolkits developers to also provide their users with abstractions and defaults for accessibility that make sense for their ecosystem.

Despite our schema recreating a screen reader experience based on SVG (and improving it), Data Navigator's additional features also apply: users are able to leverage a much wider array of input modalities.

\textit{Vega-Lite} provides many ways to make marks clickable and even perform complex actions using mouse-based input. While Data Navigator does not engage accessible brush and drag-based inputs, it does provide keyboard-only access by default, which can be used to make events previously only accessible to mouse clicking available to many other technologies. This is an improvement over \textit{Vega-Lite}'s SVG + ARIA rendering option.

When measuring performance across test datasets containing 406 and 20,300 data points in a scatter plot, Data Navigator increases initialization time by $\sim$0.45 to $\sim$1.5ms respectively. Our extraction functions specific to \textit{Vega-Lite} increase initialization between $\sim$4.8 and $\sim$8.5ms respectively. Given that our benchmark testing for \textit{Vega-Lite's} SVG rendering initialized in $\sim$1,800ms for 20,300 data points and canvas in $\sim$700ms, we do not anticipate that Data Navigator will have a negative impact on performance in most visualization contexts.

\subsection{Co-designing Novel Data Navigation Prototypes}
\label{section:codesign}

Recent projects in accessible data navigation have involved extensive co-design work with people with disabilities, ranging on the magnitude of months with as many as 10 co-designers at a time~\cite{Lundgard2019Sociotechnical,Lundgard2022Accessible,Zong2022Rich,Thompson2023Chart}.

However many visualization experiences may be authored in smaller scales, with fewer designers, and less time such as the development of a prototype or demonstration of an emerging idea. In practical or industry contexts, co-design sessions (and design sessions in general) may be much shorter. The goal of these co-design sessions is simply to create an artifact with the artifact's intended users.

Since our paper is contribution towards practical outcomes, we simulated a light co-design session with the aim of producing low-fidelity prototypes of novel data interaction patterns.

\subsubsection{Co-design Session Methods and Setup}
\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{figures/braille.png}
  \caption{Our material preparation process involved taking a reference (\textbf{A}), tracing it (\textbf{B}), and rendering it on a tactile display (\textbf{C}).}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{braille}
\end{figure}

Authors Frank Elavsky (sighted) and Lucas Nadolskis (blind) set out with the goal of developing screen-reader friendly prototypes that can explore geometric and mathematical models produced by the math diagramming tool \textit{Penrose}~\cite{Ye2020Penrose}.

Nadolskis is a neuroscience engineer who is a native screen reader user and uses both mathematical concepts as well as data-related tasks in his research. Elavsky proposed a series of possible math-based visualization types produced by \textit{Penrose} to build prototypes for, and Nadolskis selected \textit{set} and \textit{vector} diagrams as the two worth exploring first. The justification for this selection is that understanding these two concepts is important for work in data science, programming, and more advanced math concepts.

In particular we grounded the context of our contribution in a hypothetical classroom setting, where a screen reader user who is a student will have access to the equations in both raw text and \textit{MathJax}. We want to provide an experience that does not replace the existing resources screen reader users have to learn in classrooms but rather supplement.

At our disposal for our co-design session was a \textit{Dot Pad}~\cite{Dot2020Dot}, which is a refreshable tactile braille display. Our \textit{Dot Pad} enabled Elavsky to produce something visual and then translate it into the display for Nadolskis. Similar to de Greef \ea~\cite{deGreef2021Interdependent}, we used a tactile interface as an intermediary to help us get a shared sense of the meaningful spatial features of our figures.

Elavsky started with a reference diagram and then traced a wide variety of every possible node that might be worth navigating to in the diagram (see \autoref{braille}).

We selected which nodes were most important in each diagram, how to navigate between them, and how we wanted to render their visuals and semantics.

The selection of our problem space, scope of solutions, context of contribution, general discussion, and preparation of materials took approximately 12 hours of work over 2 weeks. The exploration of our prototype design space for our 2 prototypes took 1 hour. Building the prototypes took 2 hours.

\subsubsection{Creating a Navigable Set Diagram}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/sets.png}
  \caption{\textbf{A.} A reference image from \textit{Penrose} of a set diagram containing two sets intersecting. \textbf{B.} A diagram of our proposed structure, with three levels of information.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{sets}
\end{figure}

Our first prototype was a set diagram (see~\autoref{sets}). For our structure, we decided that it has 3 important semantic levels: the high level, the inclusion level, and the exclusion level. The inclusion level is first and the siblings are all sets or subsets that include other sets. The exclusion level is beneath and contains sets or subsets that are exclusive to the sets they belong to, which are accessed by drilling down from a set. 

Our schema design starts with a user encountering the root level (1) and may optionally drill in to the first child of the next level (2) using the \textit{Enter} key. The user may navigate siblings at this level using \textit{right} and \textit{left} directions, but this level is not circular (like in \autoref{static}) to maintain the spatial relationships. The user may drill in on either set again to view the non-intersecting portion of that set. Any node can drill up, towards the root, using \textit{Escape} or \textit{Backspace}.

% \textbf{Rendering.} The following descriptions correspond to the numbered nodes in \autoref{sets}:
% \begin{enumerate}
%   \itemsep-0.4em
%   \item Set A intersects Set B. Spatial view.
%   \item Set A, count: 10. Contains 1 intersection and 1 non-intersecting subset.
%   \item Set A and B intersection, count: 7.
%   \item Set B, count: 10. Contains 1 intersection and 1 non-intersecting subset.
%   \item Set A non-intersecting subset, count: 3.
%   \item Set B non-intersecting subset, count: 3
% \end{enumerate}

\subsubsection{Creating a Navigable Parallel Vectors Diagram}
\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/vectors.png}
  \caption{\textbf{A.} A reference image from \textit{Penrose} of a parallel vectors diagram. \textbf{B.} A diagram of our proposed structure, with two main sub-categories of information: understanding the vectors and their parallels.}
  % \Description{A mouse pointer is shown shaking over many data points that are very small while a touch hit area is shown over the same visualization, overlapping with many points at once.}
  \label{vectors}
\end{figure}

Our second prototype was a parallel vectors diagram (see~\autoref{vectors}). For the structure of this diagram we created a first level group that contains each vector and vector sum. The sibling to this grouping is another group which organizes sub-equations related to calculating each parallel vector. The sub equations each contain children that pair the sub equation with the vector it is parallel to.

Similar to \autoref{sets}, this figure maintains spatial relationships along the x dimension, does not have circular navigation, and allows drilling in and out.

% \textbf{Rendering.} The following descriptions correspond to the numbered nodes in \autoref{vectors}:
% \begin{enumerate}
%   \itemsep-0.4em
%   \item Using the sum of Vectors A and B to form parallel vectors. Spatial view.
%   \item Vectors, group.
%   \item Sub-equations for parallel vectors, group.
%   \item Vector A [equation].
%   \item Sum of Vectors A and B.
%   \item Vector B [equation].
%   \item Connecting Vector A to the Sum Vector creates a parallel Vector to Vector B.
%   \item Connecting Vector B to the Sum Vector creates a parallel Vector to Vector A.
%   \item Parallel Vector A Sum AB and Vector B.
%   \item Parallel Vector B Sum AB and Vector A.
% \end{enumerate}

\subsubsection{Discussion}
After our co-design sessions, our visual materials and navigation structures were used in the creation of functional prototypes. We additionally hand-crafted the descriptions and semantics for each node.

Accessibility work often takes a long time, from co-design to building to validation. But we believe that a well-articulated and useful design space, with tools that provide expressiveness and control over the dimensions of that design space, can improve how this work is done. The above case example demonstrates how builders who are thinking about data navigation design can rapidly scaffold prototypes for use in Data Navigator.

In particular, Data Navigator's design as a system gave our co-design sessions \textit{vocabulary correspondence}. Data Navigator's language helped us focus on the \textit{nodes, edges,} and \textit{navigation rules} for our \textit{structure} while we also explicitly discussed the \textit{rendering} details of \textit{coordinates, shapes, styling,} and \textit{semantics} for each node. The vocabulary of our design space directly corresponded with code details required to create a functional prototype.

% Our ability to develop these novel prototypes in a short turnaround time hinged on the design considerations of \textit{structure, navigation,} and \textit{description}~\cite{Zong2022Rich}. In addition, our deliverables are easy to integrate into a working, interactive prototype in Data Navigator because our system was designed to have \textit{vocabulary correspondence} these design dimensions. In an industry or research setting, these interactive prototypes could now be shared with other collaborators and stakeholders for further iteration.

We note that this co-design work is not intended to contribute a \textit{validated} set of designs. Rather, our contribution with this case example is to demonstrate that within the larger ecosystem of a research venture, Data Navigator is an improvement over designing and building navigable structures from scratch.

\section{Limitations and Future Work}
Data Navigator is a technical contribution, a system designed for appropriation~\cite{Dourish2003Appropriation} and adaptation~\cite{Wobbrock2011Ability} in different applied contexts. It is, as Louridas writes, a \textit{technical material}: a technology that enables new and useful capabilities~\cite{Louridas1999Bricolage}. While beyond the scope of the current paper, a critical next step for future work is to conduct separate studies with both practitioners and end users to evaluate Data Navigator's affordances.

Unlike toolkits that provide an end-to-end development pipeline for accessible visualization, Data Navigator serves as a low-level building block or material (like concrete). As such, one potential limitation of the framework is that it can be used to build both curbs (which are inaccessible) as well as ramps and \textit{curb-cuts} (which may be more broadly accessible).

Even when building more accessible curb-cuts, we stress the importance of actively involving people with disabilities in the design and validation of new ideas, in line with prior work~\cite{Reid2022Curb,Lundgard2019Sociotechnical,Lundgard2022Accessible,Zong2022Rich}. For example, while our first two case examples replicate co-designed and validated existing work, our third case example's co-designed prototypes would need to be validated with relevant stakeholders before wider implementation. Our system does not \textit{guarantee} any sort of accessibility on its own.

The diverse array of modalities supported by Data Navigator opens an immediate line of future work in engaging people with a correspondingly diverse set of disabilities. While recent explorations into accessible data visualization have been inspiring, this trend has primarily focused on the experiences of people with visual disabilities~\cite{Elavsky2022Chartability,Marriott2021Inclusive,Kim2021Accessible}. More research should be conducted with other populations, particularly people who leverage assistive technologies beyond screen readers, to understand how interactive data visualizations can be better designed to serve them.

Finally, there are significant opportunities to improve the efficiency of our approach, including developing deterministic and non-deterministic methods to generate node-edge data and navigation rules from a visualization. Ma'ayan \ea stress in particular that reducing tedious complexity can contribute to the success of a well-designed toolkit~\cite{Maayan2020Domain}. Future work should identify areas where graphical interface tools or higher-level specifications can improve the experience of working with Data Navigator.

\section{Conclusion}
Practitioners at large continue to produce inaccessible interactive data visualizations, excluding people with disabilities. We believe that the burden of remediation first starts with the developers who build and maintain the toolkits that practitioners use.

However, the challenges faced by toolkit builders are significant. Most toolkits lack an underlying, navigable structure, support for broad input modalities used by people with disabilities, and meaningful, semantic rendering.

To engage these limitations we present Data Navigator, a technical contribution that builds on existing work towards a more generalizable accessibility-centered toolkit for creating data navigation interfaces. Data Navigator is designed for use by practitioners who both build and use existing toolkits and want a tool to make their data visualizations and interfaces more accessible.

We contribute a high-level system design for our node-edge graph-based approach that can be used to build data structures that are navigable by a wide array of assistive technologies and input modalities. Data Navigator is generic and can scaffold list, tree, graph, relational, spatial, diagrammatic, and geographic types of data structures common to data visualization.

Our system is designed to encourage both remediation of existing inaccessible systems and visualization formats as well as help scaffold the design of novel, future projects. We look forward to further research that explores the possibilities enabled by Data Navigator.

%% if specified like this the section will be committed in review mode
\acknowledgments{
We want to take this time to express immense gratitude for Reviewer 1, whose generous and thorough feedback helped this project find its true vision. Elavsky also wants to thank the many folks who have encouraged this project's ideation and formation over the last few years.

This work was supported by a grant from Apple, Inc. Any views, opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and should not be interpreted as reflecting the views, policies or position, either expressed or implied, of Apple Inc.
}

%\bibliographystyle{abbrv}
% \bibliographystyle{abbrv-doi}
%\bibliographystyle{abbrv-doi-narrow}
\bibliographystyle{abbrv-doi-hyperref}
%\bibliographystyle{abbrv-doi-hyperref-narrow}

\bibliography{bibliography}
\end{document}

